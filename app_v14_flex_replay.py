# ============================================================
# Predict Cars V14-FLEX ULTRA REAL (TURBO++)
# streamlit_app.py ‚Äî Vers√£o completa com:
# - Entrada FLEX (n vari√°vel de passageiros)
# - Bar√¥metro ULTRA REAL
# - k* ULTRA REAL (sentinela baseado em k dos guardas)
# - IDX / IPF / IPO ULTRA
# - S6 Profundo & Micro-Leque ULTRA
# - Monte Carlo Profundo ULTRA
# - QDS REAL & Backtest REAL
# - Replay LIGHT
# - Replay ULTRA (Horizonte Ajust√°vel)
# - Modo TURBO++ ULTRA Adaptativo
# ============================================================

import streamlit as st
import pandas as pd
import numpy as np
import math
from typing import List, Tuple, Dict, Any
from collections import Counter
from itertools import combinations

# ------------------------------------------------------------
# Configura√ß√£o b√°sica da p√°gina
# ------------------------------------------------------------
st.set_page_config(
    page_title="Predict Cars V14-FLEX ULTRA REAL (TURBO++)",
    layout="wide",
)

# ------------------------------------------------------------
# Utilit√°rios gerais
# ------------------------------------------------------------

def registrar_evento(msg: str) -> None:
    """Log simples em session_state, apenas informativo."""
    historico = st.session_state.get("log_eventos", [])
    historico.append(msg)
    st.session_state["log_eventos"] = historico


def calcular_entropia(valores: List[int]) -> float:
    """Entropia de Shannon b√°sica para lista de inteiros."""
    if not valores:
        return 0.0
    contagem = Counter(valores)
    total = sum(contagem.values())
    if total == 0:
        return 0.0
    ent = 0.0
    for c in contagem.values():
        p = c / total
        ent -= p * math.log2(p)
    return ent


def normalizar_0_1(x: float, xmin: float, xmax: float) -> float:
    if xmax == xmin:
        return 0.0
    v = (x - xmin) / (xmax - xmin)
    return max(0.0, min(1.0, v))


def detectar_colunas_passageiros(df_raw: pd.DataFrame) -> Tuple[List[str], str]:
    """
    Detecta automaticamente quais colunas s√£o de passageiros e qual √© a coluna k.

    Regra:
    - Se existir coluna 'k' (case insensitive), ela √© usada como k.
    - Caso contr√°rio, assume-se que a √∫ltima coluna num√©rica √© k.
    - Todas as colunas num√©ricas (exceto k) entre a primeira num√©rica e k s√£o passageiros.
    """
    cols = list(df_raw.columns)

    # Tenta achar 'k' expl√≠cito
    col_k = None
    for c in cols:
        if str(c).strip().lower() == "k":
            col_k = c
            break

    if col_k is None:
        # Tenta usar √∫ltima coluna num√©rica
        numeric_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df_raw[c])]
        if not numeric_cols:
            raise ValueError("Nenhuma coluna num√©rica encontrada para detectar passageiros/k.")
        col_k = numeric_cols[-1]

    # Passageiros = todas num√©ricas antes de k
    idx_k = cols.index(col_k)
    numeric_before_k = [
        c for c in cols[: idx_k + 1] if pd.api.types.is_numeric_dtype(df_raw[c])
    ]
    passageiros_cols = [c for c in numeric_before_k if c != col_k]

    if len(passageiros_cols) == 0:
        raise ValueError("Nenhuma coluna de passageiros detectada antes da coluna k.")

    return passageiros_cols, col_k


def preparar_historico_flex(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Prepara o hist√≥rico em formato FLEX:
    - Detecta automaticamente colunas de passageiros e coluna k.
    - Garante √≠ndice C1, C2, ...
    - Salva estrutura em session_state:
      - 'df'
      - 'passageiros_cols'
      - 'col_k'
      - 'n_passageiros'
    """
    df = df_raw.copy()

    passageiros_cols, col_k = detectar_colunas_passageiros(df)
    n_pass = len(passageiros_cols)

    # Cria coluna ID se n√£o existir
    if "ID" not in df.columns and "id" not in [c.lower() for c in df.columns]:
        df.insert(0, "ID", [f"C{i}" for i in range(1, len(df) + 1)])

    # Normaliza o nome da coluna k para exatamente 'k'
    if col_k != "k":
        df.rename(columns={col_k: "k"}, inplace=True)
        col_k = "k"

    # Garante tipos num√©ricos
    for c in passageiros_cols + [col_k]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    df = df.dropna(subset=passageiros_cols + [col_k]).reset_index(drop=True)
    df["idx_interno"] = np.arange(1, len(df) + 1)

    st.session_state["df"] = df
    st.session_state["passageiros_cols"] = passageiros_cols
    st.session_state["col_k"] = col_k
    st.session_state["n_passageiros"] = n_pass

    return df


def obter_contexto_basico() -> Tuple[pd.DataFrame, List[str], str, int]:
    """Recupera df + metadados principais do session_state."""
    df = st.session_state.get("df", None)
    passageiros_cols = st.session_state.get("passageiros_cols", [])
    col_k = st.session_state.get("col_k", "k")
    n_pass = st.session_state.get("n_passageiros", len(passageiros_cols))
    return df, passageiros_cols, col_k, n_pass


# ------------------------------------------------------------
# Bar√¥metro ULTRA REAL + k* ULTRA REAL (sentinela)
# ------------------------------------------------------------

def calcular_barometro_ultra(df: pd.DataFrame, col_k: str, window: int = 120) -> Dict[str, Any]:
    """
    Bar√¥metro ULTRA REAL baseado na coluna k:
    - k representa quantos guardas acertaram exatamente os 15 passageiros do carro.
    - O bar√¥metro mede a estabilidade global desse "acerto dos guardas" ao longo do tempo.
    """
    if df is None or df.empty:
        return {
            "estado": "desconhecido",
            "turbulencia": None,
            "std_k": None,
            "mean_abs_dk": None,
        }

    serie_k = df[col_k].astype(float).values
    if len(serie_k) < 3:
        return {
            "estado": "desconhecido",
            "turbulencia": None,
            "std_k": None,
            "mean_abs_dk": None,
        }

    w = min(window, len(serie_k))
    recent = serie_k[-w:]
    if len(recent) < 3:
        return {
            "estado": "desconhecido",
            "turbulencia": None,
            "std_k": None,
            "mean_abs_dk": None,
        }

    diffs = np.diff(recent)
    mean_abs_dk = float(np.mean(np.abs(diffs)))
    std_k = float(np.std(recent))

    # √çndice de turbul√™ncia: mistura varia√ß√£o de k + varia√ß√£o entre carros
    turbulencia = float(mean_abs_dk + 0.3 * std_k)

    # Estados (ajustados para a natureza de k como "acerto de guardas")
    # Baixa turbul√™ncia ‚Üí estrada previs√≠vel (muitos guardas alinhados ou padr√£o est√°vel)
    # Alta turbul√™ncia ‚Üí guardas ora acertam muito, ora erram muito ‚Üí regime ca√≥tico.
    if turbulencia < 1.5:
        estado = "estavel"
    elif turbulencia < 3.0:
        estado = "atencao"
    else:
        estado = "critico"

    return {
        "estado": estado,
        "turbulencia": turbulencia,
        "std_k": std_k,
        "mean_abs_dk": mean_abs_dk,
    }


def calcular_k_star_ultra(df: pd.DataFrame, col_k: str, window: int = 80) -> Dict[str, Any]:
    """
    k* ULTRA REAL (sentinela):
    - Usa a distribui√ß√£o de k (acertos dos guardas) nas √∫ltimas 'window' s√©ries.
    - Entropia alta + varia√ß√£o alta ‚Üí cen√°rio ca√≥tico (guardas ora enxergam bem, ora n√£o).
    - Entropia baixa + k est√°vel ‚Üí cen√°rio mais previs√≠vel.
    Retorna:
      - k_star (0..100)
      - entropia
      - entropia_normalizada (0..1)
      - estado (estavel / atencao / critico)
    """
    if df is None or df.empty:
        return {
            "k_star": None,
            "estado": "desconhecido",
            "entropia": None,
            "entropia_norm": None,
        }

    serie_k = df[col_k].astype(int).values
    w = min(window, len(serie_k))
    recent = serie_k[-w:]
    if len(recent) < 5:
        return {
            "k_star": None,
            "estado": "desconhecido",
            "entropia": None,
            "entropia_norm": None,
        }

    ent = calcular_entropia(list(recent))
    # Entropia m√°xima aproximada para k limitado (0..15 ou pr√≥ximo)
    ent_max_teorica = math.log2(len(set(recent))) if len(set(recent)) > 1 else 1.0
    ent_norm = normalizar_0_1(ent, 0.0, ent_max_teorica)

    diffs = np.diff(recent)
    mean_abs_dk = float(np.mean(np.abs(diffs)))
    std_k = float(np.std(recent))

    # √çndice composto de caos local: varia√ß√£o + entropia
    caos_local = 0.6 * ent_norm + 0.25 * normalizar_0_1(mean_abs_dk, 0.0, 8.0) + 0.15 * normalizar_0_1(std_k, 0.0, 8.0)
    k_star = float(100.0 * caos_local)

    if k_star < 35:
        estado = "estavel"
    elif k_star < 70:
        estado = "atencao"
    else:
        estado = "critico"

    return {
        "k_star": k_star,
        "estado": estado,
        "entropia": ent,
        "entropia_norm": ent_norm,
    }


# ------------------------------------------------------------
# N√∫cleos IDX / IPF / IPO ULTRA
# ------------------------------------------------------------

def extrair_passageiros_linha(row: pd.Series, passageiros_cols: List[str]) -> List[int]:
    return [int(row[c]) for c in passageiros_cols]


def calcular_nucleos_idx_ipf_ipo(
    df: pd.DataFrame,
    idx_alvo: int,
    passageiros_cols: List[str],
    janela: int = 40,
) -> Dict[str, List[int]]:
    """
    Calcula os n√∫cleos IDX / IPF / IPO ULTRA usando uma janela de hist√≥rico antes do idx_alvo.
    - IDX ULTRA: m√©dia ponderada din√¢mica (frequ√™ncia + posi√ß√£o)
    - IPF ULTRA: mediana robusta (estrutura)
    - IPO ORIGINAL: frequ√™ncia simples
    - IPO ULTRA: refinado anti-sesgo (ajusta ordem e pesos)
    """
    n = len(df)
    if n == 0:
        return {
            "IDX": [],
            "IPF": [],
            "IPO_ORIG": [],
            "IPO_ULTRA": [],
        }

    # idx_alvo √© 1-based
    idx0 = max(1, min(idx_alvo, n))
    fim = max(1, idx0 - 1)
    inicio = max(1, fim - janela + 1)

    bloco = df[(df["idx_interno"] >= inicio) & (df["idx_interno"] <= fim)]
    if bloco.empty:
        return {
            "IDX": [],
            "IPF": [],
            "IPO_ORIG": [],
            "IPO_ULTRA": [],
        }

    # Monta lista de passageiros por linha
    todas_series = [extrair_passageiros_linha(row, passageiros_cols) for _, row in bloco.iterrows()]
    flat = [p for serie in todas_series for p in serie]

    # Frequ√™ncia simples
    freq = Counter(flat)

    # Frequ√™ncia ponderada por posi√ß√£o na janela (mais recentes pesam mais)
    pesos_pos = {}
    for _, row in bloco.iterrows():
        pos_rel = row["idx_interno"] - inicio  # 0,1,2,...
        peso = 1.0 + pos_rel / max(1, (fim - inicio + 1))
        serie_pass = extrair_passageiros_linha(row, passageiros_cols)
        for p in serie_pass:
            pesos_pos[p] = pesos_pos.get(p, 0.0) + peso

    # IDX: top por peso posicional
    idx_ord = sorted(pesos_pos.items(), key=lambda x: (-x[1], x[0]))
    idx_nucleo = [p for p, _ in idx_ord][: len(passageiros_cols)]

    # IPO_ORIG: top por frequ√™ncia simples
    ipo_ord = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    ipo_orig = [p for p, _ in ipo_ord][: len(passageiros_cols)]

    # IPF: mediana robusta por posi√ß√£o do passageiro
    n_pass = len(passageiros_cols)
    matriz = np.array(todas_series)  # shape (M, n_pass)
    ipf = []
    for j in range(n_pass):
        col = matriz[:, j]
        ipf.append(int(np.median(col)))

    # IPO_ULTRA: mistura IDX + IPF + IPO_ORIG
    # Estrat√©gia: come√ßa com IPO_ORIG e faz pequenos ajustes usando IDX / IPF.
    base = ipo_orig.copy()
    bonus = set(idx_nucleo[: max(3, n_pass // 3)]) | set(ipf[: max(3, n_pass // 3)])
    # Garante presen√ßa de alguns elementos importantes
    for b in bonus:
        if b not in base:
            base.append(b)
    # Corta no tamanho certo
    ipo_ultra = base[:n_pass]

    return {
        "IDX": idx_nucleo,
        "IPF": ipf,
        "IPO_ORIG": ipo_orig,
        "IPO_ULTRA": ipo_ultra,
        "janela_inicio": int(inicio),
        "janela_fim": int(fim),
    }


# ------------------------------------------------------------
# Layout principal ‚Äî Navega√ß√£o
# ------------------------------------------------------------

if "log_eventos" not in st.session_state:
    st.session_state["log_eventos"] = []

st.title("Predict Cars V14-FLEX ULTRA REAL (TURBO++)")
st.write(
    "Sistema ULTRA completo com: Bar√¥metro, k*, IDX, IPF / IPO, S6 Profundo, Micro-Leque, "
    "Monte Carlo Profundo, QDS + Backtest, Replay LIGHT / ULTRA e Modo TURBO++ Adaptativo."
)

with st.sidebar:
    st.markdown("## Navega√ß√£o")
    painel = st.radio(
        "Escolha o painel:",
        [
            "üì• Hist√≥rico ‚Äî Entrada (FLEX)",
            "üîç Pipeline V14-FLEX ULTRA",
            "üö® Monitor de Risco (Bar√¥metro + k*)",
            "üìä IDX / IPF / IPO ULTRA",
            "üß¨ S6 Profundo & Micro-Leque ULTRA",
            "üé≤ Monte Carlo Profundo ULTRA",
            "üß™ QDS REAL & Backtest REAL",
            "üìÖ Replay LIGHT",
            "üìÖ Replay ULTRA (Horizonte Ajust√°vel)",
            "üöÄ Modo TURBO++ ULTRA",
        ],
    )

# ------------------------------------------------------------
# PAINEL 1 ‚Äî Hist√≥rico ‚Äî Entrada (FLEX)
# ------------------------------------------------------------

if painel == "üì• Hist√≥rico ‚Äî Entrada (FLEX)":
    st.markdown("## üì• Hist√≥rico ‚Äî Entrada (FLEX)")

    df_sessao = st.session_state.get("df", None)
    if df_sessao is not None and not df_sessao.empty:
        st.success("Hist√≥rico j√° carregado na sess√£o.")
        st.dataframe(df_sessao.head(10), use_container_width=True)

    opc = st.radio(
        "Como deseja carregar o hist√≥rico?",
        ["Enviar arquivo CSV", "Copiar e colar o hist√≥rico"],
    )

    if opc == "Enviar arquivo CSV":
        file = st.file_uploader("Selecione o arquivo CSV:", type=["csv"])
        if file is not None:
            try:
                df_raw = pd.read_csv(file, sep=";", header=None, engine="python")
                df_raw = df_raw.dropna(axis=1, how="all")
               
                df = preparar_historico_flex(df_raw)
                st.success("Hist√≥rico carregado com sucesso (modo FLEX).")
                st.write(f"Total de s√©ries: **{len(df)}**")
                st.write(f"Passageiros por s√©rie (FLEX): **{st.session_state['n_passageiros']}**")
                st.write(f"Coluna k (guardas que acertaram): **{st.session_state['col_k']}**")
                registrar_evento("Hist√≥rico carregado via CSV (FLEX).")
            except Exception as e:
                st.error(f"Erro ao carregar CSV: {e}")

    else:
        texto = st.text_area(
            "Cole aqui o hist√≥rico (CSV ou linhas separadas por ponto e v√≠rgula):",
            height=200,
        )
        if st.button("Carregar hist√≥rico colado"):
            if not texto.strip():
                st.warning("Cole algum conte√∫do antes de carregar.")
            else:
                try:
                    from io import StringIO

                    buffer = StringIO(texto)
                    # Tenta detectar separador
                    df_raw = pd.read_csv(buffer, sep=None, engine="python", header=None)
                    # Tenta criar cabe√ßalho gen√©rico se necess√°rio
                    if df_raw.columns.dtype == "int64":
                        df_raw.columns = [f"col{i+1}" for i in range(len(df_raw.columns))]
                    df = preparar_historico_flex(df_raw)
                    st.success("Hist√≥rico carregado com sucesso (modo FLEX).")
                    st.write(f"Total de s√©ries: **{len(df)}**")
                    st.write(f"Passageiros por s√©rie (FLEX): **{st.session_state['n_passageiros']}**")
                    st.write(f"Coluna k (guardas que acertaram): **{st.session_state['col_k']}**")
                    registrar_evento("Hist√≥rico carregado via texto colado (FLEX).")
                except Exception as e:
                    st.error(f"Erro ao interpretar o texto como CSV: {e}")

    df, passageiros_cols, col_k, n_pass = obter_contexto_basico()
    if df is not None and not df.empty:
        st.markdown("### üìå Resumo do hist√≥rico atual")
        st.write(f"**Total de s√©ries:** {len(df)}")
        st.write(f"**Passageiros por s√©rie (detectado):** {n_pass}")
        st.write(f"**Coluna k (guardas que acertaram):** {col_k}")

        idx_preview = st.number_input(
            "Selecione um √≠ndice interno para inspecionar (1 = primeira s√©rie carregada):",
            min_value=1,
            max_value=len(df),
            value=len(df),
            step=1,
        )
        row = df.iloc[idx_preview - 1]
        serie_pass = extrair_passageiros_linha(row, passageiros_cols)
        st.markdown(
            f"**C{idx_preview} ‚Äî Passageiros:** {serie_pass} ‚Äî k (guardas que acertaram): **{int(row[col_k])}**"
        )


# ------------------------------------------------------------
# PAINEL 2 ‚Äî Pipeline V14-FLEX ULTRA (Execu√ß√£o Base)
# ------------------------------------------------------------

if painel == "üîç Pipeline V14-FLEX ULTRA":
    st.markdown("## üîç Pipeline V14-FLEX ULTRA ‚Äî Execu√ß√£o Base")

    df, passageiros_cols, col_k, n_pass = obter_contexto_basico()
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada (FLEX)'.")
        st.stop()

    n_total = len(df)

    modo_idx = st.radio(
        "Como deseja escolher o √≠ndice alvo?",
        ["Usar √∫ltima s√©rie do hist√≥rico", "Escolher manualmente"],
    )

    if modo_idx == "Usar √∫ltima s√©rie do hist√≥rico":
        idx_alvo = n_total
    else:
        idx_alvo = st.number_input(
            "Selecione o √≠ndice alvo (1 = primeira s√©rie carregada):",
            min_value=1,
            max_value=n_total,
            value=n_total,
            step=1,
        )

    row_alvo = df.iloc[idx_alvo - 1]
    serie_pass_alvo = extrair_passageiros_linha(row_alvo, passageiros_cols)
    k_alvo = int(row_alvo[col_k])
    st.markdown("### üéØ Sele√ß√£o da s√©rie alvo")
    st.write(
        f"üìå **S√©rie alvo selecionada** ‚Äî ID C{idx_alvo} ‚Äî Passageiros: {serie_pass_alvo} ‚Äî "
        f"k (guardas que acertaram): **{k_alvo}**"
    )

    # 1) Diagn√≥stico de risco ‚Äî Bar√¥metro + k*
    st.markdown("### 1Ô∏è‚É£ Diagn√≥stico de risco ‚Äî Bar√¥metro + k*")

    bar = calcular_barometro_ultra(df, col_k)
    kstar_info = calcular_k_star_ultra(df, col_k)

    estado_bar = bar["estado"]
    estado_kstar = kstar_info["estado"]

    # Bar√¥metro
    if estado_bar == "critico":
        st.error("üî¥ Bar√¥metro: **cr√≠tico** ‚Äî estrada globalmente turbulenta.")
    elif estado_bar == "atencao":
        st.warning("üü° Bar√¥metro: **aten√ß√£o** ‚Äî estrada moderadamente inst√°vel.")
    elif estado_bar == "estavel":
        st.success("üü¢ Bar√¥metro: **est√°vel** ‚Äî estrada historicamente previs√≠vel.")
    else:
        st.info("‚ö™ Bar√¥metro: estado **desconhecido** (poucos dados).")

    st.write(
        f"**√çndice de turbul√™ncia:** `{bar['turbulencia']:.3f}` ‚Ä¢ "
        f"Desvio-padr√£o de k: `{bar['std_k']:.3f}` ‚Ä¢ M√©dia de |Œîk|: `{bar['mean_abs_dk']:.3f}`"
    )

    st.markdown("#### üõ∞Ô∏è k* ULTRA REAL (Sentinela baseado em k dos guardas)")

    if kstar_info["k_star"] is not None:
        k_star_val = kstar_info["k_star"]
        if estado_kstar == "critico":
            st.error(
                f"üî¥ k*: **cr√≠tico** ‚Äî guardas com padr√£o de acerto/erro altamente ca√≥tico. (k*={k_star_val:.1f})"
            )
        elif estado_kstar == "atencao":
            st.warning(
                f"üü° k*: **aten√ß√£o** ‚Äî guardas com padr√£o misto de acerto/erro. (k*={k_star_val:.1f})"
            )
        elif estado_kstar == "estavel":
            st.success(
                f"üü¢ k*: **est√°vel** ‚Äî guardas com padr√£o relativamente previs√≠vel. (k*={k_star_val:.1f})"
            )
        else:
            st.info("‚ö™ k*: estado desconhecido (poucos dados).")

        st.write(
            f"Entropia de k: `{kstar_info['entropia']:.3f}` ‚Ä¢ "
            f"Entropia normalizada: `{kstar_info['entropia_norm']:.3f}`"
        )
    else:
        st.info("k*: n√£o foi poss√≠vel calcular (poucos dados).")

    # S√≠ntese textual
    st.markdown("#### üåê Pr√©-s√≠ntese de risco global (sem afetar o motor)")
    st.info(
        "O Bar√¥metro ULTRA avalia a estabilidade global dos acertos dos guardas (k) ao longo da estrada. "
        "O k* ULTRA REAL atua como sentinela de caos local: se os guardas oscilam demais entre acertar tudo e errar "
        "tudo em janelas curtas, k* sobe. O motor ULTRA usa essas informa√ß√µes **apenas como contexto**, "
        "n√£o como trava direta da previs√£o."
    )

    # 2) N√∫cleos IDX / IPF / IPO ULTRA
    st.markdown("### 2Ô∏è‚É£ N√∫cleos IDX / IPF / IPO ULTRA (base para previs√£o)")

    nucleos = calcular_nucleos_idx_ipf_ipo(df, idx_alvo, passageiros_cols, janela=40)
    idx_nucleo = nucleos["IDX"]
    ipf_nucleo = nucleos["IPF"]
    ipo_orig = nucleos["IPO_ORIG"]
    ipo_ultra = nucleos["IPO_ULTRA"]
    inicio_jan = nucleos.get("janela_inicio", max(1, idx_alvo - 40))
    fim_jan = nucleos.get("janela_fim", idx_alvo - 1)

    st.write("#### IDX ULTRA (m√©dia ponderada din√¢mica)")
    st.code(" ".join(str(x) for x in idx_nucleo), language="text")

    st.write("#### IPF ULTRA (mediana robusta estrutural)")
    st.code(" ".join(str(x) for x in ipf_nucleo), language="text")

    st.write("#### IPO ORIGINAL (m√©dia simples de frequ√™ncia)")
    st.code(" ".join(str(x) for x in ipo_orig), language="text")

    st.write("#### IPO ULTRA (refinada anti-sesgo, mistura IDX + IPF + IPO)")
    st.code(" ".join(str(x) for x in ipo_ultra), language="text")

    st.write(
        f"Janela usada: √≠ndices de **{inicio_jan}** at√© **{fim_jan}** "
        f"(tamanho **{fim_jan - inicio_jan + 1}** s√©ries)."
    )

    st.markdown("### 3Ô∏è‚É£ Pr√©-s√≠ntese da base de previs√£o ULTRA")
    st.info(
        "Nesta camada, o app consolida os n√∫cleos IDX / IPF / IPO como ponto de partida para o motor ULTRA "
        "(S6 Profundo, Micro-Leque, Monte Carlo, QDS / Backtest e TURBO++), que ser√° aplicado nas pr√≥ximas camadas."
    )

# (continua na PARTE 2/4)
# ------------------------------------------------------------
# PAINEL 3 ‚Äî Monitor de Risco (Bar√¥metro + k*)
# ------------------------------------------------------------

if painel == "üö® Monitor de Risco (Bar√¥metro + k*)":
    st.markdown("## üö® Monitor de Risco (Bar√¥metro + k*)")

    df, passageiros_cols, col_k, n_pass = obter_contexto_basico()
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada (FLEX)'.")
        st.stop()

    st.markdown("### üå°Ô∏è Bar√¥metro ULTRA REAL")

    bar = calcular_barometro_ultra(df, col_k)
    estado_bar = bar["estado"]

    if estado_bar == "critico":
        st.error("üî¥ Estado do bar√¥metro: **cr√≠tico**")
        st.write("Bar√¥metro: estrada globalmente turbulenta ‚Äî os acertos dos guardas (k) variam demais.")
    elif estado_bar == "atencao":
        st.warning("üü° Estado do bar√¥metro: **aten√ß√£o**")
        st.write("Bar√¥metro: estrada moderadamente inst√°vel ‚Äî altern√¢ncia entre fases de ordem e ru√≠do.")
    elif estado_bar == "estavel":
        st.success("üü¢ Estado do bar√¥metro: **est√°vel**")
        st.write("Bar√¥metro: estrada historicamente est√°vel ‚Äî padr√£o de acertos dos guardas relativamente previs√≠vel.")
    else:
        st.info("‚ö™ Estado do bar√¥metro: **desconhecido** (hist√≥rico insuficiente).")

    if bar["turbulencia"] is not None:
        st.write(f"**√çndice de turbul√™ncia:** `{bar['turbulencia']:.3f}`")
        st.write(f"**Desvio-padr√£o de k:** `{bar['std_k']:.3f}`")
        st.write(f"**M√©dia de |Œîk| (varia√ß√£o entre carros):** `{bar['mean_abs_dk']:.3f}`")

    st.markdown("---")
    st.markdown("### üõ∞Ô∏è k* ULTRA REAL (Sentinela)")

    kstar_info = calcular_k_star_ultra(df, col_k)
    estado_kstar = kstar_info["estado"]
    k_star_val = kstar_info.get("k_star", None)

    if k_star_val is not None:
        if estado_kstar == "critico":
            st.error(
                f"üî¥ Estado do k*: **cr√≠tico** ‚Äî guardas em regime ca√≥tico de acerto/erro. (k*={k_star_val:.1f})"
            )
        elif estado_kstar == "atencao":
            st.warning(
                f"üü° Estado do k*: **aten√ß√£o** ‚Äî padr√£o misto de acertos, com altern√¢ncia relevante. (k*={k_star_val:.1f})"
            )
        elif estado_kstar == "estavel":
            st.success(
                f"üü¢ Estado do k*: **est√°vel** ‚Äî guardas com padr√£o relativamente previs√≠vel. (k*={k_star_val:.1f})"
            )
        else:
            st.info("‚ö™ Estado do k*: **desconhecido** (hist√≥rico insuficiente).")

        st.write(f"**Entropia de k:** `{kstar_info['entropia']:.3f}`")
        st.write(f"**Entropia normalizada:** `{kstar_info['entropia_norm']:.3f}`")
    else:
        st.info("k*: n√£o foi poss√≠vel calcular (poucos dados).")

    st.markdown("---")
    st.markdown("### üåê S√≠ntese Global de Risco")

    # S√≠ntese global boa pr√°tica: combina bar√¥metro (global) + k* (local),
    # mas N√ÉO trava o motor. Apenas orienta o usu√°rio.
    if estado_bar == "critico" or estado_kstar == "critico":
        st.error("üî¥ N√≠vel global de risco: **cr√≠tico**")
        st.write(
            "Ambiente global cr√≠tico ‚Äî usar qualquer previs√£o com m√°xima cautela. "
            "Estrada e/ou guardas em regime altamente turbulento."
        )
        regime_state = "critico"
    elif estado_bar == "atencao" or estado_kstar == "atencao":
        st.warning("üü° N√≠vel global de risco: **aten√ß√£o**")
        st.write(
            "Ambiente global em aten√ß√£o ‚Äî estrada com oscila√ß√µes percept√≠veis ou guardas com padr√£o de acerto/erro misto. "
            "Previs√µes continuam poss√≠veis, por√©m com prud√™ncia refor√ßada."
        )
        regime_state = "atencao"
    elif estado_bar == "estavel" and estado_kstar == "estavel":
        st.success("üü¢ N√≠vel global de risco: **est√°vel**")
        st.write(
            "Ambiente global est√°vel ‚Äî estrada historicamente previs√≠vel e guardas com padr√£o coerente de acertos. "
            "Pr√©-condi√ß√µes favor√°veis para previs√µes ULTRA."
        )
        regime_state = "estavel"
    else:
        st.info("‚ö™ N√≠vel global de risco: **desconhecido**")
        st.write(
            "N√£o h√° dados suficientes para uma s√≠ntese de risco confi√°vel. "
            "Use as previs√µes com cautela at√© que o hist√≥rico seja maior."
        )
        regime_state = "desconhecido"

    # Guarda o regime no session_state para uso em outros pain√©is
    st.session_state["regime_state"] = regime_state

    st.info(
        "üîé Importante: o Monitor de Risco **n√£o bloqueia** o motor ULTRA. "
        "Ele funciona como um painel de contexto, ajudando a interpretar em que tipo de ambiente "
        "as previs√µes est√£o sendo feitas (estrada calma, moderada ou ca√≥tica)."
    )


# ------------------------------------------------------------
# PAINEL 4 ‚Äî IDX / IPF / IPO ULTRA (vis√£o detalhada)
# ------------------------------------------------------------

if painel == "üìä IDX / IPF / IPO ULTRA":
    st.markdown("## üìä IDX / IPF / IPO ULTRA ‚Äî N√∫cleos Estruturais")

    df, passageiros_cols, col_k, n_pass = obter_contexto_basico()
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada (FLEX)'.")
        st.stop()

    n_total = len(df)

    idx_alvo = st.number_input(
        "Selecione o √≠ndice alvo para calcular os n√∫cleos (1 = primeira s√©rie):",
        min_value=1,
        max_value=n_total,
        value=n_total,
        step=1,
    )

    row_alvo = df.iloc[idx_alvo - 1]
    serie_pass_alvo = extrair_passageiros_linha(row_alvo, passageiros_cols)
    k_alvo = int(row_alvo[col_k])

    st.markdown("### üéØ S√©rie alvo (contexto imediato)")
    st.write(
        f"ID C{idx_alvo} | Passageiros: {serie_pass_alvo} | "
        f"k (guardas que acertaram exatamente o carro): **{k_alvo}**"
    )

    janela = st.number_input(
        "Tamanho da janela de hist√≥rico para c√°lculo dos n√∫cleos:",
        min_value=10,
        max_value=min(200, n_total - 1),
        value=40,
        step=5,
    )

    nucleos = calcular_nucleos_idx_ipf_ipo(df, idx_alvo, passageiros_cols, janela=int(janela))
    idx_nucleo = nucleos["IDX"]
    ipf_nucleo = nucleos["IPF"]
    ipo_orig = nucleos["IPO_ORIG"]
    ipo_ultra = nucleos["IPO_ULTRA"]
    inicio_jan = nucleos.get("janela_inicio", max(1, idx_alvo - int(janela)))
    fim_jan = nucleos.get("janela_fim", idx_alvo - 1)

    st.markdown("### üì¶ Janela de hist√≥rico usada")
    st.write(f"**In√≠cio da janela:** {inicio_jan}")
    st.write(f"**Fim da janela:** {fim_jan}")
    st.write(f"**Tamanho da janela:** {fim_jan - inicio_jan + 1}")

    st.markdown("### üß† N√∫cleos IDX / IPF / IPO ULTRA")

    st.write("#### IDX ULTRA (m√©dia ponderada din√¢mica)")
    st.code(" ".join(str(x) for x in idx_nucleo), language="text")

    st.write("#### IPF ULTRA (mediana robusta)")
    st.code(" ".join(str(x) for x in ipf_nucleo), language="text")

    st.write("#### IPO ORIGINAL (m√©dia simples)")
    st.code(" ".join(str(x) for x in ipo_orig), language="text")

    st.write("#### IPO ULTRA (refinada anti-sesgo)")
    st.code(" ".join(str(x) for x in ipo_ultra), language="text")

    st.info(
        "Interpreta√ß√£o r√°pida:\n"
        "- **IDX ULTRA** destaca passageiros mais importantes com base em frequ√™ncia + posi√ß√£o (os 'mais vistos').\n"
        "- **IPF ULTRA** representa a estrutura central, resistente a ru√≠dos (mediana por posi√ß√£o).\n"
        "- **IPO ORIGINAL** mostra a fotografia bruta da frequ√™ncia.\n"
        "- **IPO ULTRA** √© a vers√£o refinada, corrigindo vieses do hist√≥rico e refor√ßando o n√∫cleo realmente preditivo."
    )

# (continua na PARTE 3/4)
# ============================================================
# ======================== PARTE 3/4 =========================
# ===== Modo TURBO++ ULTRA, S6 Profundo, Micro-Leque, MC =====
# ============================================================

# ------------------------------------------------------------
# Fun√ß√µes auxiliares ‚Äî colunas de passageiros / s√©ries
# ------------------------------------------------------------
from typing import List, Dict, Any


def extrair_colunas_passageiros(df: pd.DataFrame) -> List[str]:
    """
    Tenta descobrir automaticamente quais colunas s√£o 'passageiros'.

    Regras:
    - Remove claramente identificadores e o k
    - Usa o resto como passageiros (ordem preservada)
    """
    if df is None or df.empty:
        return []

    colunas_excluir = {"k", "K", "id", "ID", "Id", "C", "c", "serie", "SERIE", "label", "LABEL"}
    return [c for c in df.columns if c not in colunas_excluir]


def linha_para_serie(row: pd.Series, cols_pass: List[str]) -> List[int]:
    return [int(row[c]) for c in cols_pass]


def serie_para_str(serie: List[int]) -> str:
    return " ".join(str(x) for x in serie)


def contar_hits(serie_prev: List[int], serie_real: List[int]) -> int:
    alvo = set(serie_real)
    return sum(1 for x in serie_prev if x in alvo)


# ------------------------------------------------------------
# S6 Profundo ULTRA ‚Äî n√∫cleo determin√≠stico
# ------------------------------------------------------------
def s6_profundo_ultra(
    df: pd.DataFrame,
    idx_alvo: int,
    window: int = 80,
    n_series: int = 40,
) -> pd.DataFrame:
    """
    S6 Profundo ULTRA (vers√£o gen√©rica, est√°vel e resiliente):

    - Usa uma janela de hist√≥rico antes do √≠ndice alvo
    - Calcula frequ√™ncia de cada n√∫mero em cada coluna de passageiro
    - Monta s√©ries combinando os mais frequentes por coluna
    """
    if df is None or df.empty:
        return pd.DataFrame()

    cols_pass = extrair_colunas_passageiros(df)
    if not cols_pass:
        return pd.DataFrame()

    # idx_alvo √© 1-based para o usu√°rio
    idx_zero = max(idx_alvo - 1, 0)
    inicio = max(idx_zero - window, 0)
    df_janela = df.iloc[inicio:idx_zero]

    if df_janela.empty:
        return pd.DataFrame()

    # Frequ√™ncia por coluna
    top_por_col = []
    for c in cols_pass:
        vc = df_janela[c].value_counts().reset_index()
        vc.columns = ["valor", "freq"]
        top_por_col.append(vc)

    # Montar candidatos combinando os top valores coluna a coluna
    from itertools import product

    tops_lim = []
    for vc in top_por_col:
        # Ajuste para n√£o explodir combinat√≥ria
        k_max = max(3, min(6, n_series // max(1, len(cols_pass))))
        tops_lim.append(list(vc["valor"].head(k_max)))

    candidatos = []
    for comb in product(*tops_lim):
        candidatos.append(list(map(int, comb)))

    # Scoring simples: soma das frequ√™ncias individuais
    def score_serie(serie: List[int]) -> float:
        s = 0.0
        for i, v in enumerate(serie):
            vc = top_por_col[i]
            freq = vc.loc[vc["valor"] == v, "freq"]
            s += float(freq.iloc[0]) if not freq.empty else 0.0
        return s

    dados = []
    for serie in candidatos:
        dados.append(
            {
                "series": serie,
                "score_s6": score_serie(serie),
                "origem": "S6_PROFUNDO",
            }
        )

    df_out = pd.DataFrame(dados).drop_duplicates(subset=["series"])
    df_out = df_out.sort_values("score_s6", ascending=False).head(n_series).reset_index(drop=True)
    return df_out


# ------------------------------------------------------------
# Micro-Leque ULTRA ‚Äî vizinhan√ßa em torno do alvo
# ------------------------------------------------------------
def micro_leque_ultra(
    df: pd.DataFrame,
    idx_alvo: int,
    n_vizinhos: int = 3,
) -> pd.DataFrame:
    """
    Micro-Leque ULTRA:

    - Usa s√©ries pr√≥ximas (anteriores e posteriores) ao alvo como base
    - Gera pequenas varia√ß√µes em torno delas
    """
    if df is None or df.empty:
        return pd.DataFrame()

    cols_pass = extrair_colunas_passageiros(df)
    if not cols_pass:
        return pd.DataFrame()

    idx_zero = max(idx_alvo - 1, 0)
    n = len(df)

    vizinhos_idx = set()
    for delta in range(1, n_vizinhos + 1):
        if idx_zero - delta >= 0:
            vizinhos_idx.add(idx_zero - delta)
        if idx_zero + delta < n:
            vizinhos_idx.add(idx_zero + delta)

    if not vizinhos_idx:
        return pd.DataFrame()

    base_series = []
    for i in sorted(vizinhos_idx):
        row = df.iloc[i]
        base_series.append(linha_para_serie(row, cols_pass))

    # Pequenas perturba√ß√µes: troca leve entre posi√ß√µes / shuffle
    import random

    candidatos = []
    for serie in base_series:
        candidatos.append(serie)  # original

        # Troca simples
        if len(serie) >= 2:
            s2 = serie.copy()
            i1, i2 = random.sample(range(len(serie)), 2)
            s2[i1], s2[i2] = s2[i2], s2[i1]
            candidatos.append(s2)

        # Shuffle leve
        s3 = serie.copy()
        random.shuffle(s3)
        candidatos.append(s3)

    dados = []
    for serie in candidatos:
        dados.append(
            {
                "series": list(map(int, serie)),
                "score_micro": 1.0,
                "origem": "MICRO_LEQUE",
            }
        )

    df_out = pd.DataFrame(dados).drop_duplicates(subset=["series"])
    return df_out.reset_index(drop=True)


# ------------------------------------------------------------
# Monte Carlo Profundo ULTRA
# ------------------------------------------------------------
def monte_carlo_profundo_ultra(
    df: pd.DataFrame,
    idx_alvo: int,
    n_sim: int = 2000,
    n_series_saida: int = 60,
    window: int = 120,
    random_state: int | None = None,
) -> pd.DataFrame:
    """
    Monte Carlo Profundo ULTRA:

    - Usa janelas profundas para gerar simula√ß√µes independentes
    - Amostra passageiros conforme distribui√ß√£o emp√≠rica por coluna
    """
    if df is None or df.empty or n_sim <= 0:
        return pd.DataFrame()

    cols_pass = extrair_colunas_passageiros(df)
    if not cols_pass:
        return pd.DataFrame()

    idx_zero = max(idx_alvo - 1, 0)
    inicio = max(idx_zero - window, 0)
    df_janela = df.iloc[inicio:idx_zero]

    if df_janela.empty:
        return pd.DataFrame()

    import numpy as np
    import random

    if random_state is not None:
        np.random.seed(random_state)
        random.seed(random_state)

    # Distribui√ß√µes por coluna
    dist_col = {}
    for c in cols_pass:
        valores = df_janela[c].dropna().astype(int).values
        if len(valores) == 0:
            continue
        vals, counts = np.unique(valores, return_counts=True)
        prob = counts / counts.sum()
        dist_col[c] = (vals, prob)

    if not dist_col:
        return pd.DataFrame()

    series_mc = []
    for _ in range(n_sim):
        serie = []
        for c in cols_pass:
            if c not in dist_col:
                # fallback: escolhe qualquer valor da janela
                valores = df_janela[c].dropna().astype(int).values
                if len(valores) == 0:
                    continue
                serie.append(int(random.choice(list(valores))))
            else:
                vals, prob = dist_col[c]
                serie.append(int(np.random.choice(vals, p=prob)))
        if len(serie) == len(cols_pass):
            series_mc.append(serie)

    if not series_mc:
        return pd.DataFrame()

    # Agregar por frequ√™ncia
    from collections import Counter

    contagem = Counter(tuple(s) for s in series_mc)
    dados = []
    for serie_tup, freq in contagem.items():
        dados.append(
            {
                "series": list(map(int, serie_tup)),
                "freq_mc": int(freq),
                "origem": "MONTE_CARLO",
            }
        )

    df_out = pd.DataFrame(dados)
    df_out["score_mc"] = df_out["freq_mc"] / df_out["freq_mc"].max()
    df_out = df_out.sort_values("score_mc", ascending=False).head(n_series_saida).reset_index(drop=True)
    return df_out


# ------------------------------------------------------------
# Fus√£o ULTRA ‚Äî monta Previs√£o TURBO++ final
# ------------------------------------------------------------
def montar_previsao_turbo_ultra(
    df: pd.DataFrame,
    idx_alvo: int,
    n_series_saida: int = 60,
    window_s6: int = 80,
    window_mc: int = 120,
    n_sim_mc: int = 2000,
    incluir_micro_leque: bool = True,
    peso_s6: float = 0.5,
    peso_mc: float = 0.4,
    peso_micro: float = 0.1,
) -> pd.DataFrame:
    """
    N√∫cleo de fus√£o TURBO++ ULTRA:

    Combina:
    - S6 Profundo ULTRA
    - Monte Carlo Profundo ULTRA
    - Micro-Leque ULTRA (opcional)
    """
    if df is None or df.empty:
        return pd.DataFrame()

    # S6
    df_s6 = s6_profundo_ultra(df, idx_alvo, window=window_s6, n_series=n_series_saida * 2)
    if df_s6.empty:
        df_s6 = pd.DataFrame(columns=["series", "score_s6", "origem"])

    # MC
    df_mc = monte_carlo_profundo_ultra(
        df,
        idx_alvo,
        n_sim=n_sim_mc,
        n_series_saida=n_series_saida * 2,
        window=window_mc,
    )
    if df_mc.empty:
        df_mc = pd.DataFrame(columns=["series", "score_mc", "freq_mc", "origem"])

    # Micro-Leque
    if incluir_micro_leque:
        df_micro = micro_leque_ultra(df, idx_alvo)
    else:
        df_micro = pd.DataFrame(columns=["series", "score_micro", "origem"])

    # Normalizar colunas de score
    for col in ["score_s6", "score_mc", "score_micro"]:
        for d in (df_s6, df_mc, df_micro):
            if col in d.columns:
                if d[col].max() > 0:
                    d[col] = d[col] / d[col].max()
                else:
                    d[col] = 0.0

    # Unir
    frames = []
    if not df_s6.empty:
        frames.append(df_s6[["series", "score_s6"]])
    if not df_mc.empty:
        frames.append(df_mc[["series", "score_mc"]])
    if not df_micro.empty:
        frames.append(df_micro[["series", "score_micro"]])

    if not frames:
        return pd.DataFrame()

    df_all = pd.concat(frames, ignore_index=True)
    df_all = df_all.groupby("series", as_index=False).agg(
        {
            "score_s6": "max",
            "score_mc": "max",
            "score_micro": "max",
        }
    )

    for col in ["score_s6", "score_mc", "score_micro"]:
        if col not in df_all.columns:
            df_all[col] = 0.0

    df_all["score_final"] = (
        peso_s6 * df_all["score_s6"].fillna(0.0)
        + peso_mc * df_all["score_mc"].fillna(0.0)
        + peso_micro * df_all["score_micro"].fillna(0.0)
    )

    df_all = df_all.sort_values("score_final", ascending=False).head(n_series_saida).reset_index(drop=True)
    return df_all


# ------------------------------------------------------------
# Painel ‚Äî üöÄ Modo TURBO++ ‚Äî Painel Completo
# ------------------------------------------------------------
if painel == "üöÄ Modo TURBO++ ‚Äî Painel Completo":
    st.markdown("## üöÄ Modo TURBO++ ULTRA Adaptativo ‚Äî Painel Completo")

    df = st.session_state.get("df", None)
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada'.")
        st.stop()

    cols_pass = extrair_colunas_passageiros(df)
    if not cols_pass:
        st.error("N√£o foi poss√≠vel identificar as colunas de passageiros no hist√≥rico.")
        st.stop()

    n_series_hist = len(df)

    col1, col2 = st.columns(2)
    with col1:
        idx_alvo = st.number_input(
            "√çndice alvo (1 = primeira s√©rie do hist√≥rico):",
            min_value=1,
            max_value=n_series_hist,
            value=n_series_hist,
            step=1,
        )
        n_series_saida = st.slider(
            "Quantidade de s√©ries na sa√≠da TURBO++ (n√∫cleo resiliente + cobertura):",
            min_value=10,
            max_value=120,
            value=60,
            step=5,
        )
        incluir_micro = st.checkbox("Incluir Micro-Leque ULTRA (cobertura de vento fina)", value=True)

    with col2:
        window_s6 = st.slider(
            "Janela S6 Profundo ULTRA (n s√©ries para tr√°s):",
            min_value=20,
            max_value=200,
            value=80,
            step=10,
        )
        window_mc = st.slider(
            "Janela Monte Carlo Profundo ULTRA:",
            min_value=40,
            max_value=300,
            value=120,
            step=10,
        )
        n_sim_mc = st.slider(
            "Simula√ß√µes Monte Carlo Profundo ULTRA:",
            min_value=200,
            max_value=5000,
            value=2000,
            step=200,
        )

    st.markdown("### ‚öñÔ∏è Pesos de fus√£o ULTRA (S6 / Monte Carlo / Micro-Leque)")
    colp1, colp2, colp3 = st.columns(3)
    with colp1:
        peso_s6 = st.slider("Peso S6 Profundo", 0.0, 1.0, 0.5, 0.05)
    with colp2:
        peso_mc = st.slider("Peso Monte Carlo", 0.0, 1.0, 0.4, 0.05)
    with colp3:
        peso_micro = st.slider("Peso Micro-Leque", 0.0, 1.0, 0.1, 0.05)

    # Normalizar pesos se a soma n√£o for 1
    soma_pesos = peso_s6 + peso_mc + peso_micro
    if soma_pesos <= 0:
        peso_s6, peso_mc, peso_micro = 0.5, 0.4, 0.1
    else:
        peso_s6 /= soma_pesos
        peso_mc /= soma_pesos
        peso_micro /= soma_pesos

    st.markdown("---")

    rodar = st.button("üöÄ Rodar Modo TURBO++ ULTRA para este √≠ndice alvo")

    if rodar:
        with st.spinner("Rodando S6 Profundo, Micro-Leque e Monte Carlo Profundo ULTRA..."):
            df_turbo = montar_previsao_turbo_ultra(
                df,
                idx_alvo=idx_alvo,
                n_series_saida=n_series_saida,
                window_s6=window_s6,
                window_mc=window_mc,
                n_sim_mc=n_sim_mc,
                incluir_micro_leque=incluir_micro,
                peso_s6=peso_s6,
                peso_mc=peso_mc,
                peso_micro=peso_micro,
            )

        if df_turbo is None or df_turbo.empty:
            st.error("N√£o foi poss√≠vel gerar s√©ries TURBO++ ULTRA para este √≠ndice.")
        else:
            st.session_state["previsao_turbo_ultra"] = df_turbo
            st.session_state["previsao_turbo_ultra_params"] = {
                "idx_alvo": int(idx_alvo),
                "n_series_saida": int(n_series_saida),
                "window_s6": int(window_s6),
                "window_mc": int(window_mc),
                "n_sim_mc": int(n_sim_mc),
                "incluir_micro_leque": bool(incluir_micro),
                "peso_s6": float(peso_s6),
                "peso_mc": float(peso_mc),
                "peso_micro": float(peso_micro),
            }

            # Mostrar s√©rie alvo e contexto
            st.markdown("### üöó S√©rie alvo (carro atual na estrada)")
            row_alvo = df.iloc[int(idx_alvo) - 1]
            serie_alvo = linha_para_serie(row_alvo, cols_pass)
            st.code(serie_para_str(serie_alvo), language="text")

            # Integra√ß√£o com Bar√¥metro / k*
            regime_state = st.session_state.get("regime_state", "normal")
            k_estado = st.session_state.get("k_estado", "estavel")
            k_star_val = st.session_state.get("k_star_val", None)

            contexto_barometro = ""
            if regime_state == "normal":
                contexto_barometro = "üü¢ Bar√¥metro ULTRA REAL: Estrada em regime normal."
            elif regime_state == "transicao":
                contexto_barometro = "üü° Bar√¥metro ULTRA REAL: Regi√£o de transi√ß√£o / pr√©-ruptura."
            else:
                contexto_barometro = "üî¥ Bar√¥metro ULTRA REAL: Regi√£o de turbul√™ncia pesada / p√≥s-ruptura."

            contexto_k = ""
            if k_estado == "estavel":
                contexto_k = "üü¢ k* ULTRA REAL: Ambiente est√°vel ‚Äî guardas convergindo."
            elif k_estado == "atencao":
                contexto_k = "üü° k* ULTRA REAL: Pr√©-ruptura residual ‚Äî aten√ß√£o elevada."
            else:
                contexto_k = "üî¥ k* ULTRA REAL: Ambiente cr√≠tico ‚Äî sensibilidade m√°xima dos guardas."

            if k_star_val is not None:
                contexto_k += f" (k* ‚âà {k_star_val:.1f}%)"

            st.info(contexto_barometro + "\n\n" + contexto_k)

            # Tabela completa
            st.markdown("### üìä Leque TURBO++ ULTRA ‚Äî N√∫cleo Resiliente + Cobertura")
            df_view = df_turbo.copy()
            df_view["series_str"] = df_view["series"].apply(serie_para_str)
            st.dataframe(
                df_view[["series_str", "score_final", "score_s6", "score_mc", "score_micro"]].rename(
                    columns={
                        "series_str": "S√©rie (passageiros)",
                        "score_final": "Score ULTRA",
                        "score_s6": "Score S6",
                        "score_mc": "Score Monte Carlo",
                        "score_micro": "Score Micro-Leque",
                    }
                ),
                use_container_width=True,
            )

            # Previs√£o final
            melhor = df_turbo.iloc[0]
            st.markdown("### üéØ Previs√£o Final TURBO++ ULTRA (S√©rie #1 do N√∫cleo Resiliente)")
            st.code(serie_para_str(melhor["series"]), language="text")

# ============================================================
# ====================== FIM DA PARTE 3/4 ====================
# ============================================================


# ============================================================
# ======================== PARTE 4/4 =========================
# ===== Replay LIGHT / ULTRA, QDS REAL, Backtest REAL ========
# ============================================================

# ------------------------------------------------------------
# Fun√ß√µes auxiliares ‚Äî Replay e QDS REAL
# ------------------------------------------------------------
def executar_pipeline_turbo_ultra_para_replay(
    df: pd.DataFrame,
    idx_alvo: int,
    params_base: Dict[str, Any],
    modo_replay: str = "LIGHT",
) -> Dict[str, Any]:
    """
    Wrapper para usar o mesmo n√∫cleo TURBO++ ULTRA no Replay.

    - LIGHT: menos simula√ß√µes Monte Carlo / janelas menores
    - ULTRA: usa par√¢metros cheios ou at√© refor√ßados
    """
    # Clona par√¢metros
    params = dict(params_base or {})

    # Defaults se nada foi rodado ainda
    if not params:
        params = {
            "n_series_saida": 60,
            "window_s6": 80,
            "window_mc": 120,
            "n_sim_mc": 2000,
            "incluir_micro_leque": True,
            "peso_s6": 0.5,
            "peso_mc": 0.4,
            "peso_micro": 0.1,
        }

    if modo_replay == "LIGHT":
        params["n_series_saida"] = min(30, params["n_series_saida"])
        params["window_s6"] = max(40, int(params["window_s6"] * 0.6))
        params["window_mc"] = max(60, int(params["window_mc"] * 0.6))
        params["n_sim_mc"] = max(300, int(params["n_sim_mc"] * 0.3))
    else:  # ULTRA
        params["n_series_saida"] = max(60, params["n_series_saida"])
        params["n_sim_mc"] = max(1500, int(params["n_sim_mc"] * 1.0))

    df_turbo = montar_previsao_turbo_ultra(
        df,
        idx_alvo=idx_alvo,
        n_series_saida=params["n_series_saida"],
        window_s6=params["window_s6"],
        window_mc=params["window_mc"],
        n_sim_mc=params["n_sim_mc"],
        incluir_micro_leque=params["incluir_micro_leque"],
        peso_s6=params["peso_s6"],
        peso_mc=params["peso_mc"],
        peso_micro=params["peso_micro"],
    )

    if df_turbo is None or df_turbo.empty:
        return {"ok": False, "df": pd.DataFrame(), "serie_top1": None}

    top1 = df_turbo.iloc[0]["series"]
    return {"ok": True, "df": df_turbo, "serie_top1": top1}


def calcular_qds_real(aus_replay: pd.DataFrame) -> Dict[str, Any]:
    """
    Calcula QDS REAL a partir da tabela de replay:

    Espera colunas:
    - hits (n√∫mero de acertos)
    - idx_alvo
    """
    if aus_replay is None or aus_replay.empty:
        return {
            "qds": 0.0,
            "media_hits": 0.0,
            "p_ge_1": 0.0,
            "p_ge_3": 0.0,
            "p_ge_4": 0.0,
            "n": 0,
        }

    n = len(aus_replay)
    media_hits = float(aus_replay["hits"].mean())

    p_ge_1 = float((aus_replay["hits"] >= 1).mean())
    p_ge_3 = float((aus_replay["hits"] >= 3).mean())
    p_ge_4 = float((aus_replay["hits"] >= 4).mean())

    # QDS REAL (0‚Äì100) ‚Äî pondera√ß√£o simples
    qds = 100.0 * (0.25 * p_ge_1 + 0.35 * p_ge_3 + 0.40 * p_ge_4)

    return {
        "qds": qds,
        "media_hits": media_hits,
        "p_ge_1": p_ge_1,
        "p_ge_3": p_ge_3,
        "p_ge_4": p_ge_4,
        "n": n,
    }


# ------------------------------------------------------------
# Painel ‚Äî üìÖ Modo Replay Autom√°tico do Hist√≥rico
# ------------------------------------------------------------
if painel == "üìÖ Modo Replay Autom√°tico do Hist√≥rico":
    st.markdown("## üìÖ Modo Replay Autom√°tico do Hist√≥rico")

    df = st.session_state.get("df", None)
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada'.")
        st.stop()

    cols_pass = extrair_colunas_passageiros(df)
    if not cols_pass:
        st.error("N√£o foi poss√≠vel identificar as colunas de passageiros no hist√≥rico.")
        st.stop()

    n_series_hist = len(df)

    st.markdown("### üé¨ Configura√ß√£o do Replay (LIGHT / ULTRA)")

    col1, col2 = st.columns(2)
    with col1:
        idx_inicio = st.number_input(
            "√çndice inicial do Replay:",
            min_value=1,
            max_value=max(1, n_series_hist - 1),
            value=max(1, n_series_hist - 60),
            step=1,
        )
        idx_fim = st.number_input(
            "√çndice final do Replay:",
            min_value=idx_inicio,
            max_value=max(1, n_series_hist - 1),
            value=max(1, n_series_hist - 1),
            step=1,
        )
        horizonte = st.number_input(
            "Horizonte de valida√ß√£o (quantas s√©ries √† frente comparar):",
            min_value=1,
            max_value=5,
            value=1,
            step=1,
        )

    with col2:
        modo_replay = st.radio(
            "Modo de Replay:",
            options=["LIGHT (r√°pido)", "ULTRA (profundo)"],
        )
        usar_params_turbo = st.checkbox(
            "Usar par√¢metros atuais do Modo TURBO++ ULTRA (se j√° rodou)",
            value=True,
        )
        mostrar_detalhes = st.checkbox("Mostrar tabela completa de resultados do Replay", value=True)

    params_base = st.session_state.get("previsao_turbo_ultra_params", {})
    if not usar_params_turbo:
        params_base = {}

    st.markdown("---")
    rodar_replay = st.button("üìÖ Rodar Replay Autom√°tico do Hist√≥rico")

    if rodar_replay:
        registros = []
        modo_interno = "LIGHT" if modo_replay.startswith("LIGHT") else "ULTRA"

        with st.spinner("Executando Replay do hist√≥rico com o n√∫cleo TURBO++ ULTRA..."):
            for idx in range(int(idx_inicio), int(idx_fim) + 1):
                idx_real = idx + int(horizonte)
                if idx_real > n_series_hist:
                    # N√£o h√° s√©rie real para comparar
                    continue

                res = executar_pipeline_turbo_ultra_para_replay(
                    df,
                    idx_alvo=idx,
                    params_base=params_base,
                    modo_replay=modo_interno,
                )

                if not res["ok"] or res["serie_top1"] is None:
                    continue

                serie_prev = list(map(int, res["serie_top1"]))
                row_real = df.iloc[idx_real - 1]
                serie_real = linha_para_serie(row_real, cols_pass)

                h = contar_hits(serie_prev, serie_real)

                registros.append(
                    {
                        "idx_alvo": int(idx),
                        "idx_real": int(idx_real),
                        "serie_prevista": serie_para_str(serie_prev),
                        "serie_real": serie_para_str(serie_real),
                        "hits": int(h),
                        "modo": modo_interno,
                    }
                )

        if not registros:
            st.error("Replay n√£o gerou resultados v√°lidos (verifique janelas e horizonte).")
        else:
            df_replay = pd.DataFrame(registros).sort_values("idx_alvo").reset_index(drop=True)
            st.session_state["df_replay"] = df_replay

            st.markdown("### üìä Resumo do Replay")
            st.write(f"N execu√ß√µes v√°lidas: **{len(df_replay)}**")

            colm1, colm2, colm3 = st.columns(3)
            with colm1:
                st.metric("M√©dia de hits (passageiros por carro)", f"{df_replay['hits'].mean():.2f}")
            with colm2:
                st.metric("Execu√ß√µes com ‚â• 3 hits", f"{(df_replay['hits'] >= 3).sum()} / {len(df_replay)}")
            with colm3:
                st.metric("Execu√ß√µes com ‚â• 4 hits", f"{(df_replay['hits'] >= 4).sum()} / {len(df_replay)}")

            if mostrar_detalhes:
                st.markdown("### üßæ Detalhamento do Replay (carro a carro)")
                st.dataframe(
                    df_replay[
                        [
                            "idx_alvo",
                            "idx_real",
                            "serie_prevista",
                            "serie_real",
                            "hits",
                            "modo",
                        ]
                    ],
                    use_container_width=True,
                )

# ------------------------------------------------------------
# Painel ‚Äî üß™ Testes de Confiabilidade (QDS / Backtest / Monte Carlo)
# ------------------------------------------------------------
if painel == "üß™ Testes de Confiabilidade (QDS / Backtest / Monte Carlo)":
    st.markdown("## üß™ Testes de Confiabilidade ‚Äî QDS REAL + Backtest REAL")

    df = st.session_state.get("df", None)
    if df is None or df.empty:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada'.")
        st.stop()

    df_replay = st.session_state.get("df_replay", None)

    if df_replay is None or df_replay.empty:
        st.info(
            "Ainda n√£o h√° resultados de Replay salvos.\n\n"
            "Use primeiro o painel **'üìÖ Modo Replay Autom√°tico do Hist√≥rico'** "
            "para gerar a base emp√≠rica de valida√ß√£o (Backtest REAL)."
        )
        st.stop()

    st.markdown("### ‚úÖ QDS REAL ‚Äî √çndice de Qualidade Din√¢mica da S√©rie (0‚Äì100)")

    resultados_qds = calcular_qds_real(df_replay)

    colq1, colq2, colq3 = st.columns(3)
    with colq1:
        st.metric("QDS REAL (0‚Äì100)", f"{resultados_qds['qds']:.1f}")
    with colq2:
        st.metric("M√©dia de hits", f"{resultados_qds['media_hits']:.2f}")
    with colq3:
        st.metric("N execu√ß√µes", f"{resultados_qds['n']}")

    st.markdown("### üìä Distribui√ß√£o de hits por carro (Backtest REAL)")

    # Histograma simples usando value_counts
    dist_hits = df_replay["hits"].value_counts().sort_index()
    df_dist = dist_hits.reset_index()
    df_dist.columns = ["hits", "frequencia"]

    st.bar_chart(df_dist.set_index("hits"))

    colp1, colp2, colp3 = st.columns(3)
    with colp1:
        st.metric("P(hits ‚â• 1)", f"{100 * resultados_qds['p_ge_1']:.1f}%")
    with colp2:
        st.metric("P(hits ‚â• 3)", f"{100 * resultados_qds['p_ge_3']:.1f}%")
    with colp3:
        st.metric("P(hits ‚â• 4)", f"{100 * resultados_qds['p_ge_4']:.1f}%")

    st.markdown("---")
    st.markdown("### üîç Amostra do Backtest REAL (primeiros carros do Replay)")
    st.dataframe(
        df_replay.head(50)[["idx_alvo", "idx_real", "serie_prevista", "serie_real", "hits", "modo"]],
        use_container_width=True,
    )

    st.markdown(
        """
**Leitura operacional (QDS REAL + Backtest REAL + Monte Carlo Profundo ULTRA)**

- O **QDS REAL** sintetiza a qualidade din√¢mica da estrada a partir do que o sistema realmente teria feito
  nos carros do passado (Replay), usando exatamente o mesmo n√∫cleo TURBO++ ULTRA.
- A distribui√ß√£o de **hits por carro** mostra qu√£o frequentemente a previs√£o encosta em 1, 3, 4 ou mais passageiros.
- A integra√ß√£o com o **Monte Carlo Profundo ULTRA** j√° est√° embutida no pr√≥prio n√∫cleo de previs√£o usado no Replay,
  o que significa que o backtest j√° incorpora o regime estoc√°stico real da estrada.
"""
    )

# ============================================================
# ====================== FIM DA PARTE 4/4 ====================
# ============================================================
