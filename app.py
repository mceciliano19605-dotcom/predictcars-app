# =========================================================
# PREDICT CARS V13.8-TURBO ‚Äî app.py CONSOLIDADO
# Vers√£o completa (BLOCOS 1 a 14 integrados)
# =========================================================

from __future__ import annotations

import io
import json
import zipfile
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# =========================================================
# CONFIGURA√á√ÉO GLOBAL DO APP
# =========================================================

st.set_page_config(
    page_title="Predict Cars V13.8-TURBO",
    page_icon="üöó",
    layout="wide",
)

# =========================================================
# TIPOS B√ÅSICOS
# =========================================================

@dataclass
class RegimeState:
    nome: str
    dispersao: float
    amplitude: float
    vibracao: float
    pares: List[Tuple[int, int]]


# =========================================================
# FUN√á√ïES B√ÅSICAS ‚Äî PARSING DO HIST√ìRICO
# =========================================================

def parse_line_to_series(line: str) -> Optional[List[int]]:
    """
    Converte uma linha do arquivo em lista de inteiros.
    Aceita formatos:
    - C1234; n1; n2; n3; n4; n5; k
    - n1; n2; n3; n4; n5; k
    - n1 n2 n3 n4 n5 k
    """
    if not line.strip():
        return None

    # Troca v√≠rgulas por ponto e v√≠rgula, normaliza separadores
    line = line.replace(",", ";").replace("\t", ";")
    # Se n√£o houver ';', tenta separar por espa√ßo
    if ";" not in line:
        parts = line.split()
    else:
        parts = [p.strip() for p in line.split(";") if p.strip()]

    if not parts:
        return None

    # Ignora prefixos tipo 'C1234'
    if parts[0].upper().startswith("C") and len(parts) > 1:
        parts = parts[1:]

    # Espera pelo menos 6 n√∫meros (5+1 ou 6+1, etc.)
    nums = []
    for p in parts:
        try:
            nums.append(int(p))
        except ValueError:
            # ignora tokens n√£o num√©ricos
            continue

    if len(nums) < 6:
        return None

    # Considera sempre os 6 primeiros como passageiros, o √∫ltimo como k
    # Se houver mais de 7 colunas, corta.
    return nums[:7]


def history_to_dataframe(text: str) -> pd.DataFrame:
    """
    Converte texto bruto em DataFrame no formato interno:
    colunas: n1..n6, k
    Sem √≠ndice Cxxxx (n√£o √© necess√°rio para o app).
    """
    linhas = text.splitlines()
    registros = []

    for line in linhas:
        serie = parse_line_to_series(line)
        if serie is None:
            continue
        # se vier exatamente 6, assume k = 0
        if len(serie) == 6:
            serie.append(0)
        # garante tamanho 7
        if len(serie) > 7:
            serie = serie[:7]
        registros.append(serie)

    if not registros:
        return pd.DataFrame(columns=["n1", "n2", "n3", "n4", "n5", "n6", "k"])

    df = pd.DataFrame(
        registros,
        columns=["n1", "n2", "n3", "n4", "n5", "n6", "k"],
    )
    return df


# =========================================================
# FUN√á√ïES B√ÅSICAS ‚Äî ESTADO DA ESTRADA (REGIME)
# =========================================================

def calcular_regime(df: pd.DataFrame) -> Optional[RegimeState]:
    """
    Estima o regime atual com base nas √∫ltimas linhas do hist√≥rico.
    Heur√≠stica simplificada:
    - dispers√£o m√©dia
    - amplitude m√©dia
    - vibra√ß√£o (varia√ß√£o da dispers√£o)
    - pares frequentes nas √∫ltimas linhas
    """
    if df is None or df.empty:
        return None

    # Considera um trecho recente (ex.: √∫ltimas 80 linhas ou menos)
    trecho = df.tail(min(80, len(df)))
    numeros = trecho[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    dispersoes = np.std(numeros, axis=1)
    amplitudes = np.max(numeros, axis=1) - np.min(numeros, axis=1)
    vib = np.abs(np.diff(dispersoes)).mean() if len(dispersoes) > 1 else 0.0

    disp_med = float(np.mean(dispersoes))
    amp_med = float(np.mean(amplitudes))

    # Gera√ß√£o simples de pares
    contagem_pares: Dict[Tuple[int, int], int] = {}
    for linha in numeros:
        linha_ordenada = sorted(set(linha.tolist()))
        for i in range(len(linha_ordenada)):
            for j in range(i + 1, len(linha_ordenada)):
                par = (linha_ordenada[i], linha_ordenada[j])
                contagem_pares[par] = contagem_pares.get(par, 0) + 1

    pares_ativos = sorted(
        contagem_pares.items(),
        key=lambda x: x[1],
        reverse=True,
    )[:10]
    pares_ativos = [p[0] for p in pares_ativos]

    # Regra simples para nome do regime
    if disp_med < 10 and amp_med < 25 and vib < 3:
        nome = "Resiliente"
    elif disp_med < 16 and amp_med < 35:
        nome = "Intermedi√°rio"
    else:
        nome = "Turbulento"

    return RegimeState(
        nome=nome,
        dispersao=disp_med,
        amplitude=amp_med,
        vibracao=float(vib),
        pares=pares_ativos,
    )


# =========================================================
# INICIALIZA√á√ÉO DE ESTADO (session_state)
# =========================================================

def ensure_session_defaults():
    """
    Garante chaves b√°sicas no session_state.
    """
    defaults = {
        "df": pd.DataFrame(),
        "regime_state": None,
        "idx_result": pd.DataFrame(),
        "nucleo_ipf": None,
        "nucleo_ipo": None,
        "ajustes_log": [],
        "dependencias": None,
        "s6_df": pd.DataFrame(),
        "mc_df": pd.DataFrame(),
        "backtest_interno": pd.DataFrame(),
        "btf_raw": pd.DataFrame(),
        "leque_turbo": {},
        "logs_tecnicos": [],
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


ensure_session_defaults()

# =========================================================
# LAYOUT PRINCIPAL ‚Äî CABE√áALHO E ENTRADA DE HIST√ìRICO
# =========================================================

st.title("üöó Predict Cars V13.8-TURBO")
st.caption("Modo Ultra-H√≠brido TURBO ‚Äî N√∫cleo Resiliente + Leque Estrutural + Backtest do Futuro")

st.markdown("### üì• Entrada de Hist√≥rico")

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader(
        "Carregar arquivo de hist√≥rico (.txt ou .csv)",
        type=["txt", "csv"],
    )

with col2:
    text_input = st.text_area(
        "Ou colar o hist√≥rico aqui (linhas com 6 passageiros + k)",
        height=200,
    )

df: pd.DataFrame

if uploaded_file is not None:
    raw_bytes = uploaded_file.read()
    raw_text = raw_bytes.decode("utf-8", errors="ignore")
    df = history_to_dataframe(raw_text)
    st.session_state["df"] = df
elif text_input.strip():
    df = history_to_dataframe(text_input)
    st.session_state["df"] = df
else:
    df = st.session_state.get("df", pd.DataFrame())

if df is not None and not df.empty:
    st.success(f"Hist√≥rico carregado com {len(df)} s√©ries.")
    st.dataframe(df.tail(10), use_container_width=True)
else:
    st.info("Nenhum hist√≥rico v√°lido carregado ainda.")

# =========================================================
# C√ÅLCULO DO ESTADO DA ESTRADA (REGIME)
# =========================================================

if not df.empty:
    regime_state = calcular_regime(df)
    st.session_state["regime_state"] = regime_state
else:
    regime_state = None

# =========================================================
# CONTROLES GERAIS (SIDEBAR)
# =========================================================

st.sidebar.markdown("## ‚öôÔ∏è Controles Gerais")

# Modo de gera√ß√£o do leque final
output_mode = st.sidebar.radio(
    "Modo de gera√ß√£o do Leque:",
    options=[
        "Autom√°tico (por regime)",
        "Quantidade fixa",
        "Confiabilidade m√≠nima",
    ],
    index=0,
)

n_series_fixed = st.sidebar.slider(
    "Quantidade total de s√©ries (se modo for 'Quantidade fixa')",
    min_value=5,
    max_value=25,
    value=12,
)

min_conf_pct = st.sidebar.slider(
    "Confiabilidade m√≠nima (%) (se modo for 'Confiabilidade m√≠nima')",
    min_value=30,
    max_value=85,
    value=55,
)

# =========================================================
# MENU DE NAVEGA√á√ÉO (PAIN√âIS PRINCIPAIS)
# =========================================================

st.sidebar.markdown("## üìÇ Navega√ß√£o")

painel = st.sidebar.radio(
    "Escolha o painel:",
    [
        "Hist√≥rico",
        "Estado Atual",
        "IDX Avan√ßado",
        "N√∫cleo IPF / IPO",
        "Ajustes (ASB / ADN / ICA / HLA)",
        "Depend√™ncias Ocultas",
        "S6 Profundo",
        "Monte Carlo Profundo",
        "Backtest Interno",
        "Backtest do Futuro",
        "Leque TURBO",
        "Sa√≠da Final Controlada",
        "Logs T√©cnicos",
        "Diagn√≥stico Profundo",
        "Exportar Resultados",
        "Exportar Sess√£o Completa",
    ],
    index=0,
)

# A partir da PARTE 2/7, cada painel ser√° implementado
# com base na vari√°vel `painel` e no DataFrame `df`.
# =========================================================
# PAINEL: HIST√ìRICO
# =========================================================

if painel == "Hist√≥rico":
    st.markdown("## üìú Hist√≥rico Carregado")
    if df.empty:
        st.warning("Nenhum hist√≥rico carregado.")
    else:
        st.dataframe(df, use_container_width=True)
        st.markdown("### üîç √öltimas 15 s√©ries")
        st.dataframe(df.tail(15), use_container_width=True)
    st.stop()

# =========================================================
# PAINEL: ESTADO ATUAL (REGIME)
# =========================================================

if painel == "Estado Atual":
    st.markdown("## üå°Ô∏è Estado da Estrada (Regime)")
    if regime_state is None:
        st.warning("Regime n√£o p√¥de ser calculado ‚Äî carregue hist√≥rico v√°lido.")
        st.stop()

    st.subheader("Resumo do Regime Atual")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Regime", regime_state.nome)
    c2.metric("Dispers√£o", f"{regime_state.dispersao:.2f}")
    c3.metric("Amplitude", f"{regime_state.amplitude:.2f}")
    c4.metric("Vibra√ß√£o", f"{regime_state.vibracao:.2f}")

    st.markdown("### üîó Pares Ativos (mais frequentes recentemente)")
    pares_df = pd.DataFrame(regime_state.pares, columns=["p1", "p2"])
    st.dataframe(pares_df, use_container_width=True)

    st.stop()

# =========================================================
# M√ìDULO IDX AVAN√áADO ‚Äî SIMILARIDADE E N√öCLEOS INICIAIS
# =========================================================

def calcular_similaridade(linha_a: np.ndarray, linha_b: np.ndarray) -> float:
    """
    Similaridade simples entre duas s√©ries:
    - 1 / (1 + soma das dist√¢ncias absolutas)
    Quanto maior, mais parecido.
    """
    return 1.0 / (1.0 + np.sum(np.abs(linha_a - linha_b)))


def executar_idx_avancado(df: pd.DataFrame, n_top: int = 40) -> pd.DataFrame:
    """
    Identifica as s√©ries historicamente mais parecidas com a √∫ltima s√©rie.
    Retorna DataFrame com:
    - √≠ndice original
    - similaridade
    - n1..n6
    """
    if df.empty:
        return pd.DataFrame()

    ultima = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values[-1]
    similares = []

    for idx in range(len(df) - 1):
        atual = df.iloc[idx][["n1", "n2", "n3", "n4", "n5", "n6"]].values
        sim = calcular_similaridade(ultima, atual)
        similares.append(
            (idx, sim) + tuple(df.iloc[idx][["n1", "n2", "n3", "n4", "n5", "n6"]].values)
        )

    cols = ["idx", "similaridade", "n1", "n2", "n3", "n4", "n5", "n6"]
    df_sim = pd.DataFrame(similares, columns=cols)
    df_sim = df_sim.sort_values("similaridade", ascending=False).head(n_top)

    return df_sim


# =========================================================
# M√ìDULOS IPF / IPO B√ÅSICOS (primeira camada)
# =========================================================

def extrair_ipf(df_idx: pd.DataFrame) -> Optional[List[int]]:
    """
    IPF (IDX Puro Focado simplificado):
    Extrai n√∫cleo como m√©dia ponderada dos top-idx por similaridade.
    """
    if df_idx.empty:
        return None

    pesos = df_idx["similaridade"].values
    nums = df_idx[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    media = np.average(nums, weights=pesos, axis=0)
    nucleo = [int(round(x)) for x in media]
    # Garante n√∫meros distintos
    nucleo = list(sorted(set(nucleo)))
    while len(nucleo) < 6:
        nucleo.append(nucleo[-1] + 1)
    return nucleo[:6]


def aplicar_ipo_profundo(nucleo: List[int], regime: RegimeState) -> List[int]:
    """
    IPO Profundo simplificado:
    - Ajusta faixa dominante;
    - Suaviza extremos incoerentes com regime;
    - Garante coer√™ncia estrutural m√≠nima.
    """
    if nucleo is None:
        return []

    ordenado = sorted(nucleo)
    faixas = np.array(ordenado)

    # Ajuste leve conforme regime
    if regime.nome == "Resiliente":
        faixas = np.clip(faixas, 1, 70)
    elif regime.nome == "Intermedi√°rio":
        faixas = np.clip(faixas, 5, 75)
    else:  # Turbulento
        faixas = np.clip(faixas, 10, 80)

    return sorted(set(int(x) for x in faixas))[:6]


# =========================================================
# PAINEL: IDX AVAN√áADO
# =========================================================

if painel == "IDX Avan√ßado":
    st.markdown("## üîé IDX Avan√ßado")
    if df.empty:
        st.warning("Nenhum hist√≥rico carregado.")
        st.stop()

    df_idx = executar_idx_avancado(df)
    st.session_state["idx_result"] = df_idx

    st.markdown("### Top s√©ries similares (IDX)")
    st.dataframe(df_idx, use_container_width=True)

    st.stop()
# =========================================================
# FUN√á√ïES DE AJUSTE (ASB / ADN / ICA / HLA)
# =========================================================

def aplicar_asb_antibias(nucleo: List[int], regime: RegimeState) -> List[int]:
    """
    ASB ‚Äî Anti-SelfBias simplificado:
    - Permite repeti√ß√£o somente quando coerente com o regime;
    - Evita compress√£o artificial de faixa.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    # Evita compress√£o artificial
    diffs = np.diff(base)
    if np.any(diffs < 2):
        base = [base[0]] + [base[i] + 2 for i in range(1, len(base))]

    # Regras por regime
    if regime.nome == "Resiliente":
        return base  # repeti√ß√£o natural √© permitida
    elif regime.nome == "Intermedi√°rio":
        # leve expans√£o
        return [min(80, x + 1) for x in base]
    else:
        # turbul√™ncia ‚Üí evitar repeti√ß√µes e zonas muito estreitas
        return sorted(set([min(80, x + 2) for x in base]))[:6]


def aplicar_adn(nucleo: List[int], modo: str = "leve") -> List[int]:
    """
    ADN (Ajuste Din√¢mico):
    - leve ‚Üí corrige ru√≠dos sem alterar ess√™ncia
    - m√©dio ‚Üí substitui elementos fracos
    - profundo ‚Üí reavalia microestruturas (simplificado)
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    if modo == "leve":
        return base

    if modo == "m√©dio":
        # substitui o menor elemento por +1
        base[0] = min(80, base[0] + 1)
        return sorted(base)

    if modo == "profundo":
        # desloca todo o n√∫cleo para a faixa seguinte
        return sorted([min(80, x + 2) for x in base])

    return base


def aplicar_ica_profundo(nucleo: List[int]) -> List[int]:
    """
    ICA Profundo (Iterative Core Adjustment):
    - refor√ßa coer√™ncia entre posi√ß√µes adjacentes;
    - evita saltos incoerentes.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    for i in range(1, len(base)):
        if base[i] - base[i - 1] > 15:
            base[i] = base[i - 1] + 10

    return sorted(set(base))[:6]


def aplicar_hla_profundo(nucleo: List[int]) -> List[int]:
    """
    HLA Profundo:
    - poda incoer√™ncias de dispers√£o;
    - reequilibra extremos.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    # for√ßa extremos a serem coerentes
    if base[-1] - base[0] > 60:
        base[-1] = base[0] + 45

    return sorted(set(base))[:6]


# =========================================================
# PIPELINE COMPLETO DO N√öCLEO (IPF + IPO + ASB + ADN + ICA + HLA)
# =========================================================

def gerar_nucleo_resiliente(df: pd.DataFrame, regime: RegimeState) -> List[int]:
    """
    Pipeline resumido para gerar o N√∫cleo Resiliente completo.
    """
    if df.empty:
        return []

    # Etapa 1: IDX
    df_idx = executar_idx_avancado(df)
    ipf = extrair_ipf(df_idx)
    if ipf is None:
        return []

    # Etapa 2: IPO
    ipo = aplicar_ipo_profundo(ipf, regime)

    # Etapa 3: ASB (Anti-SelfBias)
    asb = aplicar_asb_antibias(ipo, regime)

    # Etapa 4: ADN (modo m√©dio por padr√£o)
    adn = aplicar_adn(asb, modo="m√©dio")

    # Etapa 5: ICA / HLA
    ica = aplicar_ica_profundo(adn)
    hla = aplicar_hla_profundo(ica)

    return sorted(set(hla))[:6]


# =========================================================
# PAINEL: N√öCLEO IPF / IPO
# =========================================================

if painel == "N√∫cleo IPF / IPO":
    st.markdown("## üß¨ N√∫cleo IPF / IPO")
    if df.empty:
        st.warning("Carregue um hist√≥rico v√°lido.")
        st.stop()

    df_idx = st.session_state.get("idx_result", executar_idx_avancado(df))
    ipf = extrair_ipf(df_idx)
    ipo = aplicar_ipo_profundo(ipf, regime_state)

    st.session_state["nucleo_ipf"] = ipf
    st.session_state["nucleo_ipo"] = ipo

    st.markdown("### üîπ N√∫cleo IPF (puro focado)")
    st.write(ipf)

    st.markdown("### üîπ N√∫cleo IPO (otimizado)")
    st.write(ipo)

    st.stop()


# =========================================================
# PAINEL: AJUSTES (ASB / ADN / ICA / HLA)
# =========================================================

if painel == "Ajustes (ASB / ADN / ICA / HLA)":
    st.markdown("## üîß Ajustes do N√∫cleo (ASB, ADN, ICA, HLA)")

    if df.empty:
        st.warning("Carregue um hist√≥rico antes de visualizar ajustes.")
        st.stop()

    # Etapas
    df_idx = st.session_state.get("idx_result", executar_idx_avancado(df))
    ipf = extrair_ipf(df_idx)
    ipo = aplicar_ipo_profundo(ipf, regime_state)

    asb = aplicar_asb_antibias(ipo, regime_state)
    adn = aplicar_adn(asb, modo="m√©dio")
    ica = aplicar_ica_profundo(adn)
    hla = aplicar_hla_profundo(ica)

    st.markdown("### üîπ IPF ‚Üí IPO ‚Üí ASB ‚Üí ADN ‚Üí ICA ‚Üí HLA")
    st.write({
        "IPF": ipf,
        "IPO": ipo,
        "ASB": asb,
        "ADN (m√©dio)": adn,
        "ICA": ica,
        "HLA": hla,
    })

    st.stop()
# =========================================================
# DEPEND√äNCIAS OCULTAS
# =========================================================

def calcular_dependencias_ocultas(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Depend√™ncias ocultas (vers√£o simplificada):
    - pares naturais
    - pares ocultos
    - pesos leves / m√©dios / pesados
    - vibra√ß√£o hist√≥rica
    """
    if df.empty:
        return {}

    numeros = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    # Contagem simples de pares
    contagem: Dict[Tuple[int, int], int] = {}
    for linha in numeros:
        linha_ord = sorted(set(linha.tolist()))
        for i in range(len(linha_ord)):
            for j in range(i + 1, len(linha_ord)):
                par = (linha_ord[i], linha_ord[j])
                contagem[par] = contagem.get(par, 0) + 1

    pares_ordenados = sorted(contagem.items(), key=lambda x: x[1], reverse=True)
    naturais = pares_ordenados[:15]
    ocultos = pares_ordenados[15:40]

    # vibra√ß√£o hist√≥rica simples
    dispersoes = np.std(numeros, axis=1)
    vibracao = float(np.mean(np.abs(np.diff(dispersoes)))) if len(dispersoes) > 1 else 0.0

    dependencias = {
        "pares_naturais": naturais,
        "pares_ocultos": ocultos,
        "vibracao": vibracao,
    }

    return dependencias


# =========================================================
# PAINEL: DEPEND√äNCIAS OCULTAS
# =========================================================

if painel == "Depend√™ncias Ocultas":
    st.markdown("## üß© Depend√™ncias Ocultas")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    dep = calcular_dependencias_ocultas(df)
    st.session_state["dependencias"] = dep

    st.markdown("### üî∏ Pares Naturais")
    df_nat = pd.DataFrame(dep["pares_naturais"], columns=["par", "freq"])
    st.dataframe(df_nat, use_container_width=True)

    st.markdown("### üî∏ Pares Ocultos")
    df_oc = pd.DataFrame(dep["pares_ocultos"], columns=["par", "freq"])
    st.dataframe(df_oc, use_container_width=True)

    st.markdown("### üî∏ Vibra√ß√£o Hist√≥rica")
    st.write(dep["vibracao"])

    st.stop()


# =========================================================
# M√ìDULO S6 ‚Äî MODOS DE 6 ACERTOS PROFUNDO
# =========================================================

def gerar_s6_profundo(df: pd.DataFrame, nucleo: List[int], regime: RegimeState) -> pd.DataFrame:
    """
    S6 Profundo simplificado:
    - gera s√©ries vizinhas do n√∫cleo
    - usa microperturba√ß√µes coerentes com o regime
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    base = sorted(nucleo)
    candidatos = []

    for desloc in [-3, -2, -1, 1, 2, 3]:
        nova = [min(80, max(1, x + desloc)) for x in base]
        nova = sorted(set(nova))[:6]
        candidatos.append(nova)

    linhas = []
    for idx, serie in enumerate(candidatos):
        linhas.append([idx] + serie)

    cols = ["id", "n1", "n2", "n3", "n4", "n5", "n6"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: S6 PROFUNDO
# =========================================================

if painel == "S6 Profundo":
    st.markdown("## üéØ S6 Profundo ‚Äî Zonas de Converg√™ncia")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    s6 = gerar_s6_profundo(df, nucleo, regime_state)

    st.session_state["s6_df"] = s6

    st.markdown("### üîπ N√∫cleo Resiliente")
    st.write(nucleo)

    st.markdown("### üîπ S√©ries S6 Geradas")
    st.dataframe(s6, use_container_width=True)

    st.stop()


# =========================================================
# M√ìDULO MONTE CARLO PROFUNDO
# =========================================================

def gerar_monte_carlo(df: pd.DataFrame, nucleo: List[int], regime: RegimeState, n_sim=50) -> pd.DataFrame:
    """
    Monte Carlo Profundo:
    - perturba o n√∫cleo de forma leve
    - gera varia√ß√µes coerentes com a estrada
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    linhas = []
    for i in range(n_sim):
        var = []
        for x in nucleo:
            ruido = np.random.randint(-2, 3)
            novo = min(80, max(1, x + ruido))
            var.append(novo)
        var = sorted(set(var))[:6]
        linhas.append([i] + var)

    cols = ["sim_id", "n1", "n2", "n3", "n4", "n5", "n6"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: MONTE CARLO PROFUNDO
# =========================================================

if painel == "Monte Carlo Profundo":
    st.markdown("## üé≤ Monte Carlo Profundo")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    mc = gerar_monte_carlo(df, nucleo, regime_state, n_sim=80)

    st.session_state["mc_df"] = mc

    st.markdown("### üîπ N√∫cleo Resiliente Usado")
    st.write(nucleo)

    st.markdown("### üîπ Simula√ß√µes Monte Carlo")
    st.dataframe(mc, use_container_width=True)

    st.stop()
# =========================================================
# BACKTEST INTERNO (Simula√ß√£o Retroativa)
# =========================================================

def executar_backtest_interno(df: pd.DataFrame, nucleo: List[int]) -> pd.DataFrame:
    """
    Backtest Interno:
    - testa o n√∫cleo atual contra trechos passados semelhantes.
    - mede coer√™ncia estrutural retrospectiva (simplificado).
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    ultimas = df.tail(80)[["n1", "n2", "n3", "n4", "n5", "n6"]].values
    nuc = np.array(nucleo)

    linhas = []
    for idx, linha in enumerate(ultimas):
        acertos = len(set(linha.tolist()) & set(nucleo))
        linhas.append([idx] + linha.tolist() + [acertos])

    cols = ["id", "n1", "n2", "n3", "n4", "n5", "n6", "acertos"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: BACKTEST INTERNO
# =========================================================

if painel == "Backtest Interno":
    st.markdown("## üïí Backtest Interno (Retroativo)")
    if df.empty:
        st.warning("Carregue hist√≥rico.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    bt = executar_backtest_interno(df, nucleo)

    st.session_state["backtest_interno"] = bt

    st.markdown("### üîπ N√∫cleo Resiliente")
    st.write(nucleo)

    st.markdown("### üîπ Backtest Interno ‚Äî √öltimas 80 s√©ries")
    st.dataframe(bt, use_container_width=True)

    st.stop()


# =========================================================
# BACKTEST DO FUTURO (BTF)
# =========================================================

def executar_backtest_do_futuro(df: pd.DataFrame, nucleo: List[int]) -> pd.DataFrame:
    """
    Backtest do Futuro:
    - simula como o n√∫cleo atual se comportaria em trechos passados longos.
    - valida coer√™ncia retrospectiva (BTF oficial).
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    linhas = []
    for idx in range(len(df) - 1):
        real = df.iloc[idx + 1][["n1", "n2", "n3", "n4", "n5", "n6"]].values
        acertos = len(set(real.tolist()) & set(nucleo))
        linhas.append([idx] + real.tolist() + [acertos])

    cols = ["id", "real1", "real2", "real3", "real4", "real5", "real6", "acertos"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: BACKTEST DO FUTURO
# =========================================================

if painel == "Backtest do Futuro":
    st.markdown("## üîÆ Backtest do Futuro (Coer√™ncia Retroativa)")

    if df.empty:
        st.warning("Carregue o hist√≥rico.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    btf = executar_backtest_do_futuro(df, nucleo)

    st.session_state["btf_raw"] = btf

    st.markdown("### üîπ N√∫cleo Usado no BTF")
    st.write(nucleo)

    st.markdown("### üîπ Backtest do Futuro ‚Äî Acur√°cia Estrutural")
    st.dataframe(btf.tail(50), use_container_width=True)

    st.stop()


# =========================================================
# LEQUE TURBO ‚Äî BASE (pr√©-s√©ries antes do controle final)
# =========================================================

def gerar_series_base(df: pd.DataFrame, regime: RegimeState) -> Dict[str, List[List[int]]]:
    """
    Gera:
    - N√∫cleo Final Turbo
    - S√©ries Premium iniciais
    - S√©ries Estruturais iniciais
    - S√©ries de Cobertura (b√°sico)
    OBS: O refinamento final vem na PARTE 6 e 7.
    """
    nucleo = gerar_nucleo_resiliente(df, regime)

    if not nucleo:
        return {
            "nucleo": [],
            "premium": [],
            "estruturais": [],
            "cobertura": [],
        }

    base = sorted(nucleo)

    # S√©ries Premium (leve varia√ß√£o)
    premium = []
    for offset in [-1, 1]:
        p = [min(80, max(1, x + offset)) for x in base]
        p = sorted(set(p))[:6]
        premium.append(p)

    # S√©ries Estruturais (duas variantes)
    estruturais = []
    e1 = [min(80, x + 2) for x in base]
    e2 = [max(1, x - 2) for x in base]
    estruturais.append(sorted(set(e1))[:6])
    estruturais.append(sorted(set(e2))[:6])

    # Cobertura (perturba√ß√µes mais amplas)
    cobertura = []
    c1 = [min(80, x + 3) for x in base]
    c2 = [max(1, x - 3) for x in base]
    cobertura.append(sorted(set(c1))[:6])
    cobertura.append(sorted(set(c2))[:6])

    return {
        "nucleo": base,
        "premium": premium,
        "estruturais": estruturais,
        "cobertura": cobertura,
    }


# =========================================================
# PAINEL: LEQUE TURBO (BASE)
# =========================================================

if painel == "Leque TURBO":
    st.markdown("## üöÄ Leque TURBO ‚Äî Base Estrutural")

    if df.empty:
        st.warning("Carregue hist√≥rico.")
        st.stop()

    leque = gerar_series_base(df, regime_state)
    st.session_state["leque_turbo"] = leque

    st.markdown("### üîπ N√∫cleo Final (base)")
    st.write(leque["nucleo"])

    st.markdown("### üîπ S√©ries Premium (base)")
    st.write(leque["premium"])

    st.markdown("### üîπ S√©ries Estruturais (base)")
    st.write(leque["estruturais"])

    st.markdown("### üîπ S√©ries de Cobertura (base)")
    st.write(leque["cobertura"])

    st.stop()
# =========================================================
# LEQUE TURBO ‚Äî FLAT TABLE + MODOS DE SA√çDA
# =========================================================

def build_flat_series_table(leque: Dict[str, Any]) -> pd.DataFrame:
    """
    Constr√≥i uma tabela plana com todas as s√©ries do Leque TURBO.
    Colunas:
    - category
    - series (lista de ints)
    - coherence (0 a 1)
    - expected_hits (1 a 6)
    """
    rows = []

    if not leque:
        return pd.DataFrame(columns=["category", "series", "coherence", "expected_hits"])

    # N√∫cleo principal
    nucleo = leque.get("nucleo", [])
    if nucleo:
        rows.append({
            "category": "N√öCLEO TURBO",
            "series": sorted(nucleo),
            "coherence": 0.90,
            "expected_hits": 4,
        })

    # Premium
    for serie in leque.get("premium", []):
        rows.append({
            "category": "Premium",
            "series": sorted(serie),
            "coherence": 0.82,
            "expected_hits": 3,
        })

    # Estruturais
    for serie in leque.get("estruturais", []):
        rows.append({
            "category": "Estrutural",
            "series": sorted(serie),
            "coherence": 0.74,
            "expected_hits": 2,
        })

    # Cobertura
    for serie in leque.get("cobertura", []):
        rows.append({
            "category": "Cobertura",
            "series": sorted(serie),
            "coherence": 0.65,
            "expected_hits": 1,
        })

    # S6 (se dispon√≠vel em sess√£o)
    s6_df = st.session_state.get("s6_df", pd.DataFrame())
    if not s6_df.empty:
        for _, row in s6_df.iterrows():
            serie = [int(row[c]) for c in ["n1", "n2", "n3", "n4", "n5", "n6"]]
            rows.append({
                "category": "S6",
                "series": sorted(serie),
                "coherence": 0.87,
                "expected_hits": 5,
            })

    if not rows:
        return pd.DataFrame(columns=["category", "series", "coherence", "expected_hits"])

    flat_df = pd.DataFrame(rows)
    return flat_df


def limit_by_mode(
    flat_df: pd.DataFrame,
    regime: Optional[RegimeState],
    output_mode: str,
    n_series_fixed: int,
    min_conf_pct: int,
) -> pd.DataFrame:
    """
    Aplica os tr√™s modos de controle:
    - Autom√°tico (por regime)
    - Quantidade fixa
    - Confiabilidade m√≠nima
    """
    if flat_df.empty:
        return flat_df

    df_sorted = flat_df.sort_values("coherence", ascending=False).reset_index(drop=True)

    # Modo autom√°tico por regime
    if output_mode.startswith("Autom√°tico"):
        if regime is None:
            target = min(12, len(df_sorted))
            return df_sorted.head(target)

        if regime.nome == "Resiliente":
            target = 10
            conf_min = 0.70
        elif regime.nome == "Intermedi√°rio":
            target = 12
            conf_min = 0.60
        else:  # Turbulento
            target = 15
            conf_min = 0.50

        filtrado = df_sorted[df_sorted["coherence"] >= conf_min].head(target)
        if filtrado.empty:
            return df_sorted.head(target)
        return filtrado

    # Modo quantidade fixa
    if output_mode.startswith("Quantidade"):
        return df_sorted.head(min(n_series_fixed, len(df_sorted)))

    # Modo confiabilidade m√≠nima
    if output_mode.startswith("Confiabilidade"):
        thr = min_conf_pct / 100.0
        filtrado = df_sorted[df_sorted["coherence"] >= thr]
        if filtrado.empty:
            # fallback
            return df_sorted.head(8)
        return filtrado.reset_index(drop=True)

    return df_sorted


# =========================================================
# PAINEL ‚Äî SA√çDA FINAL CONTROLADA
# =========================================================

if painel == "Sa√≠da Final Controlada":
    st.markdown("## üéØ Sa√≠da Final Controlada ‚Äî Leque TURBO")

    if df.empty:
        st.warning("Carregue um hist√≥rico para gerar o leque.")
        st.stop()

    # Gera/Regera o leque base
    leque = gerar_series_base(df, regime_state)
    st.session_state["leque_turbo"] = leque

    flat_df = build_flat_series_table(leque)
    if flat_df.empty:
        st.warning("N√£o foi poss√≠vel gerar s√©ries a partir do hist√≥rico atual.")
        st.stop()

    # Aplica modo de sa√≠da
    controlled_df = limit_by_mode(
        flat_df,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )

    # Monta tabela para exibi√ß√£o
    tabela = pd.DataFrame([
        {
            "Rank": i + 1,
            "Categoria": row["category"],
            "S√©rie": " ".join(str(x) for x in row["series"]),
            "Confiabilidade (%)": int(round(row["coherence"] * 100)),
            "Acertos Esperados": int(row["expected_hits"]),
        }
        for i, (_, row) in enumerate(controlled_df.iterrows())
    ])

    st.markdown("### üîπ S√©ries Selecionadas")
    st.dataframe(tabela, use_container_width=True)

    # Lista pura numerada
    st.markdown("### üìã Lista Pura (somente s√©ries, numeradas)")
    lista_pura = []
    for i, (_, row) in enumerate(controlled_df.iterrows()):
        ss = " ".join(str(x) for x in row["series"])
        lista_pura.append(f"{i + 1}) {ss}")

    texto_puro = "\n".join(lista_pura)
    st.text_area(
        "Copiar s√©ries (Lista Pura):",
        value=texto_puro,
        height=200,
    )

    st.stop()


# =========================================================
# LOGS T√âCNICOS ‚Äî REGISTRO E PAINEL
# =========================================================

def add_log(etapa: str, dados: Any):
    """
    Registra um log t√©cnico no session_state["logs_tecnicos"].
    Pode ser chamado em qualquer etapa do pipeline.
    """
    if "logs_tecnicos" not in st.session_state:
        st.session_state["logs_tecnicos"] = []
    st.session_state["logs_tecnicos"].append(
        {
            "etapa": etapa,
            "dados": dados,
        }
    )


if painel == "Logs T√©cnicos":
    st.markdown("## üß∞ Logs T√©cnicos ‚Äî Pipeline V13.8-TURBO")

    logs = st.session_state.get("logs_tecnicos", [])

    if not logs:
        st.info("Nenhum log t√©cnico registrado ainda.")
        st.stop()

    for registro in logs:
        with st.expander(f"Etapa: {registro['etapa']}"):
            st.write(registro["dados"])

    st.stop()


# =========================================================
# DIAGN√ìSTICO PROFUNDO ‚Äî GR√ÅFICOS E ESTABILIDADE
# =========================================================

def plot_line(data, title, ylabel):
    fig, ax = plt.subplots(figsize=(8, 3))
    ax.plot(data)
    ax.set_title(title)
    ax.set_ylabel(ylabel)
    ax.set_xlabel("√çndice")
    ax.grid(True, linestyle="--", alpha=0.4)
    st.pyplot(fig)


def plot_hist(data, title, xlabel):
    fig, ax = plt.subplots(figsize=(8, 3))
    ax.hist(data, bins=20, edgecolor="black", alpha=0.7)
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel("Frequ√™ncia")
    ax.grid(True, linestyle="--", alpha=0.4)
    st.pyplot(fig)


def calcular_indice_estabilidade(regime_state: Optional[RegimeState]) -> Optional[float]:
    """
    √çndice composto de estabilidade da estrada:
    ~1.0 ‚Üí muito est√°vel
    ~0.5 ‚Üí intermedi√°rio
    ~0.0 ‚Üí inst√°vel / turbulento
    """
    if not regime_state:
        return None

    disp_peso = max(0.0, 1.0 - regime_state.dispersao / 40.0)
    amp_peso = max(0.0, 1.0 - regime_state.amplitude / 60.0)
    vib_peso = max(0.0, 1.0 - regime_state.vibracao / 30.0)
    par_peso = min(1.0, len(regime_state.pares) / 10.0)

    score = (disp_peso + amp_peso + vib_peso + par_peso) / 4.0
    return score


if painel == "Diagn√≥stico Profundo":
    st.markdown("## üß≠ Diagn√≥stico Profundo ‚Äî Estrutura da Estrada")

    if df.empty:
        st.warning("Carregue um hist√≥rico para visualizar diagn√≥stico.")
        st.stop()

    # Curvas estruturais b√°sicas
    st.markdown("### üìà Dispers√£o e Amplitude ao Longo do Tempo")

    dispersoes = df.apply(
        lambda row: np.std([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]]),
        axis=1,
    )
    amplitudes = df.apply(
        lambda row: max([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]])
        - min([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]]),
        axis=1,
    )

    plot_line(dispersoes, "Dispers√£o das S√©ries", "Dispers√£o")
    plot_line(amplitudes, "Amplitude das S√©ries", "Amplitude")

    # Vibra√ß√£o
    st.markdown("### üåê Vibra√ß√£o Estrutural")
    vib = np.abs(dispersoes.diff().fillna(0))
    plot_line(vib, "Varia√ß√£o da Dispers√£o (Vibra√ß√£o)", "Vibra√ß√£o")

    # Backtest Interno ‚Äî distribui√ß√£o de acertos
    st.markdown("### üéØ Distribui√ß√£o de Acertos ‚Äî Backtest Interno")
    bti = st.session_state.get("backtest_interno", pd.DataFrame())
    if not bti.empty and "acertos" in bti.columns:
        plot_hist(bti["acertos"], "Distribui√ß√£o de Acertos (Backtest Interno)", "Acertos")
    else:
        st.info("Backtest Interno ainda n√£o foi executado.")

    # Backtest do Futuro ‚Äî distribui√ß√£o de acertos
    st.markdown("### üîÆ Distribui√ß√£o de Acertos ‚Äî Backtest do Futuro")
    btf = st.session_state.get("btf_raw", pd.DataFrame())
    if not btf.empty and "acertos" in btf.columns:
        plot_hist(btf["acertos"], "Distribui√ß√£o de Acertos (Backtest do Futuro)", "Acertos")
    else:
        st.info("Backtest do Futuro ainda n√£o foi executado.")

    # Estabilidade global
    st.markdown("### üß© √çndice Global de Estabilidade")
    est = calcular_indice_estabilidade(regime_state)
    if est is None:
        st.info("Regime ainda n√£o calculado.")
    else:
        st.metric("Estabilidade Estrutural", f"{est * 100:.1f}%")
        if est >= 0.75:
            st.success("Estrada EST√ÅVEL (tend√™ncia resiliente).")
        elif est >= 0.50:
            st.warning("Estrada MODERADA (estado intermedi√°rio).")
        else:
            st.error("Estrada INST√ÅVEL / Turbulenta.")

    st.stop()
# =========================================================
# PAINEL ‚Äî EXPORTAR RESULTADOS (TXT / CSV)
# =========================================================

def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8")


def text_to_bytes(text: str) -> bytes:
    return text.encode("utf-8")


if painel == "Exportar Resultados":
    st.markdown("## üì§ Exportar Resultados (TXT / CSV)")

    # Usamos o leque final controlado
    leque = gerar_series_base(df, regime_state)
    flat_df = build_flat_series_table(leque)
    controlled_df = limit_by_mode(
        flat_df,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )

    if controlled_df.empty:
        st.warning("Nenhuma s√©rie dispon√≠vel para exporta√ß√£o.")
        st.stop()

    # CSV
    st.markdown("### üü¶ Baixar CSV (Leque Final)")
    csv_bytes = df_to_csv_bytes(controlled_df)
    st.download_button(
        "üì• Download CSV",
        data=csv_bytes,
        file_name="leque_turbo.csv",
        mime="text/csv",
    )

    # TXT puro
    st.markdown("### üü© Baixar TXT (Lista Pura)")
    lista_pura = []
    for i, (_, row) in enumerate(controlled_df.iterrows()):
        ss = " ".join(str(x) for x in row["series"])
        lista_pura.append(f"{i+1}) {ss}")

    txt_bytes = text_to_bytes("\n".join(lista_pura))

    st.download_button(
        "üì• Download TXT",
        data=txt_bytes,
        file_name="lista_pura.txt",
        mime="text/plain",
    )

    st.stop()


# =========================================================
# PAINEL ‚Äî EXPORTAR SESS√ÉO COMPLETA (ZIP)
# =========================================================

def build_session_zip() -> bytes:
    """
    Gera um ZIP com:
    - hist√≥rico carregado
    - regime
    - n√∫cleo
    - leque final
    - lista pura
    - S6
    - Monte Carlo
    - backtests
    - logs t√©cnicos
    """
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w") as z:

        # Hist√≥rico
        if not df.empty:
            z.writestr("historico.csv", df.to_csv(index=False))

        # Regime
        if regime_state:
            z.writestr(
                "regime.json",
                json.dumps(regime_state.__dict__, indent=2),
            )

        # N√∫cleo Resiliente
        nucleo = gerar_nucleo_resiliente(df, regime_state)
        z.writestr("nucleo.json", json.dumps(nucleo))

        # Leque Final (CSV)
        leque_final = gerar_series_base(df, regime_state)
        flat_df = build_flat_series_table(leque_final)
        z.writestr("leque_flat.csv", flat_df.to_csv(index=False))

        # Lista pura
        lista_pura = [
            f"{i+1}) " + " ".join(str(x) for x in row["series"])
            for i, (_, row) in enumerate(flat_df.iterrows())
        ]
        z.writestr("lista_pura.txt", "\n".join(lista_pura))

        # S6
        s6_df = st.session_state.get("s6_df", pd.DataFrame())
        if not s6_df.empty:
            z.writestr("s6.csv", s6_df.to_csv(index=False))

        # Monte Carlo
        mc_df = st.session_state.get("mc_df", pd.DataFrame())
        if not mc_df.empty:
            z.writestr("monte_carlo.csv", mc_df.to_csv(index=False))

        # Backtest Interno
        bti = st.session_state.get("backtest_interno", pd.DataFrame())
        if not bti.empty:
            z.writestr("backtest_interno.csv", bti.to_csv(index=False))

        # Backtest do Futuro
        btf = st.session_state.get("btf_raw", pd.DataFrame())
        if not btf.empty:
            z.writestr("backtest_futuro.csv", btf.to_csv(index=False))

        # Logs t√©cnicos
        logs = st.session_state.get("logs_tecnicos", [])
        z.writestr("logs_tecnicos.json", json.dumps(logs, indent=2))

    buffer.seek(0)
    return buffer.read()


if painel == "Exportar Sess√£o Completa":
    st.markdown("## üì¶ Exportar Sess√£o Completa (ZIP)")

    if df.empty:
        st.warning("Carregue hist√≥rico para exportar sess√£o.")
        st.stop()

    zip_bytes = build_session_zip()

    st.download_button(
        "üì• Baixar ZIP Completo",
        data=zip_bytes,
        file_name="predictcars_v13.8_turbo_session.zip",
        mime="application/zip",
    )

    st.stop()
