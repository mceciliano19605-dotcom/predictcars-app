# =========================================================
# PREDICT CARS V13.8-TURBO ‚Äî app.py CONSOLIDADO
# Vers√£o completa (BLOCOS 1 a 14 integrados)
# =========================================================

from __future__ import annotations

import io
import json
import zipfile
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# =========================================================
# CONFIGURA√á√ÉO GLOBAL DO APP
# =========================================================

st.set_page_config(
    page_title="Predict Cars V13.8-TURBO",
    page_icon="üöó",
    layout="wide",
)

# =========================================================
# TIPOS B√ÅSICOS
# =========================================================

@dataclass
class RegimeState:
    nome: str
    dispersao: float
    amplitude: float
    vibracao: float
    pares: List[Tuple[int, int]]

def formatar_serie_para_texto(s):
    # Caso 1 ‚Äî j√° √© string
    if isinstance(s, str):
        # Tenta dividir em n√∫meros se for algo como "8 15 23"
        partes = [p.strip() for p in s.replace(",", " ").split() if p.strip()]
        numeros = []
        for p in partes:
            try:
                numeros.append(str(int(p)))
            except:
                continue
        return " ".join(numeros)

    # Caso 2 ‚Äî lista ou tupla
    if isinstance(s, (list, tuple)):
        numeros = []
        for x in s:
            try:
                numeros.append(str(int(x)))
            except:
                continue
        return " ".join(numeros)

    # Caso 3 ‚Äî qualquer outra coisa
    try:
        return str(int(s))
    except:
        return ""


# =========================================================
# FUN√á√ïES B√ÅSICAS ‚Äî PARSING DO HIST√ìRICO
# =========================================================

def parse_line_to_series(line: str) -> Optional[List[int]]:
    """
    Converte uma linha do arquivo em lista de inteiros.
    Aceita formatos:
    - C1234; n1; n2; n3; n4; n5; k
    - n1; n2; n3; n4; n5; k
    - n1 n2 n3 n4 n5 k
    """
    if not line.strip():
        return None

    # Troca v√≠rgulas por ponto e v√≠rgula, normaliza separadores
    line = line.replace(",", ";").replace("\t", ";")
    # Se n√£o houver ';', tenta separar por espa√ßo
    if ";" not in line:
        parts = line.split()
    else:
        parts = [p.strip() for p in line.split(";") if p.strip()]

    if not parts:
        return None

    # Ignora prefixos tipo 'C1234'
    if parts[0].upper().startswith("C") and len(parts) > 1:
        parts = parts[1:]

    # Espera pelo menos 6 n√∫meros (5+1 ou 6+1, etc.)
    nums = []
    for p in parts:
        try:
            nums.append(int(p))
        except ValueError:
            # ignora tokens n√£o num√©ricos
            continue

    if len(nums) < 6:
        return None

    # Considera sempre os 6 primeiros como passageiros, o √∫ltimo como k
    # Se houver mais de 7 colunas, corta.
    return nums[:7]


def history_to_dataframe(text: str) -> pd.DataFrame:
    """
    Converte texto bruto em DataFrame no formato interno:
    colunas: n1..n6, k
    Sem √≠ndice Cxxxx (n√£o √© necess√°rio para o app).
    """
    linhas = text.splitlines()
    registros = []

    for line in linhas:
        serie = parse_line_to_series(line)
        if serie is None:
            continue
        # se vier exatamente 6, assume k = 0
        if len(serie) == 6:
            serie.append(0)
        # garante tamanho 7
        if len(serie) > 7:
            serie = serie[:7]
        registros.append(serie)

    if not registros:
        return pd.DataFrame(columns=["n1", "n2", "n3", "n4", "n5", "n6", "k"])

    df = pd.DataFrame(
        registros,
        columns=["n1", "n2", "n3", "n4", "n5", "n6", "k"],
    )
    return df


# =========================================================
# FUN√á√ïES B√ÅSICAS ‚Äî ESTADO DA ESTRADA (REGIME)
# =========================================================

def calcular_regime(df: pd.DataFrame) -> Optional[RegimeState]:
    """
    Estima o regime atual com base nas √∫ltimas linhas do hist√≥rico.
    Heur√≠stica simplificada:
    - dispers√£o m√©dia
    - amplitude m√©dia
    - vibra√ß√£o (varia√ß√£o da dispers√£o)
    - pares frequentes nas √∫ltimas linhas
    """
    if df is None or df.empty:
        return None

    # Considera um trecho recente (ex.: √∫ltimas 80 linhas ou menos)
    trecho = df.tail(min(80, len(df)))
    numeros = trecho[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    dispersoes = np.std(numeros, axis=1)
    amplitudes = np.max(numeros, axis=1) - np.min(numeros, axis=1)
    vib = np.abs(np.diff(dispersoes)).mean() if len(dispersoes) > 1 else 0.0

    disp_med = float(np.mean(dispersoes))
    amp_med = float(np.mean(amplitudes))

    # Gera√ß√£o simples de pares
    contagem_pares: Dict[Tuple[int, int], int] = {}
    for linha in numeros:
        linha_ordenada = sorted(set(linha.tolist()))
        for i in range(len(linha_ordenada)):
            for j in range(i + 1, len(linha_ordenada)):
                par = (linha_ordenada[i], linha_ordenada[j])
                contagem_pares[par] = contagem_pares.get(par, 0) + 1

    pares_ativos = sorted(
        contagem_pares.items(),
        key=lambda x: x[1],
        reverse=True,
    )[:10]
    pares_ativos = [p[0] for p in pares_ativos]

    # Regra simples para nome do regime
    if disp_med < 10 and amp_med < 25 and vib < 3:
        nome = "Resiliente"
    elif disp_med < 16 and amp_med < 35:
        nome = "Intermedi√°rio"
    else:
        nome = "Turbulento"

    return RegimeState(
        nome=nome,
        dispersao=disp_med,
        amplitude=amp_med,
        vibracao=float(vib),
        pares=pares_ativos,
    )


# =========================================================
# INICIALIZA√á√ÉO DE ESTADO (session_state)
# =========================================================

def ensure_session_defaults():
    """
    Garante chaves b√°sicas no session_state.
    """
    defaults = {
        "df": pd.DataFrame(),
        "regime_state": None,
        "idx_result": pd.DataFrame(),
        "nucleo_ipf": None,
        "nucleo_ipo": None,
        "ajustes_log": [],
        "dependencias": None,
        "s6_df": pd.DataFrame(),
        "mc_df": pd.DataFrame(),
        "backtest_interno": pd.DataFrame(),
        "btf_raw": pd.DataFrame(),
        "leque_turbo": {},
        "logs_tecnicos": [],
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


ensure_session_defaults()

# =========================================================
# LAYOUT PRINCIPAL ‚Äî CABE√áALHO E ENTRADA DE HIST√ìRICO
# =========================================================

st.title("üöó Predict Cars V13.8-TURBO")
st.caption("Modo Ultra-H√≠brido TURBO ‚Äî N√∫cleo Resiliente + Leque Estrutural + Backtest do Futuro")

st.markdown("### üì• Entrada de Hist√≥rico")

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader(
        "Carregar arquivo de hist√≥rico (.txt ou .csv)",
        type=["txt", "csv"],
    )

with col2:
    text_input = st.text_area(
        "Ou colar o hist√≥rico aqui (linhas com 6 passageiros + k)",
        height=200,
    )

df: pd.DataFrame

if uploaded_file is not None:
    raw_bytes = uploaded_file.read()
    raw_text = raw_bytes.decode("utf-8", errors="ignore")
    df = history_to_dataframe(raw_text)
    st.session_state["df"] = df
elif text_input.strip():
    df = history_to_dataframe(text_input)
    st.session_state["df"] = df
else:
    df = st.session_state.get("df", pd.DataFrame())

if df is not None and not df.empty:
    st.success(f"Hist√≥rico carregado com {len(df)} s√©ries.")
    st.dataframe(df.tail(10), use_container_width=True)
else:
    st.info("Nenhum hist√≥rico v√°lido carregado ainda.")

# =========================================================
# C√ÅLCULO DO ESTADO DA ESTRADA (REGIME)
# =========================================================

if not df.empty:
    regime_state = calcular_regime(df)
    st.session_state["regime_state"] = regime_state
else:
    regime_state = None

# =========================================================
# CONTROLES GERAIS (SIDEBAR)
# =========================================================

st.sidebar.markdown("## ‚öôÔ∏è Controles Gerais")

# Modo de gera√ß√£o do leque final
output_mode = st.sidebar.radio(
    "Modo de gera√ß√£o do Leque:",
    options=[
        "Autom√°tico (por regime)",
        "Quantidade fixa",
        "Confiabilidade m√≠nima",
    ],
    index=0,
)

n_series_fixed = st.sidebar.slider(
    "Quantidade total de s√©ries (se modo for 'Quantidade fixa')",
    min_value=5,
    max_value=25,
    value=12,
)

min_conf_pct = st.sidebar.slider(
    "Confiabilidade m√≠nima (%) (se modo for 'Confiabilidade m√≠nima')",
    min_value=30,
    max_value=85,
    value=55,
)

modo_k = st.sidebar.radio(
    "Modo k:",
    ["Usar k atual (k*)", "Usar k preditivo (kÃÇ)"],
    index=0,
)
if modo_k == "Usar k atual (k*)":
    k_ativo = k_estado
else:
    k_ativo = k_pred

# =========================================================
# MENU DE NAVEGA√á√ÉO (PAIN√âIS PRINCIPAIS)
# =========================================================

st.sidebar.markdown("## üìÇ Navega√ß√£o")

painel = st.sidebar.radio(
    "Escolha o painel:",
    [
        "Hist√≥rico",
        "Estado Atual",
        "IDX Avan√ßado",
        "N√∫cleo IPF / IPO",
        "Ajustes (ASB / ADN / ICA / HLA)",
        "Depend√™ncias Ocultas",
        "S6 Profundo",
        "Monte Carlo Profundo",
        "Backtest Interno",
        "Backtest do Futuro",
        "Leque TURBO",
        "Sa√≠da Final Controlada",
        "S1‚ÄìS5 + Ajuste Fino",
        "Logs T√©cnicos",
        "Diagn√≥stico Profundo",
        "Exportar Resultados",
        "Exportar Sess√£o Completa",
        "Compara√ß√£o k* vs kÃÇ",
    ],
    index=0,
)


# A partir da PARTE 2/7, cada painel ser√° implementado
# com base na vari√°vel `painel` e no DataFrame `df`.
# =========================================================
# PAINEL: HIST√ìRICO
# =========================================================

if painel == "Hist√≥rico":
    st.markdown("## üìú Hist√≥rico Carregado")
    if df.empty:
        st.warning("Nenhum hist√≥rico carregado.")
    else:
        st.dataframe(df, use_container_width=True)
        st.markdown("### üîç √öltimas 15 s√©ries")
        st.dataframe(df.tail(15), use_container_width=True)
    st.stop()

# =========================================================
# PAINEL: ESTADO ATUAL (REGIME)
# =========================================================

if painel == "Estado Atual":
    st.markdown("## üå°Ô∏è Estado da Estrada (Regime)")
    if regime_state is None:
        st.warning("Regime n√£o p√¥de ser calculado ‚Äî carregue hist√≥rico v√°lido.")
        st.stop()

    # =========================================================
    # SENSOR AMBIENTAL k* ‚Äî ESTADO ATUAL (MODO SIMPLES)
    # =========================================================
    try:
        # Hist√≥rico completo
        df_hist = df.copy()

        # Fun√ß√£o para renomear colunas corretamente
        if df_hist.shape[1] >= 8:
            df_hist.columns = ["id", "n1", "n2", "n3", "n4", "n5", "n6", "k"]
        else:
            # fallback: se vier sem ID
            if df_hist.shape[1] == 7:
                df_hist.columns = ["n1", "n2", "n3", "n4", "n5", "n6", "k"]
                df_hist["id"] = None
            else:
                df_hist["k"] = 0  # pior caso

        # √öltimos valores de k
        ultimos_k = df_hist["k"].tail(5).tolist()

        # Detecta ruptura recente (k != 0)
        ruptura_recente = (df_hist["k"].iloc[-1] != 0)

        # L√≥gica do sensor
        if ruptura_recente:
            k_estado = "critico"
        else:
            if any(k != 0 for k in ultimos_k):
                k_estado = "atencao"
            else:
                k_estado = "estavel"
        k_pred = calcular_k_pred(k_estado, df_hist)

        texto_k_atual = contexto_k_texto(k_estado, prefixo="k*")
        texto_k_pred  = contexto_k_texto(k_pred,    prefixo="kÃÇ")
        
        # Exibir badge ambiental no Estado Atual
        st.markdown("### üå°Ô∏è Estado Ambiental da Estrada (k*) ‚Äî Estado Atual")
        st.markdown(texto_k_atual)
        st.markdown(texto_k_pred)
    except Exception as e:
        st.error(f"Erro no sensor k* (Estado Atual): {e}")
    st.subheader("Resumo do Regime Atual")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Regime", regime_state.nome)
    c2.metric("Dispers√£o", f"{regime_state.dispersao:.2f}")
    c3.metric("Amplitude", f"{regime_state.amplitude:.2f}")
    c4.metric("Vibra√ß√£o", f"{regime_state.vibracao:.2f}")

    st.markdown("### üîó Pares Ativos (mais frequentes recentemente)")
    pares_df = pd.DataFrame(regime_state.pares, columns=["p1", "p2"])
    st.dataframe(pares_df, use_container_width=True)

    st.stop()

# =========================================================
# M√ìDULO IDX AVAN√áADO ‚Äî SIMILARIDADE E N√öCLEOS INICIAIS
# =========================================================

def calcular_similaridade(linha_a: np.ndarray, linha_b: np.ndarray) -> float:
    """
    Similaridade simples entre duas s√©ries:
    - 1 / (1 + soma das dist√¢ncias absolutas)
    Quanto maior, mais parecido.
    """
    return 1.0 / (1.0 + np.sum(np.abs(linha_a - linha_b)))


def executar_idx_avancado(df: pd.DataFrame, n_top: int = 40) -> pd.DataFrame:
    """
    Identifica as s√©ries historicamente mais parecidas com a √∫ltima s√©rie.
    Retorna DataFrame com:
    - √≠ndice original
    - similaridade
    - n1..n6
    """
    if df.empty:
        return pd.DataFrame()

    ultima = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values[-1]
    similares = []

    for idx in range(len(df) - 1):
        atual = df.iloc[idx][["n1", "n2", "n3", "n4", "n5", "n6"]].values
        sim = calcular_similaridade(ultima, atual)
        similares.append(
            (idx, sim) + tuple(df.iloc[idx][["n1", "n2", "n3", "n4", "n5", "n6"]].values)
        )

    cols = ["idx", "similaridade", "n1", "n2", "n3", "n4", "n5", "n6"]
    df_sim = pd.DataFrame(similares, columns=cols)
    df_sim = df_sim.sort_values("similaridade", ascending=False).head(n_top)

    return df_sim


# =========================================================
# M√ìDULOS IPF / IPO B√ÅSICOS (primeira camada)
# =========================================================

def extrair_ipf(df_idx: pd.DataFrame) -> Optional[List[int]]:
    """
    IPF (IDX Puro Focado simplificado):
    Extrai n√∫cleo como m√©dia ponderada dos top-idx por similaridade.
    """
    if df_idx.empty:
        return None

    pesos = df_idx["similaridade"].values
    nums = df_idx[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    media = np.average(nums, weights=pesos, axis=0)
    nucleo = [int(round(x)) for x in media]
    # Garante n√∫meros distintos
    nucleo = list(sorted(set(nucleo)))
    while len(nucleo) < 6:
        nucleo.append(nucleo[-1] + 1)
    return nucleo[:6]


def aplicar_ipo_profundo(nucleo: List[int], regime: RegimeState) -> List[int]:
    """
    IPO Profundo simplificado:
    - Ajusta faixa dominante;
    - Suaviza extremos incoerentes com regime;
    - Garante coer√™ncia estrutural m√≠nima.
    """
    if nucleo is None:
        return []

    ordenado = sorted(nucleo)
    faixas = np.array(ordenado)

    # Ajuste leve conforme regime
    if regime.nome == "Resiliente":
        faixas = np.clip(faixas, 1, 70)
    elif regime.nome == "Intermedi√°rio":
        faixas = np.clip(faixas, 5, 75)
    else:  # Turbulento
        faixas = np.clip(faixas, 10, 80)

    return sorted(set(int(x) for x in faixas))[:6]


# =========================================================
# PAINEL: IDX AVAN√áADO
# =========================================================

if painel == "IDX Avan√ßado":
    st.markdown("## üîé IDX Avan√ßado")
    if df.empty:
        st.warning("Nenhum hist√≥rico carregado.")
        st.stop()

    df_idx = executar_idx_avancado(df)
    st.session_state["idx_result"] = df_idx

    st.markdown("### Top s√©ries similares (IDX)")
    st.dataframe(df_idx, use_container_width=True)
    # =========================================================
    # SENSOR AMBIENTAL k* ‚Äî IDX AVAN√áADO (MODO SIMPLES)
    # =========================================================
    try:
        # Hist√≥rico completo
        df_hist = df.copy()

        # Fun√ß√£o para renomear colunas corretamente
        if df_hist.shape[1] >= 8:
            df_hist.columns = ["id", "n1", "n2", "n3", "n4", "n5", "n6", "k"]
        else:
            if df_hist.shape[1] == 7:
                df_hist.columns = ["n1", "n2", "n3", "n4", "n5", "n6", "k"]
                df_hist["id"] = None
            else:
                df_hist["k"] = 0

        # √öltimos valores de k
        ultimos_k = df_hist["k"].tail(5).tolist()

        # Detecta ruptura recente
        ruptura_recente = (df_hist["k"].iloc[-1] != 0)

        # L√≥gica do sensor
        if ruptura_recente:
            k_estado = "critico"
        else:
            if any(k != 0 for k in ultimos_k):
                k_estado = "atencao"
            else:
                k_estado = "estavel"

        # Exibir badge no IDX
        st.markdown("### üå°Ô∏è Estado Ambiental da Estrada (k*) ‚Äî IDX Avan√ßado")
        st.markdown(contexto_k_texto(k_estado, prefixo="k*"))
        st.markdown(texto_k_pred)
    
    except Exception as e:
        st.error(f"Erro no sensor k* (IDX Avan√ßado): {e}")

    st.stop()
# =========================================================
# FUN√á√ïES DE AJUSTE (ASB / ADN / ICA / HLA)
# =========================================================

def aplicar_asb_antibias(nucleo: List[int], regime: RegimeState) -> List[int]:
    """
    ASB ‚Äî Anti-SelfBias simplificado:
    - Permite repeti√ß√£o somente quando coerente com o regime;
    - Evita compress√£o artificial de faixa.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    # Evita compress√£o artificial
    diffs = np.diff(base)
    if np.any(diffs < 2):
        base = [base[0]] + [base[i] + 2 for i in range(1, len(base))]

    # Regras por regime
    if regime.nome == "Resiliente":
        return base  # repeti√ß√£o natural √© permitida
    elif regime.nome == "Intermedi√°rio":
        # leve expans√£o
        return [min(80, x + 1) for x in base]
    else:
        # turbul√™ncia ‚Üí evitar repeti√ß√µes e zonas muito estreitas
        return sorted(set([min(80, x + 2) for x in base]))[:6]


def aplicar_adn(nucleo: List[int], modo: str = "leve") -> List[int]:
    """
    ADN (Ajuste Din√¢mico):
    - leve ‚Üí corrige ru√≠dos sem alterar ess√™ncia
    - m√©dio ‚Üí substitui elementos fracos
    - profundo ‚Üí reavalia microestruturas (simplificado)
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    if modo == "leve":
        return base

    if modo == "m√©dio":
        # substitui o menor elemento por +1
        base[0] = min(80, base[0] + 1)
        return sorted(base)

    if modo == "profundo":
        # desloca todo o n√∫cleo para a faixa seguinte
        return sorted([min(80, x + 2) for x in base])

    return base


def aplicar_ica_profundo(nucleo: List[int]) -> List[int]:
    """
    ICA Profundo (Iterative Core Adjustment):
    - refor√ßa coer√™ncia entre posi√ß√µes adjacentes;
    - evita saltos incoerentes.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    for i in range(1, len(base)):
        if base[i] - base[i - 1] > 15:
            base[i] = base[i - 1] + 10

    return sorted(set(base))[:6]


def aplicar_hla_profundo(nucleo: List[int]) -> List[int]:
    """
    HLA Profundo:
    - poda incoer√™ncias de dispers√£o;
    - reequilibra extremos.
    """
    if nucleo is None:
        return []

    base = sorted(nucleo)

    # for√ßa extremos a serem coerentes
    if base[-1] - base[0] > 60:
        base[-1] = base[0] + 45

    return sorted(set(base))[:6]


# =========================================================
# PIPELINE COMPLETO DO N√öCLEO (IPF + IPO + ASB + ADN + ICA + HLA)
# =========================================================

def gerar_nucleo_resiliente(df: pd.DataFrame, regime: RegimeState) -> List[int]:
    """
    Pipeline resumido para gerar o N√∫cleo Resiliente completo.
    """
    if df.empty:
        return []

    # Etapa 1: IDX
    df_idx = executar_idx_avancado(df)
    ipf = extrair_ipf(df_idx)
    if ipf is None:
        return []

    # Etapa 2: IPO
    ipo = aplicar_ipo_profundo(ipf, regime)

    # Etapa 3: ASB (Anti-SelfBias)
    asb = aplicar_asb_antibias(ipo, regime)

    # Etapa 4: ADN (modo m√©dio por padr√£o)
    adn = aplicar_adn(asb, modo="m√©dio")

    # Etapa 5: ICA / HLA
    ica = aplicar_ica_profundo(adn)
    hla = aplicar_hla_profundo(ica)

    return sorted(set(hla))[:6]


# =========================================================
# PAINEL: N√öCLEO IPF / IPO
# =========================================================

if painel == "N√∫cleo IPF / IPO":
    st.markdown("## üß¨ N√∫cleo IPF / IPO")
    if df.empty:
        st.warning("Carregue um hist√≥rico v√°lido.")
        st.stop()

    df_idx = st.session_state.get("idx_result", executar_idx_avancado(df))
    ipf = extrair_ipf(df_idx)
    ipo = aplicar_ipo_profundo(ipf, regime_state)

    st.session_state["nucleo_ipf"] = ipf
    st.session_state["nucleo_ipo"] = ipo

    st.markdown("### üîπ N√∫cleo IPF (puro focado)")
    st.write(ipf)

    st.markdown("### üîπ N√∫cleo IPO (otimizado)")
    st.write(ipo)

    st.stop()


# =========================================================
# PAINEL: AJUSTES (ASB / ADN / ICA / HLA)
# =========================================================

if painel == "Ajustes (ASB / ADN / ICA / HLA)":
    st.markdown("## üîß Ajustes do N√∫cleo (ASB, ADN, ICA, HLA)")

    if df.empty:
        st.warning("Carregue um hist√≥rico antes de visualizar ajustes.")
        st.stop()

    # Etapas
    df_idx = st.session_state.get("idx_result", executar_idx_avancado(df))
    ipf = extrair_ipf(df_idx)
    ipo = aplicar_ipo_profundo(ipf, regime_state)

    asb = aplicar_asb_antibias(ipo, regime_state)
    adn = aplicar_adn(asb, modo="m√©dio")
    ica = aplicar_ica_profundo(adn)
    hla = aplicar_hla_profundo(ica)

    st.markdown("### üîπ IPF ‚Üí IPO ‚Üí ASB ‚Üí ADN ‚Üí ICA ‚Üí HLA")
    st.write({
        "IPF": ipf,
        "IPO": ipo,
        "ASB": asb,
        "ADN (m√©dio)": adn,
        "ICA": ica,
        "HLA": hla,
    })

    st.stop()
# =========================================================
# DEPEND√äNCIAS OCULTAS
# =========================================================

def calcular_dependencias_ocultas(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Depend√™ncias ocultas (vers√£o simplificada):
    - pares naturais
    - pares ocultos
    - pesos leves / m√©dios / pesados
    - vibra√ß√£o hist√≥rica
    """
    if df.empty:
        return {}

    numeros = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values

    # Contagem simples de pares
    contagem: Dict[Tuple[int, int], int] = {}
    for linha in numeros:
        linha_ord = sorted(set(linha.tolist()))
        for i in range(len(linha_ord)):
            for j in range(i + 1, len(linha_ord)):
                par = (linha_ord[i], linha_ord[j])
                contagem[par] = contagem.get(par, 0) + 1

    pares_ordenados = sorted(contagem.items(), key=lambda x: x[1], reverse=True)
    naturais = pares_ordenados[:15]
    ocultos = pares_ordenados[15:40]

    # vibra√ß√£o hist√≥rica simples
    dispersoes = np.std(numeros, axis=1)
    vibracao = float(np.mean(np.abs(np.diff(dispersoes)))) if len(dispersoes) > 1 else 0.0

    dependencias = {
        "pares_naturais": naturais,
        "pares_ocultos": ocultos,
        "vibracao": vibracao,
    }

    return dependencias


# =========================================================
# PAINEL: DEPEND√äNCIAS OCULTAS
# =========================================================

if painel == "Depend√™ncias Ocultas":
    st.markdown("## üß© Depend√™ncias Ocultas")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    dep = calcular_dependencias_ocultas(df)
    st.session_state["dependencias"] = dep

    st.markdown("### üî∏ Pares Naturais")
    df_nat = pd.DataFrame(dep["pares_naturais"], columns=["par", "freq"])
    st.dataframe(df_nat, use_container_width=True)

    st.markdown("### üî∏ Pares Ocultos")
    df_oc = pd.DataFrame(dep["pares_ocultos"], columns=["par", "freq"])
    st.dataframe(df_oc, use_container_width=True)

    st.markdown("### üî∏ Vibra√ß√£o Hist√≥rica")
    st.write(dep["vibracao"])

    st.stop()


# =========================================================
# M√ìDULO S6 ‚Äî MODOS DE 6 ACERTOS PROFUNDO
# =========================================================

def gerar_s6_profundo(df: pd.DataFrame, nucleo: List[int], regime: RegimeState) -> pd.DataFrame:
    """
    S6 Profundo simplificado:
    - gera s√©ries vizinhas do n√∫cleo
    - usa microperturba√ß√µes coerentes com o regime
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    base = sorted(nucleo)
    candidatos = []

    for desloc in [-3, -2, -1, 1, 2, 3]:
        nova = [min(80, max(1, x + desloc)) for x in base]
        nova = sorted(set(nova))[:6]
        candidatos.append(nova)

    linhas = []
    for idx, serie in enumerate(candidatos):
        linhas.append([idx] + serie)

    cols = ["id", "n1", "n2", "n3", "n4", "n5", "n6"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: S6 PROFUNDO
# =========================================================

if painel == "S6 Profundo":
    st.markdown("## üéØ S6 Profundo ‚Äî Zonas de Converg√™ncia")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    s6 = gerar_s6_profundo(df, nucleo, regime_state)

    st.session_state["s6_df"] = s6

    st.markdown("### üîπ N√∫cleo Resiliente")
    st.write(nucleo)

    st.markdown("### üîπ S√©ries S6 Geradas")
    st.dataframe(s6, use_container_width=True)

    st.stop()


# =========================================================
# M√ìDULO MONTE CARLO PROFUNDO
# =========================================================

def gerar_monte_carlo(df: pd.DataFrame, nucleo: List[int], regime: RegimeState, n_sim=50) -> pd.DataFrame:
    """
    Monte Carlo Profundo:
    - perturba o n√∫cleo de forma leve
    - gera varia√ß√µes coerentes com a estrada
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    linhas = []
    for i in range(n_sim):
        var = []
        for x in nucleo:
            ruido = np.random.randint(-2, 3)
            novo = min(80, max(1, x + ruido))
            var.append(novo)
        var = sorted(set(var))[:6]
        linhas.append([i] + var)

    cols = ["sim_id", "n1", "n2", "n3", "n4", "n5", "n6"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: MONTE CARLO PROFUNDO
# =========================================================

if painel == "Monte Carlo Profundo":
    st.markdown("## üé≤ Monte Carlo Profundo")
    if df.empty:
        st.warning("Carregue hist√≥rico primeiro.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    mc = gerar_monte_carlo(df, nucleo, regime_state, n_sim=80)

    st.session_state["mc_df"] = mc

    st.markdown("### üîπ N√∫cleo Resiliente Usado")
    st.write(nucleo)

    st.markdown("### üîπ Simula√ß√µes Monte Carlo")
    st.dataframe(mc, use_container_width=True)

    st.stop()
# =========================================================
# BACKTEST INTERNO (Simula√ß√£o Retroativa)
# =========================================================

def executar_backtest_interno(df: pd.DataFrame, nucleo: List[int]) -> pd.DataFrame:
    """
    Backtest Interno:
    - testa o n√∫cleo atual contra trechos passados semelhantes.
    - mede coer√™ncia estrutural retrospectiva (simplificado).
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    ultimas = df.tail(80)[["n1", "n2", "n3", "n4", "n5", "n6"]].values
    nuc = np.array(nucleo)

    linhas = []
    for idx, linha in enumerate(ultimas):
        acertos = len(set(linha.tolist()) & set(nucleo))
        linhas.append([idx] + linha.tolist() + [acertos])

    cols = ["id", "n1", "n2", "n3", "n4", "n5", "n6", "acertos"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: BACKTEST INTERNO
# =========================================================

if painel == "Backtest Interno":
    st.markdown("## üïí Backtest Interno (Retroativo)")
    if df.empty:
        st.warning("Carregue hist√≥rico.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    bt = executar_backtest_interno(df, nucleo)

    st.session_state["backtest_interno"] = bt

    st.markdown("### üîπ N√∫cleo Resiliente")
    st.write(nucleo)

    st.markdown("### üîπ Backtest Interno ‚Äî √öltimas 80 s√©ries")
    st.dataframe(bt, use_container_width=True)

    st.stop()


# =========================================================
# BACKTEST DO FUTURO (BTF)
# =========================================================

def executar_backtest_do_futuro(df: pd.DataFrame, nucleo: List[int]) -> pd.DataFrame:
    """
    Backtest do Futuro:
    - simula como o n√∫cleo atual se comportaria em trechos passados longos.
    - valida coer√™ncia retrospectiva (BTF oficial).
    """
    if df.empty or nucleo is None:
        return pd.DataFrame()

    linhas = []
    for idx in range(len(df) - 1):
        real = df.iloc[idx + 1][["n1", "n2", "n3", "n4", "n5", "n6"]].values
        acertos = len(set(real.tolist()) & set(nucleo))
        linhas.append([idx] + real.tolist() + [acertos])

    cols = ["id", "real1", "real2", "real3", "real4", "real5", "real6", "acertos"]
    return pd.DataFrame(linhas, columns=cols)


# =========================================================
# PAINEL: BACKTEST DO FUTURO
# =========================================================

if painel == "Backtest do Futuro":
    st.markdown("## üîÆ Backtest do Futuro (Coer√™ncia Retroativa)")

    if df.empty:
        st.warning("Carregue o hist√≥rico.")
        st.stop()

    nucleo = gerar_nucleo_resiliente(df, regime_state)
    btf = executar_backtest_do_futuro(df, nucleo)

    st.session_state["btf_raw"] = btf

    st.markdown("### üîπ N√∫cleo Usado no BTF")
    st.write(nucleo)

    st.markdown("### üîπ Backtest do Futuro ‚Äî Acur√°cia Estrutural")
    st.dataframe(btf.tail(50), use_container_width=True)

    st.stop()


# =========================================================
# LEQUE TURBO ‚Äî BASE (pr√©-s√©ries antes do controle final)
# =========================================================

def gerar_series_base(df: pd.DataFrame, regime: RegimeState) -> Dict[str, List[List[int]]]:
    """
    Gera:
    - N√∫cleo Final Turbo
    - S√©ries Premium iniciais
    - S√©ries Estruturais iniciais
    - S√©ries de Cobertura (b√°sico)
    OBS: O refinamento final vem na PARTE 6 e 7.
    """
    nucleo = gerar_nucleo_resiliente(df, regime)

    if not nucleo:
        return {
            "nucleo": [],
            "premium": [],
            "estruturais": [],
            "cobertura": [],
        }

    base = sorted(nucleo)

    # S√©ries Premium (leve varia√ß√£o)
    premium = []
    for offset in [-1, 1]:
        p = [min(80, max(1, x + offset)) for x in base]
        p = sorted(set(p))[:6]
        premium.append(p)

    # S√©ries Estruturais (duas variantes)
    estruturais = []
    e1 = [min(80, x + 2) for x in base]
    e2 = [max(1, x - 2) for x in base]
    estruturais.append(sorted(set(e1))[:6])
    estruturais.append(sorted(set(e2))[:6])

    # Cobertura (perturba√ß√µes mais amplas)
    cobertura = []
    c1 = [min(80, x + 3) for x in base]
    c2 = [max(1, x - 3) for x in base]
    cobertura.append(sorted(set(c1))[:6])
    cobertura.append(sorted(set(c2))[:6])

    return {
        "nucleo": base,
        "premium": premium,
        "estruturais": estruturais,
        "cobertura": cobertura,
    }


# =========================================================
# PAINEL: LEQUE TURBO (BASE)
# =========================================================

if painel == "Leque TURBO":
    st.markdown("## üöÄ Leque TURBO ‚Äî Base Estrutural")

    if df.empty:
        st.warning("Carregue hist√≥rico.")
        st.stop()

    leque = gerar_series_base(df, regime_state)
    st.session_state["leque_turbo"] = leque

    st.markdown("### üîπ N√∫cleo Final (base)")
    st.write(leque["nucleo"])

    st.markdown("### üîπ S√©ries Premium (base)")
    st.write(leque["premium"])

    st.markdown("### üîπ S√©ries Estruturais (base)")
    st.write(leque["estruturais"])

    st.markdown("### üîπ S√©ries de Cobertura (base)")
    st.write(leque["cobertura"])

    st.stop()
# =========================================================
# LEQUE TURBO ‚Äî FLAT TABLE + MODOS DE SA√çDA
# =========================================================

def build_flat_series_table(leque: Dict[str, Any]) -> pd.DataFrame:
    """
    Constr√≥i uma tabela plana com todas as s√©ries do Leque TURBO.
    Colunas:
    - category
    - series (lista de ints)
    - coherence (0 a 1)
    - expected_hits (1 a 6)
    """
    rows = []

    if not leque:
        return pd.DataFrame(columns=["category", "series", "coherence", "expected_hits"])

    # N√∫cleo principal
    nucleo = leque.get("nucleo", [])
    if nucleo:
        rows.append({
            "category": "N√öCLEO TURBO",
            "series": sorted(nucleo),
            "coherence": 0.90,
            "expected_hits": 4,
        })

    # Premium
    for serie in leque.get("premium", []):
        rows.append({
            "category": "Premium",
            "series": sorted(serie),
            "coherence": 0.82,
            "expected_hits": 3,
        })

    # Estruturais
    for serie in leque.get("estruturais", []):
        rows.append({
            "category": "Estrutural",
            "series": sorted(serie),
            "coherence": 0.74,
            "expected_hits": 2,
        })

    # Cobertura
    for serie in leque.get("cobertura", []):
        rows.append({
            "category": "Cobertura",
            "series": sorted(serie),
            "coherence": 0.65,
            "expected_hits": 1,
        })

    # S6 (se dispon√≠vel em sess√£o)
    s6_df = st.session_state.get("s6_df", pd.DataFrame())
    if not s6_df.empty:
        for _, row in s6_df.iterrows():
            serie = [int(row[c]) for c in ["n1", "n2", "n3", "n4", "n5", "n6"]]
            rows.append({
                "category": "S6",
                "series": sorted(serie),
                "coherence": 0.87,
                "expected_hits": 5,
            })

    if not rows:
        return pd.DataFrame(columns=["category", "series", "coherence", "expected_hits"])

    flat_df = pd.DataFrame(rows)
    return flat_df


def limit_by_mode(
    flat_df: pd.DataFrame,
    regime: Optional[RegimeState],
    output_mode: str,
    n_series_fixed: int,
    min_conf_pct: int,
) -> pd.DataFrame:
    """
    Aplica os tr√™s modos de controle:
    - Autom√°tico (por regime)
    - Quantidade fixa
    - Confiabilidade m√≠nima
    """
    if flat_df.empty:
        return flat_df

    df_sorted = flat_df.sort_values("coherence", ascending=False).reset_index(drop=True)

    # Modo autom√°tico por regime
    if output_mode.startswith("Autom√°tico"):
        if regime is None:
            target = min(12, len(df_sorted))
            return df_sorted.head(target)

        if regime.nome == "Resiliente":
            target = 10
            conf_min = 0.70
        elif regime.nome == "Intermedi√°rio":
            target = 12
            conf_min = 0.60
        else:  # Turbulento
            target = 15
            conf_min = 0.50

        filtrado = df_sorted[df_sorted["coherence"] >= conf_min].head(target)
        if filtrado.empty:
            return df_sorted.head(target)
        return filtrado

    # Modo quantidade fixa
    if output_mode.startswith("Quantidade"):
        return df_sorted.head(min(n_series_fixed, len(df_sorted)))

    # Modo confiabilidade m√≠nima
    if output_mode.startswith("Confiabilidade"):
        thr = min_conf_pct / 100.0
        filtrado = df_sorted[df_sorted["coherence"] >= thr]
        if filtrado.empty:
            # fallback
            return df_sorted.head(8)
        return filtrado.reset_index(drop=True)

    return df_sorted



# =========================================================
# LOGS T√âCNICOS ‚Äî REGISTRO E PAINEL
# =========================================================

def add_log(etapa: str, dados: Any):
    """
    Registra um log t√©cnico no session_state["logs_tecnicos"].
    Pode ser chamado em qualquer etapa do pipeline.
    """
    if "logs_tecnicos" not in st.session_state:
        st.session_state["logs_tecnicos"] = []
    st.session_state["logs_tecnicos"].append(
        {
            "etapa": etapa,
            "dados": dados,
        }
    )


if painel == "Logs T√©cnicos":
    st.markdown("## üß∞ Logs T√©cnicos ‚Äî Pipeline V13.8-TURBO")

    logs = st.session_state.get("logs_tecnicos", [])

    if not logs:
        st.info("Nenhum log t√©cnico registrado ainda.")
        st.stop()

    for registro in logs:
        with st.expander(f"Etapa: {registro['etapa']}"):
            st.write(registro["dados"])

    st.stop()


# =========================================================
# DIAGN√ìSTICO PROFUNDO ‚Äî GR√ÅFICOS E ESTABILIDADE
# =========================================================

def plot_line(data, title, ylabel):
    fig, ax = plt.subplots(figsize=(8, 3))
    ax.plot(data)
    ax.set_title(title)
    ax.set_ylabel(ylabel)
    ax.set_xlabel("√çndice")
    ax.grid(True, linestyle="--", alpha=0.4)
    st.pyplot(fig)


def plot_hist(data, title, xlabel):
    fig, ax = plt.subplots(figsize=(8, 3))
    ax.hist(data, bins=20, edgecolor="black", alpha=0.7)
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel("Frequ√™ncia")
    ax.grid(True, linestyle="--", alpha=0.4)
    st.pyplot(fig)


def calcular_indice_estabilidade(regime_state: Optional[RegimeState]) -> Optional[float]:
    """
    √çndice composto de estabilidade da estrada:
    ~1.0 ‚Üí muito est√°vel
    ~0.5 ‚Üí intermedi√°rio
    ~0.0 ‚Üí inst√°vel / turbulento
    """
    if not regime_state:
        return None

    disp_peso = max(0.0, 1.0 - regime_state.dispersao / 40.0)
    amp_peso = max(0.0, 1.0 - regime_state.amplitude / 60.0)
    vib_peso = max(0.0, 1.0 - regime_state.vibracao / 30.0)
    par_peso = min(1.0, len(regime_state.pares) / 10.0)

    score = (disp_peso + amp_peso + vib_peso + par_peso) / 4.0
    return score


if painel == "Diagn√≥stico Profundo":
    st.markdown("## üß≠ Diagn√≥stico Profundo ‚Äî Estrutura da Estrada")

    if df.empty:
        st.warning("Carregue um hist√≥rico para visualizar diagn√≥stico.")
        st.stop()

    # Curvas estruturais b√°sicas
    st.markdown("### üìà Dispers√£o e Amplitude ao Longo do Tempo")

    dispersoes = df.apply(
        lambda row: np.std([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]]),
        axis=1,
    )
    amplitudes = df.apply(
        lambda row: max([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]])
        - min([row["n1"], row["n2"], row["n3"], row["n4"], row["n5"], row["n6"]]),
        axis=1,
    )

    plot_line(dispersoes, "Dispers√£o das S√©ries", "Dispers√£o")
    plot_line(amplitudes, "Amplitude das S√©ries", "Amplitude")

    # Vibra√ß√£o
    st.markdown("### üåê Vibra√ß√£o Estrutural")
    vib = np.abs(dispersoes.diff().fillna(0))
    plot_line(vib, "Varia√ß√£o da Dispers√£o (Vibra√ß√£o)", "Vibra√ß√£o")

    # Backtest Interno ‚Äî distribui√ß√£o de acertos
    st.markdown("### üéØ Distribui√ß√£o de Acertos ‚Äî Backtest Interno")
    bti = st.session_state.get("backtest_interno", pd.DataFrame())
    if not bti.empty and "acertos" in bti.columns:
        plot_hist(bti["acertos"], "Distribui√ß√£o de Acertos (Backtest Interno)", "Acertos")
    else:
        st.info("Backtest Interno ainda n√£o foi executado.")

    # Backtest do Futuro ‚Äî distribui√ß√£o de acertos
    st.markdown("### üîÆ Distribui√ß√£o de Acertos ‚Äî Backtest do Futuro")
    btf = st.session_state.get("btf_raw", pd.DataFrame())
    if not btf.empty and "acertos" in btf.columns:
        plot_hist(btf["acertos"], "Distribui√ß√£o de Acertos (Backtest do Futuro)", "Acertos")
    else:
        st.info("Backtest do Futuro ainda n√£o foi executado.")

    # Estabilidade global
    st.markdown("### üß© √çndice Global de Estabilidade")
    est = calcular_indice_estabilidade(regime_state)
    if est is None:
        st.info("Regime ainda n√£o calculado.")
    else:
        st.metric("Estabilidade Estrutural", f"{est * 100:.1f}%")
        if est >= 0.75:
            st.success("Estrada EST√ÅVEL (tend√™ncia resiliente).")
        elif est >= 0.50:
            st.warning("Estrada MODERADA (estado intermedi√°rio).")
        else:
            st.error("Estrada INST√ÅVEL / Turbulenta.")

    st.stop()
# =========================================================
# PAINEL ‚Äî EXPORTAR RESULTADOS (TXT / CSV)
# =========================================================

def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8")


def text_to_bytes(text: str) -> bytes:
    return text.encode("utf-8")


if painel == "Exportar Resultados":
    st.markdown("## üì§ Exportar Resultados (TXT / CSV)")

    # Usamos o leque final controlado
    leque = gerar_series_base(df, regime_state)
    flat_df = build_flat_series_table(leque)
    controlled_df = limit_by_mode(
        flat_df,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )

    if controlled_df.empty:
        st.warning("Nenhuma s√©rie dispon√≠vel para exporta√ß√£o.")
        st.stop()

    # CSV
    st.markdown("### üü¶ Baixar CSV (Leque Final)")
    csv_bytes = df_to_csv_bytes(controlled_df)
    st.download_button(
        "üì• Download CSV",
        data=csv_bytes,
        file_name="leque_turbo.csv",
        mime="text/csv",
    )

    # TXT puro
    st.markdown("### üü© Baixar TXT (Lista Pura)")
    lista_pura = []
    for i, (_, row) in enumerate(controlled_df.iterrows()):
        ss = " ".join(str(x) for x in row["series"])
        lista_pura.append(f"{i+1}) {ss}")

    txt_bytes = text_to_bytes("\n".join(lista_pura))

    st.download_button(
        "üì• Download TXT",
        data=txt_bytes,
        file_name="lista_pura.txt",
        mime="text/plain",
    )

    st.stop()


# =========================================================
# PAINEL ‚Äî EXPORTAR SESS√ÉO COMPLETA (ZIP)
# =========================================================

def build_session_zip() -> bytes:
    """
    Gera um ZIP com:
    - hist√≥rico carregado
    - regime
    - n√∫cleo
    - leque final
    - lista pura
    - S6
    - Monte Carlo
    - backtests
    - logs t√©cnicos
    """
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w") as z:

        # Hist√≥rico
        if not df.empty:
            z.writestr("historico.csv", df.to_csv(index=False))

        # Regime
        if regime_state:
            z.writestr(
                "regime.json",
                json.dumps(regime_state.__dict__, indent=2),
            )

        # N√∫cleo Resiliente
        nucleo = gerar_nucleo_resiliente(df, regime_state)
        z.writestr("nucleo.json", json.dumps(nucleo))

        # Leque Final (CSV)
        leque_final = gerar_series_base(df, regime_state)
        flat_df = build_flat_series_table(leque_final)
        z.writestr("leque_flat.csv", flat_df.to_csv(index=False))

        # Lista pura
        lista_pura = [
            f"{i+1}) " + " ".join(str(x) for x in row["series"])
            for i, (_, row) in enumerate(flat_df.iterrows())
        ]
        z.writestr("lista_pura.txt", "\n".join(lista_pura))

        # S6
        s6_df = st.session_state.get("s6_df", pd.DataFrame())
        if not s6_df.empty:
            z.writestr("s6.csv", s6_df.to_csv(index=False))

        # Monte Carlo
        mc_df = st.session_state.get("mc_df", pd.DataFrame())
        if not mc_df.empty:
            z.writestr("monte_carlo.csv", mc_df.to_csv(index=False))

        # Backtest Interno
        bti = st.session_state.get("backtest_interno", pd.DataFrame())
        if not bti.empty:
            z.writestr("backtest_interno.csv", bti.to_csv(index=False))

        # Backtest do Futuro
        btf = st.session_state.get("btf_raw", pd.DataFrame())
        if not btf.empty:
            z.writestr("backtest_futuro.csv", btf.to_csv(index=False))

        # Logs t√©cnicos
        logs = st.session_state.get("logs_tecnicos", [])
        z.writestr("logs_tecnicos.json", json.dumps(logs, indent=2))

    buffer.seek(0)
    return buffer.read()


if painel == "Exportar Sess√£o Completa":
    st.markdown("## üì¶ Exportar Sess√£o Completa (ZIP)")

    if df.empty:
        st.warning("Carregue hist√≥rico para exportar sess√£o.")
        st.stop()

    zip_bytes = build_session_zip()

    st.download_button(
        "üì• Baixar ZIP Completo",
        data=zip_bytes,
        file_name="predictcars_v13.8_turbo_session.zip",
        mime="application/zip",
    )

    st.stop()
# =========================================================
# M√ìDULO S ‚Äî Protocolos S1‚ÄìS5 + Ajuste Fino Global (AFG)
# =========================================================
# Objetivo:
# - Detectar conflitos estruturais NG vs NL
# - Aplicar corre√ß√µes macro (S1‚ÄìS4)
# - Aplicar ajuste fino (S5) em faixas cr√≠ticas
# - Permitir comparar:
#   ‚Ä¢ Leque ORIGINAL (sem corre√ß√£o)
#   ‚Ä¢ Leque CORRIGIDO (com S1‚ÄìS5 + AFG)
#   em um painel dedicado.
# =========================================================


# ---------------------------------------------------------
# 1) N√∫cleos Global (NG) e Local (NL)
# ---------------------------------------------------------

def gerar_nucleo_global(df: pd.DataFrame, regime: RegimeState) -> List[int]:
    """NG ‚Äî N√∫cleo Global (usa todo o hist√≥rico via V13.8-TURBO)."""
    return gerar_nucleo_resiliente(df, regime)


def gerar_nucleo_local(df: pd.DataFrame, regime: RegimeState, janela: int = 40) -> List[int]:
    """
    NL ‚Äî N√∫cleo Local:
    - usa apenas as √∫ltimas N s√©ries (`janela`)
    - captura motorista de curto trecho / comportamento local
    """
    if df.empty:
        return []
    trecho = df.tail(min(janela, len(df)))
    return gerar_nucleo_resiliente(trecho, regime)


# ---------------------------------------------------------
# 2) M√©tricas de Conflito: MUC, dispers√£o, zona final
# ---------------------------------------------------------

@dataclass
class SMetricasConflito:
    muc: float
    d_faixas: float
    d_clusters: float
    d_mediana: float
    d_disp: float
    d_zona: float
    aciona_s1: bool
    aciona_s2: bool
    aciona_s3: bool
    aciona_s4: bool


def _faixa_media(serie: List[int]) -> float:
    if not serie:
        return 0.0
    return float(np.mean(serie))


def _mediana_serie(serie: List[int]) -> float:
    if not serie:
        return 0.0
    return float(np.median(serie))


def _pseudo_cluster(serie: List[int]) -> float:
    """
    Proxy simples para clusters / motoristas:
    - calcula m√©dia dos deltas entre vizinhos.
    """
    if len(serie) < 2:
        return 0.0
    arr = np.array(sorted(serie))
    deltas = np.diff(arr)
    return float(np.mean(deltas))


def calcular_metricas_conflito_s(
    df: pd.DataFrame,
    regime: Optional[RegimeState],
    janela_local: int = 40,
) -> Optional[SMetricasConflito]:
    """
    Calcula:
    - NG (n√∫cleo global)
    - NL (n√∫cleo local)
    - D_faixas, D_clusters, D_mediana
    - D_disp (dispers√£o prevista vs real)
    - D_zona (zona final prevista vs real)
    - MUC = m√©dia das tr√™s primeiras
    Define gatilhos para S1‚ÄìS4 com limiares heur√≠sticos.
    """
    if df.empty or regime is None:
        return None

    ng = gerar_nucleo_global(df, regime)
    nl = gerar_nucleo_local(df, regime, janela_local)

    if not ng or not nl:
        return None

    # faixas
    d_faixas = abs(_faixa_media(ng) - _faixa_media(nl))

    # clusters aproximados
    d_clusters = abs(_pseudo_cluster(ng) - _pseudo_cluster(nl))

    # mediana
    d_mediana = abs(_mediana_serie(ng) - _mediana_serie(nl))

    muc = (d_faixas + d_clusters + d_mediana) / 3.0

    # Dispers√£o prevista x real (√∫ltimas s√©ries)
    nums = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values
    disp_real = float(np.mean(np.std(nums, axis=1)))
    disp_prev = float(np.std(np.array(ng)))
    d_disp = abs(disp_prev - disp_real)

    # Zona final (√∫ltimo passageiro da s√©rie / n√∫cleo)
    ultimo_real = float(np.mean(nums[:, -1]))  # m√©dia dos √∫ltimos passageiros
    ultimo_prev = float(sorted(ng)[-1])
    d_zona = abs(ultimo_prev - ultimo_real)

    # Limiar heur√≠stico (podem ser recalibrados via backtest)
    theta_global = 6.0   # conflito forte NG vs NL
    theta_local = 4.0    # conflito local acentuado
    theta_disp = 5.0     # dispers√£o at√≠pica
    theta_zf = 5.0       # zona final desalinhada

    aciona_s1 = muc > theta_global
    aciona_s2 = (muc > theta_local) and not aciona_s1
    aciona_s3 = d_disp > theta_disp
    aciona_s4 = d_zona > theta_zf

    return SMetricasConflito(
        muc=muc,
        d_faixas=d_faixas,
        d_clusters=d_clusters,
        d_mediana=d_mediana,
        d_disp=d_disp,
        d_zona=d_zona,
        aciona_s1=aciona_s1,
        aciona_s2=aciona_s2,
        aciona_s3=aciona_s3,
        aciona_s4=aciona_s4,
    )


# ---------------------------------------------------------
# 3) Macrocorre√ß√µes S1‚ÄìS4 sobre o n√∫cleo / leque
# ---------------------------------------------------------

def aplicar_anti_s1(nucleo: List[int]) -> List[int]:
    """
    Anti-S1 ‚Äî N√∫cleo supercomprimido:
    - aumenta levemente dispers√£o
    - reintroduz "segunda for√ßa" via deslocamento suave
    """
    if not nucleo:
        return []
    base = sorted(nucleo)
    # empurra alguns elementos para abrir a faixa
    ajustado = []
    for i, x in enumerate(base):
        if i == 0:
            ajustado.append(x)
        else:
            if x - ajustado[-1] < 3:
                ajustado.append(ajustado[-1] + 3)
            else:
                ajustado.append(x)
    return sorted(set(min(80, max(1, v)) for v in ajustado))[:6]


def aplicar_anti_s2(ng: List[int], nl: List[int]) -> List[int]:
    """
    Anti-S2 ‚Äî Motorista de curto trecho:
    - N√∫cleo final = interse√ß√£o NG‚à©NL + 1‚Äì2 dominantes locais
    """
    if not ng or not nl:
        return sorted(set(ng or nl))[:6]

    inter = sorted(set(ng) & set(nl))
    locais = [x for x in nl if x not in inter]

    # garante interse√ß√£o
    resultado = inter.copy()

    # adiciona at√© 2 dominantes locais
    for x in locais:
        if len(resultado) >= 6:
            break
        resultado.append(x)

    # completa, se faltar, com NG
    for x in ng:
        if len(resultado) >= 6:
            break
        if x not in resultado:
            resultado.append(x)

    return sorted(set(resultado))[:6]


def aplicar_anti_s3(nucleo: List[int], disp_alvo: float) -> List[int]:
    """
    Anti-S3 ‚Äî Dispers√£o at√≠pica:
    - ajusta extremos para aproximar dispers√£o de disp_alvo.
    """
    if not nucleo:
        return []

    base = sorted(nucleo)
    disp_atual = float(np.std(np.array(base)))
    # heur√≠stica simples: se muito menor, abre extremos; se muito maior, puxa
    if disp_atual < disp_alvo:
        base[0] = max(1, base[0] - 1)
        base[-1] = min(80, base[-1] + 1)
    elif disp_atual > disp_alvo:
        base[0] = min(base[-1], base[0] + 1)
        base[-1] = max(base[0], base[-1] - 1)

    return sorted(set(base))[:6]


def aplicar_anti_s4(nucleo: List[int], ultimo_real: float) -> List[int]:
    """
    Anti-S4 ‚Äî Zona final desalinhada:
    - ajusta o √∫ltimo passageiro em dire√ß√£o √† m√©dia real da cauda.
    """
    if not nucleo:
        return []
    base = sorted(nucleo)
    alvo = int(round(ultimo_real))
    # move s√≥ o √∫ltimo elemento
    base[-1] = min(80, max(1, alvo))
    return sorted(set(base))[:6]


def aplicar_macro_s1_s4(
    df: pd.DataFrame,
    regime: RegimeState,
    metricas: SMetricasConflito,
) -> List[int]:
    """
    Aplica S1‚ÄìS4 sobre o n√∫cleo global, retornando n√∫cleo macro-corrigido.
    """
    ng = gerar_nucleo_global(df, regime)
    nl = gerar_nucleo_local(df, regime, janela=40)
    if not ng:
        return []

    nuc = ng.copy()

    # Dispers√£o real alvo
    nums = df[["n1", "n2", "n3", "n4", "n5", "n6"]].values
    disp_real = float(np.mean(np.std(nums, axis=1)))
    ultimo_real = float(np.mean(nums[:, -1]))

    if metricas.aciona_s1:
        nuc = aplicar_anti_s1(nuc)

    if metricas.aciona_s2:
        nuc = aplicar_anti_s2(nuc, nl)

    if metricas.aciona_s3:
        nuc = aplicar_anti_s3(nuc, disp_real)

    if metricas.aciona_s4:
        nuc = aplicar_anti_s4(nuc, ultimo_real)

    return sorted(set(nuc))[:6]


# ---------------------------------------------------------
# 4) Ajuste Fino Global (AFG) + S5 (permuta√ß√µes finas)
# ---------------------------------------------------------

def identificar_faixas_criticas(serie: List[int]) -> List[Tuple[int, int]]:
    """
    Identifica pares de valores muito pr√≥ximos (candidatos equivalentes).
    Ex.: (30, 32), (45, 47) etc.
    """
    if len(serie) < 2:
        return []
    arr = sorted(serie)
    criticos = []
    for i in range(len(arr) - 1):
        if abs(arr[i+1] - arr[i]) <= 2:
            criticos.append((arr[i], arr[i+1]))
    return criticos


def aplicar_s5_permuta_fina(serie: List[int]) -> List[List[int]]:
    """
    S5 ‚Äî Permuta√ß√µes finas em faixas cr√≠ticas:
    - troca apenas dois elementos em faixas cr√≠ticas
    - mant√©m sempre 6 passageiros
    - N√ÉO usa set(), N√ÉO redefine, N√ÉO corta lista
    """
    base = sorted(serie)
    criticos = identificar_faixas_criticas(base)

    if not criticos:
        return []

    variacoes = []

    # limite de no m√°ximo 2 varia√ß√µes
    for par in criticos[:2]:
        a, b = par

        # s√≥ cria permuta√ß√£o se ambos est√£o na s√©rie
        if a in base and b in base:
            s = base.copy()
            i = s.index(a)
            j = s.index(b)

            # troca simples (permuta controlada)
            s[i], s[j] = s[j], s[i]

            # garantir que continua com 6 n√∫meros ordenados
            variacoes.append(sorted(s))

    # remover duplica√ß√µes
    limpas = []
    for v in variacoes:
        if v not in limpas:
            limpas.append(v)

    return limpas



def aplicar_ajuste_fino_global(
    flat_df: pd.DataFrame,
    score_min: float = 0.70,
) -> pd.DataFrame:
    """
    AFG:
    - atua somente em s√©ries com coherence >= score_min
    - aplica S5 para gerar varia√ß√µes finas em faixas cr√≠ticas
    - n√£o altera s√©ries base, apenas adiciona varia√ß√µes derivadas
    """
    if flat_df.empty:
        return flat_df

    linhas = []
    # Copia todas as s√©ries originais
    for _, row in flat_df.iterrows():
        linhas.append(row.to_dict())

    # Ajuste fino apenas nas s√©ries mais fortes
    foco = flat_df[flat_df["coherence"] >= score_min]

    for _, row in foco.iterrows():
        serie_base = row["series"]
        variacoes = aplicar_s5_permuta_fina(serie_base)
        for v in variacoes:
            novo = row.to_dict()
            novo["series"] = sorted(v)
            # leve ajuste na coherence / expected_hits (refinamento)
            novo["coherence"] = min(1.0, float(novo["coherence"]) + 0.02)
            novo["expected_hits"] = min(6, int(novo["expected_hits"]) + 0)
            novo["category"] = f"{row['category']}+S5"
            linhas.append(novo)
 
    # Padronizar e filtrar s√©ries v√°lidas antes de remover duplicatas
    df_temp = pd.DataFrame(linhas)

    # 1) manter apenas s√©ries "de verdade":
    #    - listas/tuplas
    #    - com exatamente 6 n√∫meros
    #    (descarta vetores estranhos tipo 0 1 1 1 2 3 3 3 3 3 4 6)
    def _serie_valida(s):
        if isinstance(s, (list, tuple)):
            if len(s) != 6:
                return False
            # opcional: garantir que s√£o inteiros entre 1 e 80
            try:
                return all(isinstance(x, (int, float)) and 1 <= int(x) <= 80 for x in s)
            except Exception:
                return False
        return False

    df_temp = df_temp[df_temp["series"].apply(_serie_valida)].copy()

    # 2) converter a lista em string para poder usar drop_duplicates
    df_temp["series"] = df_temp["series"].apply(
        lambda s: " ".join(str(int(x)) for x in s)  # garante "n1 n2 n3 n4 n5 n6"
    )

    # 3) remover duplicatas e ordenar por coherence
    df_out = df_temp.drop_duplicates(subset=["category", "series"])
    df_out = df_out.sort_values("coherence", ascending=False).reset_index(drop=True)
    return df_out




# ---------------------------------------------------------
# 5) Constru√ß√£o do Leque CORRIGIDO (S1‚ÄìS5)
# ---------------------------------------------------------

def gerar_leque_corrigido(
    df: pd.DataFrame,
    regime: RegimeState,
) -> Dict[str, Any]:
    """
    Gera um leque corrigido:
    - n√∫cleo passa por S1‚ÄìS4
    - s√©ries derivadas passam por AFG + S5
    """
    metricas = calcular_metricas_conflito_s(df, regime)
    if metricas is None:
        # fallback: usa leque base
        return gerar_series_base(df, regime)

    # n√∫cleo corrigido
    nuc_corrigido = aplicar_macro_s1_s4(df, regime, metricas)

    # constr√≥i leque base a partir do n√∫cleo corrigido
    if not nuc_corrigido:
        leque_base = gerar_series_base(df, regime)
    else:
        # reaproveita a l√≥gica de gerar_series_base, mas com n√∫cleo injetado
        leque_base = gerar_series_base(df, regime)
        leque_base["nucleo"] = nuc_corrigido

    # flat base
    flat_base = build_flat_series_table(leque_base)
    # aplica ajuste fino (AFG + S5)
    flat_corrigido = aplicar_ajuste_fino_global(flat_base, score_min=0.70)

    # reconstr√≥i dicion√°rio de listas para o painel de compara√ß√£o
    leque_out = {
        "nucleo": nuc_corrigido,
        "premium": [],
        "estruturais": [],
        "cobertura": [],
        "s6": [],
    }
    # Fun√ß√£o auxiliar para garantir s√©ries com exatamente 6 n√∫meros
    def _converter_serie(s):
        # caso 1 ‚Äî se vier como string: "12 22 30 35 40 54"
        if isinstance(s, str):
            try:
                nums = [int(x) for x in s.split() if x.isdigit()]
                if len(nums) >= 6:
                    return sorted(nums[:6])
            except:
                pass

        # caso 2 ‚Äî se vier como lista/tupla
        if isinstance(s, (list, tuple)):
            try:
                nums = [int(x) for x in s]
                if len(nums) >= 6:
                    return sorted(nums[:6])
            except:
                pass

        # fallback ‚Äî inv√°lido
        return []

    for _, row in flat_corrigido.iterrows():
        cat = row["category"]
        serie = _converter_serie(row["series"])
        if cat.startswith("N√öCLEO"):
            leque_out["nucleo"] = serie
        elif cat.startswith("Premium"):
            leque_out["premium"].append(serie)
        elif cat.startswith("Estrutural"):
            leque_out["estruturais"].append(serie)
        elif cat.startswith("Cobertura"):
            leque_out["cobertura"].append(serie)
        elif cat.startswith("S6"):
            leque_out.setdefault("s6", []).append(serie)

    return leque_out
# ---------------------------------------------------------
# FUN√á√ÉO ‚Äî UNIR LEQUES ORIGINAL + CORRIGIDO (TURBO++)
# ---------------------------------------------------------

def unir_leques(flat_original: pd.DataFrame, flat_corr: pd.DataFrame) -> pd.DataFrame:
    """
    Junta os dois leques:
    - mant√©m categoria original
    - remove duplicatas
    - reordena por coherence (maior primeiro)
    """
    if flat_original is None or flat_original.empty:
        return flat_corr.copy()

    if flat_corr is None or flat_corr.empty:
        return flat_original.copy()

    df_mix = pd.concat([flat_original, flat_corr], ignore_index=True)

    # remover duplicatas por s√©rie (string ou lista coerente)
    def _key(s):
        if isinstance(s, (list, tuple)):
            return " ".join(str(int(x)) for x in s)
        if isinstance(s, str):
            return s.strip()
        return str(s)

    df_mix["serie_key"] = df_mix["series"].apply(_key)

    df_mix = df_mix.drop_duplicates(subset=["serie_key"])
    df_mix = df_mix.sort_values("coherence", ascending=False).reset_index(drop=True)
    df_mix = df_mix.drop(columns=["serie_key"])

    return df_mix



# =========================================================
# PAINEL ‚Äî SA√çDA FINAL CONTROLADA
# =========================================================

if painel == "Sa√≠da Final Controlada":
    st.markdown("## üéØ Sa√≠da Final Controlada ‚Äî Leque TURBO")

    if df.empty:
        st.warning("Carregue um hist√≥rico para gerar o leque.")
        st.stop()

    # Gera/Regera o leque base
    leque = gerar_series_base(df, regime_state)
    st.session_state["leque_turbo"] = leque
    # Leque corrigido S1‚ÄìS5
    leque_corrigido = gerar_leque_corrigido(df, regime_state)
    flat_corr = build_flat_series_table(leque_corrigido).copy()

    # Criar Leque MISTO (ORIGINAL + CORRIGIDO)
    leque_original = gerar_series_base(df, regime_state)
    flat_original = build_flat_series_table(leque_original)

    flat_mix = unir_leques(flat_original, flat_corr)

    # Aplicar modo de sa√≠da sobre o MIX
    flat_df = limit_by_mode(
        flat_mix,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )


    flat_df = flat_corr.copy()
    if flat_df.empty:
        st.warning("N√£o foi poss√≠vel gerar s√©ries a partir do hist√≥rico atual.")
        st.stop()
    # Criar Leque MISTO TURBO++
    flat_mix = unir_leques(flat_df, flat_corr)
    
    # Aplica modo de sa√≠da
    controlled_df = limit_by_mode(
        flat_mix,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )

    # Monta tabela final
    def montar_tabela_final(df_in: pd.DataFrame) -> pd.DataFrame:
        return pd.DataFrame([
            {
                "Rank": i + 1,
                "Categoria": row["category"],
                "S√©rie": row["series"],
                "Confiabilidade (%)": int(round(row["coherence"] * 100)),
                "Acertos Esperados": int(row["expected_hits"]),
            }
            for i, (_, row) in enumerate(df_in.iterrows())
        ])
    # N√∫cleo Resiliente Final (NRF)
    try:
        nucleo_resiliente = None

        # pega a melhor s√©rie do controlled_df (rank 1)
        if not controlled_df.empty:
            melhor = controlled_df.iloc[0]
            nucleo_resiliente = melhor["series"]

        st.markdown("### ‚≠ê N√∫cleo Resiliente Final (NRF)")
        if nucleo_resiliente:
            st.code(" ".join(str(x) for x in nucleo_resiliente), language="text")
        else:
            st.write("N√∫cleo n√£o dispon√≠vel.")

    except Exception as e:
        st.error(f"Erro ao gerar N√∫cleo Resiliente Final: {e}")

    # =========================================================
    # SENSOR AMBIENTAL k* ‚Äî MODO SIMPLES (Compat√≠vel com V13.8)
    # =========================================================
    try:
        # Hist√≥rico completo
        df_hist = df.copy()

        # Fun√ß√£o para renomear colunas corretamente
        if df_hist.shape[1] >= 8:
            df_hist.columns = ["id", "n1", "n2", "n3", "n4", "n5", "n6", "k"]
        else:
            # fallback: se vier sem ID
            if df_hist.shape[1] == 7:
                df_hist.columns = ["n1", "n2", "n3", "n4", "n5", "n6", "k"]
                df_hist["id"] = None
            else:
                df_hist["k"] = 0  # pior caso

        # √öltimos valores de k
        ultimos_k = df_hist["k"].tail(5).tolist()

        # Detecta ruptura recente (k != 0)
        ruptura_recente = (df_hist["k"].iloc[-1] != 0)

        # L√≥gica do sensor
        if ruptura_recente:
            k_estado = "critico"
        else:
            if any(k != 0 for k in ultimos_k):
                k_estado = "atencao"
            else:
                k_estado = "estavel"

        # Exibir badge ambiental
        st.markdown("### üå°Ô∏è Estado Ambiental da Estrada (k*)")
        st.markdown(contexto_k_texto(k_estado, prefixo="k*"))

    except Exception as e:
        st.error(f"Erro no sensor k* simples: {e}")

def contexto_k_texto(k_estado: str, prefixo: str = "k*") -> str:
    """
    Gera o texto padr√£o para o estado k* ou kÃÇ.
    k_estado: "estavel", "atencao" ou "critico"
    prefixo: r√≥tulo exibido (ex.: "k*", "kÃÇ", "k efetivo")
    """
    if k_estado == "estavel":
        return f"üü¢ {prefixo}: Ambiente est√°vel ‚Äî previs√£o em regime normal."
    elif k_estado == "atencao":
        return f"üü° {prefixo}: Pr√©-ruptura residual ‚Äî usar previs√£o com aten√ß√£o."
    else:
        return f"üî¥ {prefixo}: Ambiente cr√≠tico ‚Äî usar previs√£o com cautela m√°xima."

def calcular_sdm(df, janela=8):
    """
    SDM ‚Äî Similaridade Din√¢mica do Momento.
    Mede qu√£o parecidos s√£o os √∫ltimos trechos entre si.
    Retorna valor entre 0 e 1.
    """

    try:
        if df is None or df.empty or len(df) < janela + 1:
            return 0.5  # neutro

        # Extrair √∫ltimos n1..n6
        recentes = df[["n1","n2","n3","n4","n5","n6"]].tail(janela + 1).values

        atual = recentes[-1]
        anteriores = recentes[:-1]

        sims = []
        for linha in anteriores:
            dist = abs(linha - atual).sum()
            sim = 1 / (1 + dist)
            sims.append(sim)

        return float(sum(sims) / len(sims))

    except:
        return 0.5  # fallback neutro
def calcular_t_norm(df, janela=10):
    """
    T_norm ‚Äî Turbul√™ncia Normalizada.
    Mede quanta oscila√ß√£o existe nos √∫ltimos trechos.
    Retorna valor entre 0 e 1.
    """

    try:
        if df is None or df.empty or len(df) < janela:
            return 0.5  # neutro

        # pegar √∫ltimos trechos n1..n6
        bloco = df[["n1","n2","n3","n4","n5","n6"]].tail(janela).values

        # medir dispers√£o m√©dia entre trechos
        variacoes = []
        for i in range(1, len(bloco)):
            dist = abs(bloco[i] - bloco[i-1]).sum()
            variacoes.append(dist)

        media = sum(variacoes) / len(variacoes)

        # normaliza entre 0 e 1 usando fun√ß√£o suave
        t_norm = 1 - (1 / (1 + media))

        return float(t_norm)

    except:
        return 0.5  # fallback neutro
def calcular_entropia_k(df, janela=10):
    """
    Entropia direcional do k.
    Mede a irregularidade do comportamento do k recente.
    Retorna valor entre 0 e 1.
    """

    try:
        if df is None or df.empty or "k" not in df.columns:
            return 0.5  # neutro

        # √∫ltimos valores de k
        k_vals = df["k"].tail(janela).tolist()

        if len(k_vals) <= 1:
            return 0.5

        # contar mudan√ßas de estado
        mudancas = 0
        for i in range(1, len(k_vals)):
            if (k_vals[i] != 0) != (k_vals[i-1] != 0):
                mudancas += 1

        entropia = mudancas / (len(k_vals) - 1)

        return float(entropia)

    except:
        return 0.5
def calcular_tendencia_k(df, janela=12):
    """
    Tend√™ncia do k (k-slope).
    Indica se o ambiente est√° melhorando (+), piorando (-) ou neutro.
    Retorna: -1, 0 ou +1.
    """

    try:
        if df is None or df.empty or "k" not in df.columns:
            return 0  # neutro

        k_vals = df["k"].tail(janela).tolist()

        if len(k_vals) < 3:
            return 0

        # Converter k em bin√°rio (0 = est√°vel, 1 = alerta/ruptura)
        binario = [1 if k != 0 else 0 for k in k_vals]

        # Eixo x (0,1,2,...)
        xs = list(range(len(binario)))

        # C√°lculo do slope simples (regress√£o linear de 1 vari√°vel)
        n = len(xs)
        media_x = sum(xs) / n
        media_y = sum(binario) / n

        num = sum((xs[i] - media_x) * (binario[i] - media_y) for i in range(n))
        den = sum((xs[i] - media_x) ** 2 for i in range(n))

        slope = num / den if den != 0 else 0

        # Interpreta√ß√£o da tend√™ncia
        if slope > 0.05:
            return +1  # piorando
        elif slope < -0.05:
            return -1  # melhorando
        else:
            return 0   # neutro

    except:
        return 0


def calcular_k_pred(k_estado_atual: str, df):
    """
    k preditivo b√°sico (kÃÇ) ‚Äî vers√£o inicial.
    Nesta fase, apenas retorna o pr√≥prio k_estado_atual.
    Depois, iremos substituir pela vers√£o real com SDM, T_norm, entropia e tend√™ncia.
    """
    try:
        # 1) Calcular sensores avan√ßados
        sdm = calcular_sdm(df)
        tnorm = calcular_t_norm(df)
        ent = calcular_entropia_k(df)
        trend = calcular_tendencia_k(df)

        # 2) Score bruto
        score = (
            0.30 * (1 - sdm) +      # menor similaridade ‚Üí mais cr√≠tico
            0.30 * tnorm +         # mais turbul√™ncia ‚Üí pior
            0.25 * ent +           # mais entropia ‚Üí pior
            0.15 * (trend + 1)/2   # trend: -1,0,+1 ‚Üí normaliza p/ 0..1
        )

        # 3) Classifica√ß√£o por faixas
        if score < 0.33:
            return "estavel"
        elif score < 0.66:
            return "atencao"
        else:
            return "critico"

    except:
        return k_estado_atual

   

def ajustar_n_series_por_k(k_ativo: str, n_series_base: int) -> int:
    """
    Ajuste simples do tamanho do leque com base no k_ativo.
    - estavel  ‚Üí mant√©m o tamanho original
    - atencao  ‚Üí reduz levemente o leque
    - critico  ‚Üí reduz mais o leque, focando nas s√©ries mais fortes
    Sempre respeita um m√≠nimo de 5 s√©ries.
    """
    n = n_series_base

    if k_ativo == "atencao":
        n = max(5, n - 2)
    elif k_ativo == "critico":
        n = max(5, n - 4)

    return n

# Previs√£o Final TURBO
try:
    previsao_final = None
    if not controlled_df.empty:
        melhor = controlled_df.iloc[0]
        previsao_final = melhor["series"]
    prefixo_k = "k*" if k_ativo == k_estado else "kÃÇ"
    contexto_k = contexto_k_texto(k_ativo, prefixo=prefixo_k)
    st.markdown("### üéØ Previs√£o Final TURBO")
    if previsao_final:
        st.code(" ".join(str(x) for x in previsao_final), language="text")
        st.info(contexto_k)
    else:
        st.write("Previs√£o n√£o dispon√≠vel.")

except Exception as e:
    st.error(f"Erro ao gerar Previs√£o Final TURBO: {e}")

# Listas Auxiliares TURBO
try:
    st.markdown("### üß© Listas Auxiliares (Premium / Estruturais / Cobertura)")

    lista_premium = []
    lista_estruturais = []
    lista_cobertura = []

    for _, row in controlled_df.iterrows():
        cat = row["category"]
        ss = " ".join(str(x) for x in row["series"])

        # Ajuste leve por k_ativo (modo simples)
        if k_ativo == "critico":
            # Em ambiente cr√≠tico, remover Cobertura (focar no n√∫cleo forte)
            if "Cobertura" in cat:
                continue
        elif k_ativo == "atencao":
            # Em aten√ß√£o, reduzir Cobertura (deixa passar s√≥ parte)
            import random
            if "Cobertura" in cat and random.random() < 0.5:
                continue

        if cat.startswith("Premium"):
            lista_premium.append(ss)
        elif cat.startswith("Estrutural"):
            lista_estruturais.append(ss)
        elif cat.startswith("Cobertura"):
            lista_cobertura.append(ss)

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("#### ‚≠ê Premium")
        st.text_area("Premium", value="\n".join(lista_premium), height=200)

    with col2:
        st.markdown("#### üß± Estruturais")
        st.text_area("Estruturais", value="\n".join(lista_estruturais), height=200)

    with col3:
        st.markdown("#### üåê Cobertura")
        st.text_area("Cobertura", value="\n".join(lista_cobertura), height=200)

except Exception as e:
    st.error(f"Erro ao gerar listas auxiliares: {e}")


# Lista Pura Final TURBO
try:
    st.markdown("### üìã Lista Pura Final (Numerada)")

    lista_final = []
    for i, (_, row) in enumerate(controlled_df.iterrows()):
        ss = " ".join(str(x) for x in row["series"])
        lista_final.append(f"{i + 1}) {ss}")

    st.text_area(
        "Lista Pura Final",
        value="\n".join(lista_final),
        height=220,
    )

except Exception as e:
    st.error(f"Erro ao gerar Lista Pura Final: {e}")

# Monta tabela para exibi√ß√£o
st.markdown("### üì¶ Leque Final ‚Äî TURBO")
st.dataframe(
    montar_tabela_final(controlled_df),
    use_container_width=True
)

# BOT√ÉO ‚Äî EXPORTAR PREVIS√ÉO TURBO++
if not controlled_df.empty:
    pass

    try:
        texto_exportar = "\n".join(
            " ".join(str(x) for x in row["series"])
            for _, row in controlled_df.iterrows()
        )

        st.markdown("### üì§ Exportar Previs√£o TURBO++")
        st.download_button(
            label="üì• Baixar arquivo .txt com as s√©ries (TURBO++)",
            data=texto_exportar,
            file_name="previsao_turbo_plus.txt",
            mime="text/plain",
        )

    except Exception as e:
        st.error(f"Erro ao exportar arquivo TURBO++: {e}")

st.stop()


# ---------------------------------------------------------
# 6) Painel S1‚ÄìS5 + Ajuste Fino ‚Äî Compara√ß√£o Original vs Corrigido
# ---------------------------------------------------------

if painel == "S1‚ÄìS5 + Ajuste Fino":
    st.markdown("## üåÄ Protocolos S1‚ÄìS5 + Ajuste Fino Global")

    if df.empty or regime_state is None:
        st.warning("Carregue o hist√≥rico para ativar os protocolos S1‚ÄìS5.")
        st.stop()

    # Modo de visualiza√ß√£o
    modo_corr = st.radio(
        "Modo de visualiza√ß√£o:",
        [
            "Somente Leque Original (sem corre√ß√£o)",
            "Somente Leque Corrigido (S1‚ÄìS5 + AFG)",
            "Comparar Lado a Lado",
        ],
        index=2,
    )

    # M√©tricas de conflito
    metricas = calcular_metricas_conflito_s(df, regime_state)
    if metricas is None:
        st.info("N√£o foi poss√≠vel calcular m√©tricas de conflito. Usando apenas leque original.")
        metricas = None

    st.markdown("### üìä M√©trica Universal de Conflito (MUC) e derivados")

    col_m1, col_m2, col_m3 = st.columns(3)
    if metricas:
        col_m1.metric("MUC", f"{metricas.muc:.2f}")
        col_m2.metric("D_faixas", f"{metricas.d_faixas:.2f}")
        col_m3.metric("D_clusters", f"{metricas.d_clusters:.2f}")

        col_m4, col_m5, col_m6 = st.columns(3)
        col_m4.metric("D_mediana", f"{metricas.d_mediana:.2f}")
        col_m5.metric("D_disp", f"{metricas.d_disp:.2f}")
        col_m6.metric("D_zona", f"{metricas.d_zona:.2f}")

        st.markdown("#### üîî Gatilhos S1‚ÄìS4")
        gatilhos = {
            "S1 ‚Äî N√∫cleo supercomprimido": metricas.aciona_s1,
            "S2 ‚Äî Motorista de curto trecho": metricas.aciona_s2,
            "S3 ‚Äî Dispers√£o at√≠pica": metricas.aciona_s3,
            "S4 ‚Äî Zona final desalinhada": metricas.aciona_s4,
        }
        for nome, flag in gatilhos.items():
            if flag:
                st.error(f"{nome} ‚Äî ATIVADO")
            else:
                st.success(f"{nome} ‚Äî Inativo")
    else:
        st.write("M√©tricas indispon√≠veis nesta configura√ß√£o de hist√≥rico.")

    st.markdown("---")

    # Leque ORIGINAL
    leque_original = gerar_series_base(df, regime_state)
    flat_original = build_flat_series_table(leque_original)
    flat_original = limit_by_mode(
        flat_original,
        regime_state,
        output_mode,
        n_series_fixed,
        min_conf_pct,
    )

    # Leque CORRIGIDO
    leque_corrigido = gerar_leque_corrigido(df, regime_state)
    flat_corr = build_flat_series_table(leque_corrigido).copy()

    # Leque MISTO (ORIGINAL + CORRIGIDO)
    flat_mix = unir_leques(flat_original, flat_corr)

    # Aplicar modo de sa√≠da no MIX

    n_series_ajustado = ajustar_n_series_por_k(k_ativo, n_series_fixed)

    flat_corrigido = limit_by_mode(
        flat_mix,
        regime_state,
        output_mode,
        n_series_ajustado,
        min_conf_pct,
    )




    def montar_tabela(flat_df: pd.DataFrame) -> pd.DataFrame:
        return pd.DataFrame([
            {
                "Rank": i + 1,
                "Categoria": row["category"],
                "S√©rie": row["series"],
                "Confiabilidade (%)": int(round(row["coherence"] * 100)),
                "Acertos Esperados": int(row["expected_hits"]),
            }
            for i, (_, row) in enumerate(flat_df.iterrows())
        ])

    if modo_corr.startswith("Somente Leque Original"):
        st.markdown("### üéØ Leque Original (sem corre√ß√µes S1‚ÄìS5)")
        st.dataframe(montar_tabela(flat_original), use_container_width=True)

    elif modo_corr.startswith("Somente Leque Corrigido"):
        st.markdown("### üéØ Leque Corrigido (S1‚ÄìS5 + AFG)")
        st.dataframe(montar_tabela(flat_corrigido), use_container_width=True)

    else:
        st.markdown("### üÜö Compara√ß√£o Lado a Lado")
        c1, c2 = st.columns(2)

        with c1:
            st.markdown("#### üéØ Leque Original")
            st.dataframe(montar_tabela(flat_original), use_container_width=True)

        with c2:
            st.markdown("#### üéØ Leque Corrigido (S1‚ÄìS5 + AFG)")
            st.dataframe(montar_tabela(flat_corrigido), use_container_width=True)
    # Listas puras (para copiar)
    st.markdown("---")
    st.markdown("### üìã Listas Puras ‚Äî Original vs Corrigido")

    lista_orig = [
        f"{i+1}) " + formatar_serie_para_texto(row["series"])
        for i, (_, row) in enumerate(flat_original.iterrows())
    ]

    lista_corr = [
        f"{i+1}) " + formatar_serie_para_texto(row["series"])
        for i, (_, row) in enumerate(flat_corrigido.iterrows())
    ]

    col_o, col_c = st.columns(2)
    with col_o:
        st.markdown("#### Original")
        st.text_area(
            "Lista Pura Original",
            value="\n".join(lista_orig),
            height=300,
        )

    with col_c:
        st.markdown("#### Corrigido (S1‚ÄìS5)")
        st.text_area(
            "Lista Pura Corrigida",
            value="\n".join(lista_corr),
            height=300,
        )

      

    st.stop()
# ---------------------------------------------------------
# 7) Painel TURBO ‚Äî Sa√≠da Final V13.8
# ---------------------------------------------------------

if painel == "Sa√≠da Turbo V13.8":
    st.markdown("## üöÄ Predict Cars V13.8 ‚Äî Sa√≠da Turbo Final")

    if df.empty or regime_state is None:
        st.warning("Carregue o hist√≥rico para ativar a Sa√≠da Turbo.")
        st.stop()

    st.info("Painel Turbo instalado. Falta ativar o motor interno (Passo 4).")

# =========================================================
# PAINEL: COMPARA√á√ÉO k* vs kÃÇ
# =========================================================

if painel == "Compara√ß√£o k* vs kÃÇ":
    st.markdown("## ‚öñÔ∏è Compara√ß√£o entre k* (atual) e kÃÇ (preditivo)")

    if df.empty:
        st.warning("Hist√≥rico vazio ‚Äî carregue um arquivo para comparar.")
        st.stop()

    # --- Contexto com k atual (k*) ---
    prefixo_kA = "k*"
    contextoA = contexto_k_texto(k_estado, prefixo=prefixo_kA)

    # --- Contexto com k preditivo (kÃÇ) ---
    prefixo_kB = "kÃÇ"
    contextoB = contexto_k_texto(k_pred, prefixo=prefixo_kB)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### üîµ Previs√£o com k atual (k*)")
        st.markdown(contextoA)

    with col2:
        st.markdown("### üü£ Previs√£o com k preditivo (kÃÇ)")
        st.markdown(contextoB)

    st.info("Este painel compara exclusivamente o estado ambiental. "
            "A previs√£o num√©rica permanece igual por enquanto.")

    st.stop()

# ---------------------------------------------------------
# Fun√ß√£o auxiliar ‚Äî Normalizar S√©rie
# ---------------------------------------------------------

import pandas as pd
from collections.abc import Iterable

def normalizar_serie(serie):
    if serie is None or (isinstance(serie, float) and pd.isna(serie)):
        return ""

    nums = []

    if isinstance(serie, str):
        cleaned = (serie.replace("["," ").replace("]"," ")
                         .replace("(" , " ").replace(")" , " ")
                         .replace(",", " ").replace(";", " "))
        for t in cleaned.split():
            try: nums.append(int(t))
            except: pass

    elif isinstance(serie, (list, tuple, set)):
        try: nums = [int(x) for x in serie]
        except: return str(serie)

    else:
        try:
            if isinstance(serie, Iterable):
                nums = [int(x) for x in serie]
            else:
                return str(serie)
        except:
            return str(serie)

    if not nums:
        return str(serie)

    nums = sorted(dict.fromkeys(nums))
    return " ".join(str(n) for n in nums)

