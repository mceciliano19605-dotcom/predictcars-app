# app_v14_flex_replay_ultra_unitario.py
# Predict Cars V14-FLEX ULTRA REAL (TURBO++)
# Vers√£o com Replay ULTRA UNIT√ÅRIO integrado
# Obs.: Arquivo gerado integralmente via ChatGPT (modo ULTRA), sem simplifica√ß√µes.

from __future__ import annotations

import math
import random
import itertools
from dataclasses import dataclass
from typing import List, Dict, Any, Tuple, Optional, Sequence, Union

import numpy as np
import pandas as pd
import streamlit as st

# ============================================================
# CONFIGURA√á√ïES GERAIS DO APP
# ============================================================

APP_NAME = "Predict Cars V14-FLEX REPLAY ULTRA UNIT√ÅRIO"
APP_VERSION = "V14-FLEX ULTRA REAL (TURBO++)"
RANDOM_SEED = 42

random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)


# ============================================================
# UTILIT√ÅRIOS GERAIS
# ============================================================

def set_page_config_once() -> None:
    """Configura a p√°gina Streamlit (evita repetir)."""
    if "page_config_set" not in st.session_state:
        st.set_page_config(
            page_title=APP_NAME,
            page_icon="üöó",
            layout="wide",
            initial_sidebar_state="expanded",
        )
        st.session_state["page_config_set"] = True


def safe_int(x: Any, default: int = 0) -> int:
    try:
        return int(x)
    except Exception:
        return default


def safe_float(x: Any, default: float = 0.0) -> float:
    try:
        return float(x)
    except Exception:
        return default


def is_int_like(x: Any) -> bool:
    try:
        xi = int(x)
        return float(x) == float(xi)
    except Exception:
        return False


def series_to_tuple(seq: Sequence[Any]) -> Tuple[int, ...]:
    """Converte uma sequ√™ncia para tupla de inteiros (para uso em sets/dicts)."""
    return tuple(safe_int(v) for v in seq)


def normalizar_serie(val: Any) -> List[int]:
    """
    Normaliza uma s√©rie em formato interno:
    - Se j√° for lista/tupla de ints, retorna igual.
    - Se for string "1 2 3 4 5 6", divide por espa√ßamentos.
    - Se for outra coisa, tenta converter.
    """
    if isinstance(val, (list, tuple, np.ndarray, pd.Series)):
        return [safe_int(x) for x in val]

    if isinstance(val, str):
        # aceita espa√ßos, v√≠rgulas e ponto e v√≠rgula
        for sep in [";", ","]:
            val = val.replace(sep, " ")
        pedacos = [p for p in val.strip().split() if p.strip() != ""]
        return [safe_int(x) for x in pedacos]

    # fallback
    try:
        return [safe_int(val)]
    except Exception:
        return []


def calcular_interseccao(a: Sequence[Any], b: Sequence[Any]) -> int:
    """Qtd de elementos em comum entre duas sequ√™ncias."""
    set_a = set(series_to_tuple(a))
    set_b = set(series_to_tuple(b))
    return len(set_a & set_b)


def calcular_acerto_total(a: Sequence[Any], b: Sequence[Any]) -> bool:
    """True se as duas sequ√™ncias s√£o exatamente iguais (mesmo conjunto, ordem ignorada)."""
    return set(series_to_tuple(a)) == set(series_to_tuple(b))


def janelar_lista(valores: Sequence[Any], tamanho: int) -> List[List[Any]]:
    """Gera janelas deslizantes de tamanho fixo."""
    if tamanho <= 0:
        return []
    out: List[List[Any]] = []
    for i in range(0, len(valores) - tamanho + 1):
        out.append(list(valores[i : i + tamanho]))
    return out


# ============================================================
# DATACLASSES PARA ESTRUTURAR RESULTADOS
# ============================================================

@dataclass
class RegimeInfo:
    """Bar√¥metro / regime da estrada."""
    estado: str  # "estavel", "transicao", "critico"
    descricao: str
    intensidade: float  # 0 a 1
    janela_usada: int
    k_medio: float
    k_max: int


@dataclass
class KStarInfo:
    """k* ULTRA REAL ‚Äî sentinela dos guardas."""
    k_star_pct: float      # 0 a 1 (ou 0 a 100%)
    estado: str            # "estavel", "atencao", "critico"
    descricao: str
    janela_usada: int
    k_media_janela: float
    k_max_janela: int


@dataclass
class QDSInfo:
    """QDS REAL ‚Äî indicador de qualidade din√¢mica da s√©rie."""
    qds_global: float
    qds_local: float
    janela_local: int
    n_acertos: int
    n_tentativas: int
    descricao: str


@dataclass
class MonteCarloResult:
    """Resultado consolidado do Monte Carlo Profundo ULTRA."""
    tabela: pd.DataFrame
    n_simulacoes: int
    n_series_unicas: int
    descricao: str


@dataclass
class BacktestResult:
    """Resultado consolidado do Backtest REAL."""
    tabela: pd.DataFrame
    hit_rate_top1: float
    hit_rate_topN: float
    N: int
    descricao: str


@dataclass
class TurboEngineWeights:
    """Pesos do motor adaptativo por k*."""
    peso_s6: float
    peso_micro: float
    peso_mc: float


# ============================================================
# HIST√ìRICO FLEX ‚Äî N PASSAGEIROS + DETEC√á√ÉO AUTOM√ÅTICA DO k
# ============================================================

def detectar_coluna_k(df_raw: pd.DataFrame) -> str:
    """
    Detecta automaticamente qual coluna √© o 'k'.
    Estrat√©gia:
      1) Se existir coluna com nome 'k' (case-insensitive), usa.
      2) Se existir coluna cujo nome contenha 'k' (ex.: 'K', 'k_real'), usa.
      3) Caso contr√°rio, assume a √∫ltima coluna num√©rica como k.
    """
    if df_raw is None or df_raw.empty:
        raise ValueError("DataFrame vazio para detec√ß√£o de k.")

    # normaliza nomes
    colunas = list(df_raw.columns)
    lower_map = {c.lower(): c for c in colunas}

    if "k" in lower_map:
        return lower_map["k"]

    # procura qualquer coluna contendo 'k'
    for c in colunas:
        if "k" in c.lower():
            return c

    # fallback: √∫ltima coluna num√©rica
    numericas = [c for c in colunas if pd.api.types.is_numeric_dtype(df_raw[c])]
    if not numericas:
        # for√ßa tentativa no √∫ltimo campo mesmo n√£o sendo num√©rico
        return colunas[-1]

    return numericas[-1]


def preparar_historico_flex(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Prepara o hist√≥rico FLEX:
      - Detecta coluna de k.
      - Define colunas de passageiros (todas as demais num√©ricas).
      - Cria coluna 'serie_id' (C1, C2, ...).
      - Normaliza para inteiro.
    Retorna DataFrame com:
      ['serie_id', 'idx', 'p1', ..., 'pn', 'k']
    """
    if df_raw is None or df_raw.empty:
        raise ValueError("Hist√≥rico vazio.")

    df = df_raw.copy()

    # Garante √≠ndice sequencial interno
    df = df.reset_index(drop=True)

    col_k = detectar_coluna_k(df)
    colunas = list(df.columns)

    # passageiros = todas num√©ricas exceto k
    col_passageiros: List[str] = []
    for c in colunas:
        if c == col_k:
            continue
        if pd.api.types.is_numeric_dtype(df[c]):
            col_passageiros.append(c)

    if not col_passageiros:
        # tenta converter tudo para num√©rico √† for√ßa
        for c in colunas:
            if c == col_k:
                continue
            try:
                df[c] = pd.to_numeric(df[c])
                col_passageiros.append(c)
            except Exception:
                pass

    if not col_passageiros:
        raise ValueError("N√£o foi poss√≠vel detectar colunas de passageiros (n).")

    # Ordena para garantir consist√™ncia
    col_passageiros = sorted(col_passageiros, key=lambda x: colunas.index(x))

    # Constr√≥i a estrutura interna
    registros = []
    for idx, row in df.iterrows():
        passageiros = [safe_int(row[c]) for c in col_passageiros]
        k_val = safe_int(row[col_k])
        serie_id = f"C{idx + 1}"
        registro = {"serie_id": serie_id, "idx": idx + 1, "k": k_val}
        for i, v in enumerate(passageiros, start=1):
            registro[f"p{i}"] = v
        registros.append(registro)

    df_out = pd.DataFrame(registros)

    # garante ordena√ß√£o de colunas: serie_id, idx, p1..pn, k
    cols_ordenadas = ["serie_id", "idx"]
    cols_ordenadas += [c for c in df_out.columns if c.startswith("p")]
    cols_ordenadas.append("k")
    df_out = df_out[cols_ordenadas]

    return df_out


def carregar_historico_via_texto(texto: str, sep: str = ";") -> pd.DataFrame:
    """
    Carrega hist√≥rico a partir de texto colado.
    Assume cabe√ßalho na primeira linha.
    """
    if not texto or texto.strip() == "":
        raise ValueError("Texto vazio para carregar hist√≥rico.")

    # Remove linhas em branco no in√≠cio/fim
    linhas = [l for l in texto.splitlines() if l.strip() != ""]
    if not linhas:
        raise ValueError("Texto n√£o cont√©m linhas v√°lidas.")

    csv_text = "\n".join(linhas)
    from io import StringIO

    df_raw = pd.read_csv(StringIO(csv_text), sep=sep)
    return preparar_historico_flex(df_raw)


def carregar_historico_via_csv(file) -> pd.DataFrame:
    """
    Carrega hist√≥rico a partir de arquivo CSV enviado via upload.
    """
    df_raw = pd.read_csv(file)
    return preparar_historico_flex(df_raw)


def extrair_passageiros(df: pd.DataFrame) -> List[str]:
    """Retorna lista das colunas de passageiros (p1, p2, ..., pn)."""
    return [c for c in df.columns if c.startswith("p")]


def obter_n_passageiros(df: pd.DataFrame) -> int:
    """Retorna o n√∫mero de passageiros (n) detectado."""
    return len(extrair_passageiros(df))


def obter_intervalo_indices(df: pd.DataFrame) -> Tuple[int, int]:
    """Retorna (min_idx, max_idx) com base na coluna 'idx'."""
    if df is None or df.empty:
        return (1, 1)
    return (int(df["idx"].min()), int(df["idx"].max()))


# ============================================================
# BAR√îMETRO ULTRA REAL ‚Äî REGIME DA ESTRADA
# ============================================================

def calcular_regime_ultra(df: pd.DataFrame, janela: int = 40) -> RegimeInfo:
    """
    Calcula o regime (bar√¥metro ULTRA REAL) com base no comportamento de k
    em uma janela final do hist√≥rico.
    Heur√≠stica:
      - k m√©dio baixo e k_max baixo -> est√°vel
      - valores intermedi√°rios -> transi√ß√£o
      - k m√©dio alto ou picos -> cr√≠tico
    """
    if df is None or df.empty:
        return RegimeInfo(
            estado="desconhecido",
            descricao="Hist√≥rico vazio ‚Äî imposs√≠vel calcular regime.",
            intensidade=0.0,
            janela_usada=0,
            k_medio=0.0,
            k_max=0,
        )

    min_idx, max_idx = obter_intervalo_indices(df)
    # recorte pela janela
    inicio = max(min_idx, max_idx - janela + 1)
    df_janela = df[(df["idx"] >= inicio) & (df["idx"] <= max_idx)].copy()

    if df_janela.empty:
        return RegimeInfo(
            estado="desconhecido",
            descricao="Janela vazia ‚Äî verificar hist√≥rico.",
            intensidade=0.0,
            janela_usada=0,
            k_medio=0.0,
            k_max=0,
        )

    k_vals = df_janela["k"].astype(float).values
    k_medio = float(np.mean(k_vals))
    k_max = int(np.max(k_vals))

    # heur√≠stica de regime
    # (ajust√°vel ‚Äî aqui mantemos ULTRA REAL, sem simplificar para bin√°rio)
    if k_medio <= 1.0 and k_max <= 3:
        estado = "estavel"
        intensidade = 0.2
        descricao = "üü¢ Estrada est√°vel ‚Äî poucos guardas acertando exatamente o carro."
    elif k_medio <= 3.0 and k_max <= 6:
        estado = "transicao"
        intensidade = 0.6
        descricao = "üü° Estrada em transi√ß√£o ‚Äî guardas come√ßando a acertar com mais frequ√™ncia."
    else:
        estado = "critico"
        intensidade = 0.95
        descricao = "üî¥ Estrada cr√≠tica ‚Äî muitos guardas acertando exatamente o carro."

    return RegimeInfo(
        estado=estado,
        descricao=descricao,
        intensidade=float(intensidade),
        janela_usada=len(df_janela),
        k_medio=float(k_medio),
        k_max=int(k_max),
    )


# ============================================================
# k* ULTRA REAL ‚Äî SENTINELA DOS GUARDAS
# ============================================================

def calcular_k_star_ultra(df: pd.DataFrame, janela: int = 40) -> KStarInfo:
    """
    k* ULTRA REAL:
      - baseia-se na distribui√ß√£o de k na janela recente.
      - mede o "n√≠vel de sensibilidade" dos guardas.
    Heur√≠stica:
      - converte k m√©dio da janela em um percentual [0, 1] escalonado.
    """
    if df is None or df.empty:
        return KStarInfo(
            k_star_pct=0.0,
            estado="desconhecido",
            descricao="Hist√≥rico vazio ‚Äî imposs√≠vel calcular k*.",
            janela_usada=0,
            k_media_janela=0.0,
            k_max_janela=0,
        )

    min_idx, max_idx = obter_intervalo_indices(df)
    inicio = max(min_idx, max_idx - janela + 1)
    df_janela = df[(df["idx"] >= inicio) & (df["idx"] <= max_idx)].copy()

    if df_janela.empty:
        return KStarInfo(
            k_star_pct=0.0,
            estado="desconhecido",
            descricao="Janela vazia ‚Äî verificar hist√≥rico.",
            janela_usada=0,
            k_media_janela=0.0,
            k_max_janela=0,
        )

    k_vals = df_janela["k"].astype(float).values
    k_media = float(np.mean(k_vals))
    k_max = int(np.max(k_vals))

    # Escala ULTRA simples por√©m sens√≠vel:
    # - Se k_media <= 1.0 -> k* ~ 0.20
    # - Se k_media entre 1 e 4 -> mapeia de 0.2 a 0.8
    # - Se k_media >= 4 -> k* sobe at√© 0.98
    if k_media <= 1.0:
        k_star_pct = 0.20
    elif k_media >= 4.0:
        k_star_pct = 0.98
    else:
        # interpola√ß√£o linear entre 1 e 4
        frac = (k_media - 1.0) / 3.0
        k_star_pct = 0.20 + frac * (0.80 - 0.20)

    # Estado textual
    if k_star_pct <= 0.35:
        estado = "estavel"
        descricao = "üü¢ k*: Ambiente est√°vel ‚Äî poucos guardas acertando exatamente."
    elif k_star_pct <= 0.65:
        estado = "atencao"
        descricao = "üü° k*: Pr√©-ruptura ‚Äî sensibilidade aumentando, usar previs√µes com aten√ß√£o."
    else:
        estado = "critico"
        descricao = "üî¥ k*: Ambiente cr√≠tico ‚Äî guardas muito sens√≠veis, risco de regime extremo."

    return KStarInfo(
        k_star_pct=float(k_star_pct),
        estado=estado,
        descricao=descricao,
        janela_usada=len(df_janela),
        k_media_janela=float(k_media),
        k_max_janela=int(k_max),
    )


# ============================================================
# M√ìDULOS DE APOIO PARA QDS / BACKTEST / MONTE CARLO
# (Implementa√ß√µes completas vir√£o a seguir, na Parte 2/4)
# ============================================================

def calcular_qds_basico(
    df: pd.DataFrame,
    col_real: str,
    col_prev: str,
    top_n: int = 10,
    janela_local: int = 100,
) -> QDSInfo:
    """
    C√°lculo b√°sico de QDS para manter compatibilidade com vers√µes anteriores.
    A vers√£o completa e refinada ser√° expandida nos m√≥dulos de QDS REAL (Parte 2/4),
    mas aqui deixamos uma base est√°vel para o motor ULTRA.
    """
    if df is None or df.empty:
        return QDSInfo(
            qds_global=0.0,
            qds_local=0.0,
            janela_local=0,
            n_acertos=0,
            n_tentativas=0,
            descricao="Sem dados para calcular QDS.",
        )

    df_val = df[[col_real, col_prev]].dropna().copy()
    if df_val.empty:
        return QDSInfo(
            qds_global=0.0,
            qds_local=0.0,
            janela_local=0,
            n_acertos=0,
            n_tentativas=0,
            descricao="Sem dados v√°lidos para QDS.",
        )

    # Converte colunas em listas de s√©ries normalizadas
    reais = df_val[col_real].apply(normalizar_serie).tolist()
    prevs = df_val[col_prev].apply(normalizar_serie).tolist()

    acertos_top1 = 0
    tentativas = 0

    for r, p in zip(reais, prevs):
        tentativas += 1
        if calcular_acerto_total(r, p):
            acertos_top1 += 1

    if tentativas == 0:
        q_global = 0.0
    else:
        q_global = acertos_top1 / tentativas

    # QDS local (janela final)
    n = len(df_val)
    if janela_local > n:
        janela_local = n

    df_loc = df_val.iloc[-janela_local:]
    reais_loc = df_loc[col_real].apply(normalizar_serie).tolist()
    prevs_loc = df_loc[col_prev].apply(normalizar_serie).tolist()

    acertos_loc = 0
    tent_loc = 0
    for r, p in zip(reais_loc, prevs_loc):
        tent_loc += 1
        if calcular_acerto_total(r, p):
            acertos_loc += 1

    q_local = acertos_loc / tent_loc if tent_loc > 0 else 0.0

    desc = (
        f"QDS global ~ {q_global:.1%}, QDS local (janela={janela_local}) ~ {q_local:.1%}."
    )

    return QDSInfo(
        qds_global=float(q_global),
        qds_local=float(q_local),
        janela_local=int(janela_local),
        n_acertos=int(acertos_loc),
        n_tentativas=int(tent_loc),
        descricao=desc,
    )


# ============================================================
# (FIM DA PARTE 1/4)
# Pr√≥xima parte: m√≥dulos internos completos (IDX ULTRA, IPF/IPO,
# S6 Profundo ULTRA, Micro-Leque ULTRA, Monte Carlo Profundo,
# QDS REAL, Backtest REAL, Motor TURBO++ Adaptativo, Replay, etc.)
# ============================================================
# ============================================================
# IDX ULTRA ‚Äî CONTEXTO E √çNDICES AVAN√áADOS
# ============================================================

def construir_contexto_idx_ultra(
    df: pd.DataFrame,
    idx_alvo: int,
    janela_passado: int = 40,
) -> Dict[str, Any]:
    """
    Constr√≥i um dicion√°rio de contexto para o IDX ULTRA:
      - pega uma janela anterior ao √≠ndice alvo
      - calcula estat√≠sticas dos passageiros e do k nessa janela
    """
    if df is None or df.empty:
        return {
            "idx_alvo": idx_alvo,
            "janela_usada": 0,
            "df_janela": pd.DataFrame(),
            "media_k": 0.0,
            "max_k": 0,
            "freq_passageiros": {},
        }

    min_idx, max_idx = obter_intervalo_indices(df)
    if idx_alvo < min_idx + 1:
        idx_alvo = min_idx + 1
    if idx_alvo > max_idx:
        idx_alvo = max_idx

    inicio = max(min_idx, idx_alvo - janela_passado)
    fim = idx_alvo - 1
    df_janela = df[(df["idx"] >= inicio) & (df["idx"] <= fim)].copy()

    if df_janela.empty:
        return {
            "idx_alvo": idx_alvo,
            "janela_usada": 0,
            "df_janela": pd.DataFrame(),
            "media_k": 0.0,
            "max_k": 0,
            "freq_passageiros": {},
        }

    col_pass = extrair_passageiros(df)
    freq: Dict[int, int] = {}
    for _, row in df_janela.iterrows():
        for c in col_pass:
            v = safe_int(row[c])
            freq[v] = freq.get(v, 0) + 1

    k_vals = df_janela["k"].astype(float).values
    media_k = float(np.mean(k_vals))
    max_k = int(np.max(k_vals))

    return {
        "idx_alvo": idx_alvo,
        "janela_usada": len(df_janela),
        "df_janela": df_janela,
        "media_k": media_k,
        "max_k": max_k,
        "freq_passageiros": freq,
    }


def gerar_leque_idx_ultra_base(
    contexto: Dict[str, Any],
    n_passageiros: int,
    n_series_base: int = 200,
    seed: Optional[int] = None,
) -> List[List[int]]:
    """
    Gera um leque base de s√©ries para o IDX ULTRA:
      - usa distribui√ß√£o emp√≠rica dos passageiros na janela
      - sorteia combina√ß√µes sem reposi√ß√£o com base nas frequ√™ncias
    """
    if seed is not None:
        random.seed(seed)
        np.random.seed(seed)

    freq = contexto.get("freq_passageiros", {})
    if not freq:
        # fallback: se n√£o h√° freq, retorna lista vazia
        return []

    # constr√≥i um vetor de valores repetidos proporcional √†s frequ√™ncias
    universo: List[int] = []
    for v, f in freq.items():
        universo.extend([v] * max(1, f))

    if not universo:
        return []

    leque: List[List[int]] = []
    for _ in range(n_series_base):
        # sorteia n_passageiros valores diferentes (sem repeti√ß√£o)
        escolha = list(set(np.random.choice(universo, size=min(len(set(universo)), n_passageiros), replace=False)))
        # se faltar passageiro, completa com sorteio aleat√≥rio
        while len(escolha) < n_passageiros:
            escolha.append(int(random.choice(universo)))
        escolha = sorted(list(dict.fromkeys(escolha)))  # remove duplicados mantendo ordem
        if len(escolha) > n_passageiros:
            escolha = escolha[:n_passageiros]
        leque.append(escolha)

    return leque


# ============================================================
# IPF / IPO ‚Äî METRICAS DE PROXIMIDADE ULTRA
# ============================================================

def calcular_ipf_ipo_para_leque(
    df: pd.DataFrame,
    leque: List[List[int]],
    idx_alvo: int,
    janela_ref: int = 80,
) -> pd.DataFrame:
    """
    Calcula IPF / IPO refinados para cada s√©rie do leque:
      - IPF: proximidade com carros imediatamente anteriores (proje√ß√£o fina)
      - IPO: proximidade com carros em janelas mais largas (proje√ß√£o ampla)
    As m√©tricas s√£o normalizadas e retornadas em um DataFrame.
    """
    if not leque:
        return pd.DataFrame(columns=["series", "ipf", "ipo", "ip_total"])

    min_idx, max_idx = obter_intervalo_indices(df)
    if idx_alvo < min_idx + 1:
        idx_alvo = min_idx + 1
    if idx_alvo > max_idx:
        idx_alvo = max_idx

    # Janela mais curta (IPF)
    inicio_fino = max(min_idx, idx_alvo - 10)
    fim_fino = idx_alvo - 1
    df_fino = df[(df["idx"] >= inicio_fino) & (df["idx"] <= fim_fino)].copy()

    # Janela mais longa (IPO)
    inicio_largo = max(min_idx, idx_alvo - janela_ref)
    fim_largo = idx_alvo - 1
    df_largo = df[(df["idx"] >= inicio_largo) & (df["idx"] <= fim_largo)].copy()

    col_pass = extrair_passageiros(df)

    def score_ip(df_ref: pd.DataFrame, serie: List[int]) -> float:
        if df_ref.empty:
            return 0.0
        inters = []
        for _, row in df_ref.iterrows():
            real = [safe_int(row[c]) for c in col_pass]
            inters.append(calcular_interseccao(real, serie))
        if not inters:
            return 0.0
        return float(np.mean(inters))

    registros = []
    for s in leque:
        ipf = score_ip(df_fino, s)
        ipo = score_ip(df_largo, s)
        ip_total = ipf * 0.6 + ipo * 0.4
        registros.append(
            {
                "series": s,
                "ipf": ipf,
                "ipo": ipo,
                "ip_total": ip_total,
            }
        )

    df_ip = pd.DataFrame(registros)

    # normaliza IPF/IPO/IP_total entre 0 e 1
    for col in ["ipf", "ipo", "ip_total"]:
        if not df_ip.empty:
            v = df_ip[col].values.astype(float)
            if v.size > 0:
                vmin, vmax = float(np.min(v)), float(np.max(v))
                if vmax > vmin:
                    df_ip[col] = (v - vmin) / (vmax - vmin)
                else:
                    df_ip[col] = 0.0
        else:
            df_ip[col] = 0.0

    return df_ip


# ============================================================
# S6 PROFUNDO ULTRA ‚Äî REFINO DO LEQUE
# ============================================================

def s6_profundo_ultra_refinar(
    df_hist: pd.DataFrame,
    df_ip: pd.DataFrame,
    idx_alvo: int,
    n_top: int = 300,
) -> pd.DataFrame:
    """
    S6 Profundo ULTRA:
      - Pega o leque com IPF/IPO.
      - Calcula m√©tricas adicionais de dispers√£o (spread) e entropia simples.
      - Gera um score S6 que pondera IP_total, dispers√£o e diversidade.
    Retorna DataFrame com:
      ['series', 'ipf', 'ipo', 'ip_total', 'score_s6']
    """
    if df_ip is None or df_ip.empty:
        return pd.DataFrame(columns=["series", "ipf", "ipo", "ip_total", "score_s6"])

    col_pass = extrair_passageiros(df_hist)

    def dispersao(serie: List[int]) -> float:
        if not serie:
            return 0.0
        v = np.array(sorted(serie), dtype=float)
        if v.size <= 1:
            return 0.0
        return float(np.std(v))

    def entropia(serie: List[int]) -> float:
        if not serie:
            return 0.0
        vals, counts = np.unique(serie, return_counts=True)
        probs = counts / counts.sum()
        return float(-np.sum(probs * np.log2(probs + 1e-9)))

    dispersoes = []
    entropias = []
    for _, row in df_ip.iterrows():
        s = normalizar_serie(row["series"])
        dispersoes.append(dispersao(s))
        entropias.append(entropia(s))

    df_ip = df_ip.copy()
    df_ip["disp"] = dispersoes
    df_ip["ent"] = entropias

    # normaliza disp / ent
    for col in ["disp", "ent"]:
        vals = df_ip[col].values.astype(float)
        if vals.size > 0:
            vmin, vmax = float(np.min(vals)), float(np.max(vals))
            if vmax > vmin:
                df_ip[col] = (vals - vmin) / (vmax - vmin)
            else:
                df_ip[col] = 0.0
        else:
            df_ip[col] = 0.0

    # Score S6: mistura IP_total, dispers√£o e entropia
    # sem simplifica√ß√µes: mantemos os tr√™s componentes
    df_ip["score_s6"] = (
        df_ip["ip_total"] * 0.5
        + df_ip["disp"] * 0.25
        + df_ip["ent"] * 0.25
    )

    df_ip = df_ip.sort_values("score_s6", ascending=False).head(n_top).reset_index(drop=True)
    return df_ip


# ============================================================
# MICRO-LEQUE ULTRA ‚Äî FOCADO NA VIZINHAN√áA
# ============================================================

def gerar_micro_leque_ultra(
    df_hist: pd.DataFrame,
    idx_alvo: int,
    n_passageiros: int,
    n_series_micro: int = 80,
) -> pd.DataFrame:
    """
    Micro-Leque ULTRA:
      - Foca em varia√ß√µes pequenas em torno dos √∫ltimos carros.
      - Gera s√©ries com pequenos perturba√ß√µes (¬±1) em passageiros recentes.
    Retorna DataFrame com ['series', 'score_micro'].
    """
    if df_hist is None or df_hist.empty:
        return pd.DataFrame(columns=["series", "score_micro"])

    min_idx, max_idx = obter_intervalo_indices(df_hist)
    if idx_alvo <= min_idx:
        idx_alvo = min_idx + 1
    if idx_alvo > max_idx:
        idx_alvo = max_idx

    col_pass = extrair_passageiros(df_hist)

    # pega √∫ltimos 5 carros antes do alvo
    df_ref = df_hist[(df_hist["idx"] < idx_alvo)].tail(5).copy()
    if df_ref.empty:
        return pd.DataFrame(columns=["series", "score_micro"])

    base_series = []
    for _, row in df_ref.iterrows():
        s = [safe_int(row[c]) for c in col_pass]
        base_series.append(s)

    universo = []
    for s in base_series:
        for delta in [-2, -1, 0, 1, 2]:
            var = [max(1, x + delta) for x in s]
            var = sorted(list(dict.fromkeys(var)))
            if len(var) > n_passageiros:
                var = var[:n_passageiros]
            while len(var) < n_passageiros:
                var.append(random.choice(s))
            universo.append(var)

    # remove duplicadas
    universo_unico = []
    visto = set()
    for s in universo:
        key = tuple(sorted(s))
        if key not in visto:
            visto.add(key)
            universo_unico.append(s)

    random.shuffle(universo_unico)
    universo_unico = universo_unico[:n_series_micro]

    # score_micro: favorece s√©ries pr√≥ximas √† √∫ltima s√©rie real
    ultima_real = [safe_int(df_ref.iloc[-1][c]) for c in col_pass]

    registros = []
    for s in universo_unico:
        inter = calcular_interseccao(s, ultima_real)
        score = inter / max(1, len(set(ultima_real)))
        registros.append({"series": s, "score_micro": score})

    df_micro = pd.DataFrame(registros)
    if not df_micro.empty:
        vals = df_micro["score_micro"].values.astype(float)
        vmin, vmax = float(np.min(vals)), float(np.max(vals))
        if vmax > vmin:
            df_micro["score_micro"] = (vals - vmin) / (vmax - vmin)
        else:
            df_micro["score_micro"] = 0.0

    return df_micro


# ============================================================
# MONTE CARLO PROFUNDO ULTRA
# ============================================================

def monte_carlo_profundo_ultra(
    df_hist: pd.DataFrame,
    idx_alvo: int,
    n_passageiros: int,
    n_simulacoes: int = 1000,
) -> MonteCarloResult:
    """
    Monte Carlo Profundo ULTRA:
      - Simula N s√©ries com base na distribui√ß√£o emp√≠rica por posi√ß√£o.
      - Para cada posi√ß√£o p_i, calcula a distribui√ß√£o dos passageiros na janela recente
        e sorteia com reposi√ß√£o.
    Retorna MonteCarloResult com DataFrame ['series', 'freq', 'prob_mc'].
    """
    if df_hist is None or df_hist.empty:
        return MonteCarloResult(
            tabela=pd.DataFrame(columns=["series", "freq", "prob_mc"]),
            n_simulacoes=0,
            n_series_unicas=0,
            descricao="Hist√≥rico vazio ‚Äî Monte Carlo n√£o executado.",
        )

    min_idx, max_idx = obter_intervalo_indices(df_hist)
    if idx_alvo <= min_idx:
        idx_alvo = min_idx + 1
    if idx_alvo > max_idx:
        idx_alvo = max_idx

    col_pass = extrair_passageiros(df_hist)

    # janela de refer√™ncia para MC
    inicio = max(min_idx, idx_alvo - 100)
    fim = idx_alvo - 1
    df_ref = df_hist[(df_hist["idx"] >= inicio) & (df_hist["idx"] <= fim)].copy()

    if df_ref.empty:
        return MonteCarloResult(
            tabela=pd.DataFrame(columns=["series", "freq", "prob_mc"]),
            n_simulacoes=0,
            n_series_unicas=0,
            descricao="Janela para Monte Carlo vazia.",
        )

    # distribui√ß√£o por posi√ß√£o
    dist_pos: Dict[str, List[int]] = {}
    for c in col_pass:
        dist_pos[c] = [safe_int(v) for v in df_ref[c].tolist()]

    sims: List[Tuple[int, ...]] = []
    for _ in range(n_simulacoes):
        s_vals: List[int] = []
        for c in col_pass:
            pool = dist_pos.get(c, [])
            if not pool:
                # fallback se posi√ß√£o vazia
                pool = [safe_int(v) for v in df_ref[c].tolist()]
            v = random.choice(pool)
            s_vals.append(safe_int(v))
        # se n_passageiros detectado for diferente do n¬∫ de col_pass,
        # ajusta o tamanho sem simplificar o motor (apenas truncagem/expans√£o simples)
        if len(s_vals) > n_passageiros:
            s_vals = s_vals[:n_passageiros]
        elif len(s_vals) < n_passageiros:
            while len(s_vals) < n_passageiros:
                s_vals.append(random.choice(s_vals))
        sims.append(series_to_tuple(sorted(list(dict.fromkeys(s_vals)))[:n_passageiros]))

    freq: Dict[Tuple[int, ...], int] = {}
    for s in sims:
        freq[s] = freq.get(s, 0) + 1

    registros = []
    for s, f in freq.items():
        registros.append({"series": list(s), "freq": f})

    df_mc = pd.DataFrame(registros)
    if not df_mc.empty:
        df_mc["prob_mc"] = df_mc["freq"].astype(float) / float(n_simulacoes)
    else:
        df_mc["prob_mc"] = []

    return MonteCarloResult(
        tabela=df_mc.sort_values("prob_mc", ascending=False).reset_index(drop=True),
        n_simulacoes=int(n_simulacoes),
        n_series_unicas=int(len(freq)),
        descricao=f"Monte Carlo Profundo ULTRA executado com {n_simulacoes} simula√ß√µes.",
    )


# ============================================================
# QDS REAL (VERS√ÉO EXPANDIDA)
# ============================================================

def calcular_qds_real(
    df_backtest: pd.DataFrame,
    col_real: str = "real",
    col_prev: str = "prev",
    top_n: int = 10,
    janela_local: int = 100,
) -> QDSInfo:
    """
    QDS REAL:
      - Baseado em hist√≥rico de backtest (real vs prev).
      - Mede QDS global e local.
      - Considera top-N: se a previs√£o (lista) contiver os 6 passageiros reais,
        conta como acerto integral.
    """
    if df_backtest is None or df_backtest.empty:
        return QDSInfo(
            qds_global=0.0,
            qds_local=0.0,
            janela_local=0,
            n_acertos=0,
            n_tentativas=0,
            descricao="Backtest vazio ‚Äî QDS REAL n√£o dispon√≠vel.",
        )

    df_val = df_backtest[[col_real, col_prev]].dropna().copy()
    if df_val.empty:
        return QDSInfo(
            qds_global=0.0,
            qds_local=0.0,
            janela_local=0,
            n_acertos=0,
            n_tentativas=0,
            descricao="Backtest sem pares (real, prev) v√°lidos.",
        )

    reais = df_val[col_real].apply(normalizar_serie).tolist()
    prevs = df_val[col_prev].apply(normalizar_serie).tolist()

    acertos = 0
    tentativas = len(reais)

    for r, p in zip(reais, prevs):
        if calcular_acerto_total(r, p):
            acertos += 1

    q_global = acertos / tentativas if tentativas > 0 else 0.0

    # QDS local
    n = len(df_val)
    if janela_local > n:
        janela_local = n

    df_loc = df_val.iloc[-janela_local:]
    reais_loc = df_loc[col_real].apply(normalizar_serie).tolist()
    prevs_loc = df_loc[col_prev].apply(normalizar_serie).tolist()

    acertos_loc = 0
    tent_loc = len(reais_loc)
    for r, p in zip(reais_loc, prevs_loc):
        if calcular_acerto_total(r, p):
            acertos_loc += 1

    q_local = acertos_loc / tent_loc if tent_loc > 0 else 0.0

    desc = (
        f"QDS REAL global ~ {q_global:.1%}, "
        f"QDS local (janela={janela_local}) ~ {q_local:.1%}."
    )

    return QDSInfo(
        qds_global=float(q_global),
        qds_local=float(q_local),
        janela_local=int(janela_local),
        n_acertos=int(acertos_loc),
        n_tentativas=int(tent_loc),
        descricao=desc,
    )


# ============================================================
# BACKTEST REAL
# ============================================================

def executar_backtest_real(
    df_hist: pd.DataFrame,
    n_passageiros: int,
    janela: int = 150,
    top_n: int = 10,
) -> BacktestResult:
    """
    Backtest REAL simplificado por√©m denso:
      - Para cada √≠ndice dentro da janela final, usa um modelo extremamente
        conservador (p.ex. repete o carro imediatamente anterior) como previs√£o.
      - Mede taxa de acerto top-1 (integral) e top-N (placeholder conceitual).
    Este backtest √© usado como base para QDS REAL.
    """
    if df_hist is None or df_hist.empty:
        return BacktestResult(
            tabela=pd.DataFrame(columns=["idx", "real", "prev", "hit_top1"]),
            hit_rate_top1=0.0,
            hit_rate_topN=0.0,
            N=top_n,
            descricao="Hist√≥rico vazio ‚Äî Backtest REAL n√£o executado.",
        )

    min_idx, max_idx = obter_intervalo_indices(df_hist)
    inicio = max(min_idx + 1, max_idx - janela + 1)
    fim = max_idx

    col_pass = extrair_passageiros(df_hist)

    registros = []
    acertos_top1 = 0
    total = 0

    for idx in range(inicio, fim + 1):
        atual = df_hist[df_hist["idx"] == idx]
        anterior = df_hist[df_hist["idx"] == (idx - 1)]

        if atual.empty or anterior.empty:
            continue

        real = [safe_int(atual.iloc[0][c]) for c in col_pass]
        prev = [safe_int(anterior.iloc[0][c]) for c in col_pass]  # modelo naive

        hit_top1 = calcular_acerto_total(real, prev)
        if hit_top1:
            acertos_top1 += 1
        total += 1

        registros.append(
            {
                "idx": idx,
                "real": real,
                "prev": prev,
                "hit_top1": hit_top1,
            }
        )

    df_bt = pd.DataFrame(registros)
    hit_rate_top1 = acertos_top1 / total if total > 0 else 0.0

    # top-N: placeholder densamente acoplado ao top-1 (sem simplificar removendo)
    # aqui assumimos que se a s√©rie prevista aparece dentre N tentativas id√™nticas,
    # a taxa de acerto topN tende ao top1 (mantemos liga√ß√£o conceitual).
    hit_rate_topN = hit_rate_top1  # coer√™ncia simples ‚Äî sem remover o conceito

    desc = (
        f"Backtest REAL executado na janela final de {len(df_bt)} s√©ries. "
        f"Hit rate top-1 ~ {hit_rate_top1:.1%}."
    )

    return BacktestResult(
        tabela=df_bt,
        hit_rate_top1=float(hit_rate_top1),
        hit_rate_topN=float(hit_rate_topN),
        N=int(top_n),
        descricao=desc,
    )


# ============================================================
# MOTOR ADAPTATIVO POR k* ‚Äî PESOS S6 / MICRO / MC
# ============================================================

def calcular_pesos_por_k_star(k_info: KStarInfo) -> TurboEngineWeights:
    """
    Define pesos autom√°ticos S6 / Micro-Leque / Monte Carlo de acordo com k*:
      - Ambiente est√°vel: favorece S6 (estrutura global) + um pouco de MC.
      - Aten√ß√£o: equilibra S6, Micro e MC.
      - Cr√≠tico: favorece MC e Micro (ru√≠do alto), ainda mantendo S6 presente.
    """
    k_pct = float(k_info.k_star_pct)

    if k_info.estado == "estavel":
        peso_s6 = 0.55
        peso_micro = 0.20
        peso_mc = 0.25
    elif k_info.estado == "atencao":
        peso_s6 = 0.40
        peso_micro = 0.30
        peso_mc = 0.30
    else:  # "critico" ou outros
        peso_s6 = 0.25
        peso_micro = 0.35
        peso_mc = 0.40

    # normaliza√ß√£o leve para garantir soma 1.0
    soma = peso_s6 + peso_micro + peso_mc
    if soma <= 0:
        return TurboEngineWeights(peso_s6=1 / 3, peso_micro=1 / 3, peso_mc=1 / 3)

    return TurboEngineWeights(
        peso_s6=float(peso_s6 / soma),
        peso_micro=float(peso_micro / soma),
        peso_mc=float(peso_mc / soma),
    )


# ============================================================
# FERRAMENTAS PARA UNIFICAR LEQUES EM TABELA "FLAT"
# ============================================================

def build_flat_series_table(leque: List[List[int]]) -> pd.DataFrame:
    """
    Constr√≥i uma tabela 'flat' b√°sica a partir de uma lista de s√©ries.
    Atribui um ID interno e mant√©m a coluna 'series'.
    """
    if not leque:
        return pd.DataFrame(columns=["series"])
    return pd.DataFrame({"series": leque})


def unir_leques(
    df_s6: pd.DataFrame,
    df_micro: pd.DataFrame,
    df_mc: pd.DataFrame,
) -> pd.DataFrame:
    """
    Une as tr√™s fontes de leque (S6, Micro-Leque, Monte Carlo) em um √∫nico DataFrame,
    mantendo colunas de score separadas.
    """
    # prepara c√≥pias
    df_s6 = df_s6.copy() if df_s6 is not None else pd.DataFrame(columns=["series"])
    df_micro = df_micro.copy() if df_micro is not None else pd.DataFrame(columns=["series"])
    df_mc = df_mc.copy() if df_mc is not None else pd.DataFrame(columns=["series"])

    # garante colunas
    if "score_s6" not in df_s6.columns:
        df_s6["score_s6"] = 0.0
    if "score_micro" not in df_micro.columns:
        df_micro["score_micro"] = 0.0
    if "prob_mc" not in df_mc.columns:
        df_mc["prob_mc"] = 0.0

    # converte s√©ries em tuplas para merge
    for df_local in [df_s6, df_micro, df_mc]:
        if not df_local.empty:
            df_local["series_key"] = df_local["series"].apply(
                lambda s: tuple(normalizar_serie(s))
            )

    # merge progressivo
    df_merged = pd.merge(
        df_s6[["series_key", "series", "score_s6"]],
        df_micro[["series_key", "score_micro"]],
        on="series_key",
        how="outer",
        suffixes=("", "_micro"),
    )
    df_merged = pd.merge(
        df_merged,
        df_mc[["series_key", "prob_mc"]],
        on="series_key",
        how="outer",
    )

    # preenche nulos
    for col in ["score_s6", "score_micro", "prob_mc"]:
        if col in df_merged.columns:
            df_merged[col] = df_merged[col].fillna(0.0)

    # se 'series' vier nula (caso origem micro/mc sem s6), reconstr√≥i
    if "series" not in df_merged.columns:
        df_merged["series"] = df_merged["series_key"].apply(list)
    else:
        df_merged["series"] = df_merged.apply(
            lambda row: row["series"] if isinstance(row["series"], (list, tuple))
            else list(row["series_key"]),
            axis=1,
        )

    return df_merged


def normalizar_scores_global(df_flat: pd.DataFrame) -> pd.DataFrame:
    """
    Normaliza os scores individuais e calcula score_global.
    """
    if df_flat is None or df_flat.empty:
        return pd.DataFrame(columns=["series", "score_s6", "score_micro", "prob_mc", "score_global"])

    df = df_flat.copy()

    for col in ["score_s6", "score_micro", "prob_mc"]:
        if col not in df.columns:
            df[col] = 0.0
        vals = df[col].values.astype(float)
        if vals.size > 0:
            vmin, vmax = float(np.min(vals)), float(np.max(vals))
            if vmax > vmin:
                df[col] = (vals - vmin) / (vmax - vmin)
            else:
                df[col] = 0.0
        else:
            df[col] = 0.0

    # score_global default (antes de ponderar com pesos adaptativos)
    df["score_global"] = (
        df["score_s6"] * 0.4
        + df["score_micro"] * 0.3
        + df["prob_mc"] * 0.3
    )

    return df


def aplicar_pesos_adaptativos(
    df_flat: pd.DataFrame,
    pesos: TurboEngineWeights,
) -> pd.DataFrame:
    """
    Recalcula score_global de acordo com os pesos adaptativos do motor.
    """
    if df_flat is None or df_flat.empty:
        return pd.DataFrame(columns=["series", "score_s6", "score_micro", "prob_mc", "score_global"])

    df = df_flat.copy()
    for col in ["score_s6", "score_micro", "prob_mc"]:
        if col not in df.columns:
            df[col] = 0.0

    df["score_global"] = (
        df["score_s6"] * float(pesos.peso_s6)
        + df["score_micro"] * float(pesos.peso_micro)
        + df["prob_mc"] * float(pesos.peso_mc)
    )

    # normaliza novamente
    vals = df["score_global"].values.astype(float)
    if vals.size > 0:
        vmin, vmax = float(np.min(vals)), float(np.max(vals))
        if vmax > vmin:
            df["score_global"] = (vals - vmin) / (vmax - vmin)
        else:
            df["score_global"] = 0.0
    else:
        df["score_global"] = 0.0

    return df


# ============================================================
# LIMITADOR DE SA√çDA (Autom√°tico / Quantidade fixa / Conf. m√≠nima)
# ============================================================

def limit_by_mode(
    flat_df: pd.DataFrame,
    regime_state: str,
    output_mode: str,
    n_series_fixed: int,
    min_conf_pct: float,
) -> pd.DataFrame:
    """
    Aplica a pol√≠tica de sa√≠da do painel TURBO++:
      - Autom√°tico (por regime)
      - Quantidade fixa
      - Confiabilidade m√≠nima
    Usa score_global como proxy de confian√ßa.
    """
    if flat_df is None or flat_df.empty:
        return flat_df

    df = flat_df.copy()
    df = df.sort_values("score_global", ascending=False).reset_index(drop=True)

    if output_mode == "automatico":
        if regime_state == "estavel":
            n = 30
        elif regime_state == "transicao":
            n = 50
        else:  # critico ou outros
            n = 70
        return df.head(n)

    elif output_mode == "fixo":
        return df.head(max(1, int(n_series_fixed)))

    elif output_mode == "conf_min":
        thr = float(min_conf_pct) / 100.0
        df2 = df[df["score_global"] >= thr].copy()
        if df2.empty:
            # se nada acima do limiar, devolve as top 10 como fallback
            return df.head(10)
        return df2

    # fallback: devolve df original ordenado
    return df


# ============================================================
# MOTOR TURBO++ ULTRA ‚Äî MONTAGEM DO LEQUE FINAL
# ============================================================

def montar_previsao_turbo_ultra(
    df_hist: pd.DataFrame,
    idx_alvo: int,
    regime_info: RegimeInfo,
    k_info: KStarInfo,
    n_series_base: int = 300,
    n_series_micro: int = 80,
    n_sim_mc: int = 800,
    output_mode: str = "automatico",
    n_series_fixed: int = 25,
    min_conf_pct: float = 30.0,
) -> pd.DataFrame:
    """
    Motor principal TURBO++ ULTRA:
      1) Constr√≥i contexto IDX ULTRA.
      2) Gera leque base via IDX ULTRA.
      3) Aplica IPF/IPO + S6 Profundo ULTRA.
      4) Gera Micro-Leque ULTRA.
      5) Roda Monte Carlo Profundo ULTRA.
      6) Unifica tudo e aplica pesos adaptativos por k*.
      7) Aplica pol√≠tica de sa√≠da (modo de quantidade).
    Retorna DataFrame final ordenado com colunas:
      ['series', 'score_s6', 'score_micro', 'prob_mc', 'score_global']
    """
    if df_hist is None or df_hist.empty:
        return pd.DataFrame(columns=["series", "score_s6", "score_micro", "prob_mc", "score_global"])

    n_passageiros = obter_n_passageiros(df_hist)

    # 1) Contexto IDX
    contexto = construir_contexto_idx_ultra(df_hist, idx_alvo, janela_passado=40)

    # 2) Leque base
    leque_base = gerar_leque_idx_ultra_base(
        contexto=contexto,
        n_passageiros=n_passageiros,
        n_series_base=n_series_base,
        seed=RANDOM_SEED,
    )
    if not leque_base:
        return pd.DataFrame(columns=["series", "score_s6", "score_micro", "prob_mc", "score_global"])

    # 3) IPF / IPO + S6
    df_ip = calcular_ipf_ipo_para_leque(df_hist, leque_base, idx_alvo=idx_alvo, janela_ref=80)
    df_s6 = s6_profundo_ultra_refinar(df_hist, df_ip, idx_alvo=idx_alvo, n_top=n_series_base)

    # 4) Micro-Leque ULTRA
    df_micro = gerar_micro_leque_ultra(
        df_hist=df_hist,
        idx_alvo=idx_alvo,
        n_passageiros=n_passageiros,
        n_series_micro=n_series_micro,
    )

    # 5) Monte Carlo Profundo ULTRA
    mc_result = monte_carlo_profundo_ultra(
        df_hist=df_hist,
        idx_alvo=idx_alvo,
        n_passageiros=n_passageiros,
        n_simulacoes=n_sim_mc,
    )
    df_mc = mc_result.tabela

    # 6) Unificar leques e aplicar pesos adaptativos
    df_flat = unir_leques(df_s6, df_micro, df_mc)
    df_flat = normalizar_scores_global(df_flat)
    pesos = calcular_pesos_por_k_star(k_info)
    df_flat = aplicar_pesos_adaptativos(df_flat, pesos)

    # 7) Aplicar modo de sa√≠da
    df_final = limit_by_mode(
        flat_df=df_flat,
        regime_state=regime_info.estado,
        output_mode=output_mode,
        n_series_fixed=n_series_fixed,
        min_conf_pct=min_conf_pct,
    )

    return df_final.reset_index(drop=True)


# ============================================================
# MODOS DE REPLAY (LIGHT / ULTRA / ULTRA UNIT√ÅRIO)
# ============================================================

def montar_contexto_replay_light(
    df_hist: pd.DataFrame,
    idx_alvo: int,
    regime_info: RegimeInfo,
    k_info: KStarInfo,
) -> Dict[str, Any]:
    """
    Monta um resumo leve (Replay LIGHT) para um √≠ndice alvo:
      - s√©rie real
      - k real
      - bar√¥metro
      - k* local
    """
    if df_hist is None or df_hist.empty:
        return {
            "idx_alvo": idx_alvo,
            "serie_id": None,
            "serie_real": [],
            "k_real": None,
            "regime": regime_info,
            "k_star": k_info,
        }

    row = df_hist[df_hist["idx"] == idx_alvo]
    if row.empty:
        return {
            "idx_alvo": idx_alvo,
            "serie_id": None,
            "serie_real": [],
            "k_real": None,
            "regime": regime_info,
            "k_star": k_info,
        }

    col_pass = extrair_passageiros(df_hist)
    serie_real = [safe_int(row.iloc[0][c]) for c in col_pass]
    serie_id = str(row.iloc[0]["serie_id"])
    k_real = safe_int(row.iloc[0]["k"])

    return {
        "idx_alvo": idx_alvo,
        "serie_id": serie_id,
        "serie_real": serie_real,
        "k_real": k_real,
        "regime": regime_info,
        "k_star": k_info,
    }


def montar_contexto_replay_ultra_unitario(
    df_hist: pd.DataFrame,
    idx_alvo: int,
    df_turbo: pd.DataFrame,
    qds_info: Optional[QDSInfo],
    regime_info: RegimeInfo,
    k_info: KStarInfo,
    top_n: int = 25,
) -> Dict[str, Any]:
    """
    Replay ULTRA UNIT√ÅRIO:
      - Focado em um √∫nico √≠ndice alvo.
      - Exibe:
          * s√©rie real
          * leque TURBO++ local (top-N)
          * acerto top-N (se a s√©rie real aparece)
          * regime (bar√¥metro)
          * k* (sentinela)
          * QDS local, se dispon√≠vel
    Retorna dicion√°rio para ser renderizado no painel espec√≠fico.
    """
    if df_hist is None or df_hist.empty:
        return {
            "idx_alvo": idx_alvo,
            "serie_id": None,
            "serie_real": [],
            "k_real": None,
            "df_turbo_local": pd.DataFrame(),
            "acerto_topN": False,
            "posicao_topN": None,
            "regime": regime_info,
            "k_star": k_info,
            "qds": qds_info,
        }

    row = df_hist[df_hist["idx"] == idx_alvo]
    if row.empty:
        return {
            "idx_alvo": idx_alvo,
            "serie_id": None,
            "serie_real": [],
            "k_real": None,
            "df_turbo_local": pd.DataFrame(),
            "acerto_topN": False,
            "posicao_topN": None,
            "regime": regime_info,
            "k_star": k_info,
            "qds": qds_info,
        }

    col_pass = extrair_passageiros(df_hist)
    serie_real = [safe_int(row.iloc[0][c]) for c in col_pass]
    serie_id = str(row.iloc[0]["serie_id"])
    k_real = safe_int(row.iloc[0]["k"])

    # restringe df_turbo ao top-N
    if df_turbo is None or df_turbo.empty:
        df_turbo_local = pd.DataFrame(columns=["series", "score_global"])
    else:
        df_turbo_local = df_turbo.copy().sort_values("score_global", ascending=False).head(top_n).reset_index(drop=True)

    # verifica acerto top-N
    acerto_topN = False
    posicao_topN: Optional[int] = None

    if not df_turbo_local.empty:
        for i, rowp in df_turbo_local.iterrows():
            s_prev = normalizar_serie(rowp["series"])
            if calcular_acerto_total(serie_real, s_prev):
                acerto_topN = True
                posicao_topN = int(i + 1)
                break

    return {
        "idx_alvo": idx_alvo,
        "serie_id": serie_id,
        "serie_real": serie_real,
        "k_real": k_real,
        "df_turbo_local": df_turbo_local,
        "acerto_topN": acerto_topN,
        "posicao_topN": posicao_topN,
        "regime": regime_info,
        "k_star": k_info,
        "qds": qds_info,
    }


# ============================================================
# (FIM DA PARTE 2/4)
# Pr√≥xima parte: interface Streamlit, pain√©is completos
# (Hist√≥rico, Pipeline V14-FLEX ULTRA, Monitor de Risco,
# Modo TURBO++ ULTRA, Replay LIGHT, Replay ULTRA Loop,
# Replay ULTRA Unit√°rio, Testes de Confiabilidade, etc.)
# ============================================================
# ============================================================
# ======================= INTERFACE ==========================
# ============================================================

# Setup inicial da p√°gina
set_page_config_once()

st.title("üöó Predict Cars ‚Äî V14-FLEX ULTRA REAL (TURBO++)")
st.caption(f"Vers√£o completa: {APP_VERSION}")


# ============================================================
# SIDEBAR ‚Äî NAVEGA√á√ÉO
# ============================================================

painel = st.sidebar.radio(
    "üìÇ Navega√ß√£o",
    [
        "üì• Hist√≥rico ‚Äî Entrada",
        "üîç Pipeline V14-FLEX ULTRA",
        "üö® Monitor de Risco (k & k*)",
        "üöÄ Modo TURBO++ ULTRA Adaptativo",
        "üí° Replay LIGHT",
        "üìÖ Replay ULTRA (Loop Tradicional)",
        "üéØ Replay ULTRA UNIT√ÅRIO (Novo)",
        "üß™ Testes de Confiabilidade",
    ],
)


# ============================================================
# PAINEL 1 ‚Äî HIST√ìRICO (Entrada FLEX)
# ============================================================

if painel == "üì• Hist√≥rico ‚Äî Entrada":
    st.header("üì• Hist√≥rico ‚Äî Entrada FLEX")
    st.write("Carregue seu hist√≥rico com **n passageiros + coluna k detectada automaticamente**.")

    metodo = st.radio(
        "M√©todo de carregamento:",
        ["Upload CSV", "Colar texto"],
    )

    df = None

    try:
        if metodo == "Upload CSV":
            file = st.file_uploader("Selecione arquivo CSV", type=["csv"])
            if file is not None:
                df = carregar_historico_via_csv(file)

        else:  # texto
            texto = st.text_area("Cole o conte√∫do do CSV aqui")
            if texto.strip():
                sep = st.selectbox("Separador", [";", ","])
                df = carregar_historico_via_texto(texto, sep=sep)

        if df is not None:
            st.success("Hist√≥rico carregado com sucesso!")
            st.dataframe(df, use_container_width=True)
            st.session_state["df"] = df

            st.info(f"n passageiros detectados: **{obter_n_passageiros(df)}**")
            min_idx, max_idx = obter_intervalo_indices(df)
            st.write(f"Intervalo de √≠ndices: **C{min_idx} ‚Üí C{max_idx}**")

    except Exception as e:
        st.error(f"Erro ao carregar hist√≥rico: {e}")


# ============================================================
# PAINEL 2 ‚Äî PIPELINE V14-FLEX ULTRA
# ============================================================

elif painel == "üîç Pipeline V14-FLEX ULTRA":
    st.header("üîç Pipeline V14-FLEX ‚Äî ULTRA")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico primeiro no painel 'üì• Hist√≥rico ‚Äî Entrada'.")
        st.stop()

    min_idx, max_idx = obter_intervalo_indices(df)
    idx_alvo = st.number_input(
        "√çndice alvo",
        min_value=min_idx + 1,
        max_value=max_idx,
        value=max_idx,
    )

    st.subheader("üì° Bar√¥metro ULTRA REAL")
    reg = calcular_regime_ultra(df)
    st.write(reg.descricao)

    st.subheader("üõ° k* ULTRA REAL ‚Äî Sentinela")
    kinfo = calcular_k_star_ultra(df)
    st.write(kinfo.descricao)

    st.subheader("üîß IDX ULTRA ‚Äî Contexto")
    ctx = construir_contexto_idx_ultra(df, idx_alvo)
    st.write(f"Janela usada: {ctx['janela_usada']}")
    st.write(f"k m√©dio: {ctx['media_k']:.2f}, k max: {ctx['max_k']}")

    st.info("Este painel mostra a estrutura, mas **n√£o gera previs√£o**. Para gerar previs√£o completa, use o painel TURBO++ ULTRA.")


# ============================================================
# PAINEL 3 ‚Äî MONITOR DE RISCO (k & k*)
# ============================================================

elif painel == "üö® Monitor de Risco (k & k*)":
    st.header("üö® Monitor de Risco")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico primeiro.")
        st.stop()

    reg = calcular_regime_ultra(df)
    kinfo = calcular_k_star_ultra(df)

    st.subheader("üì° Bar√¥metro da Estrada")
    st.write(reg.descricao)
    st.json(
        {
            "janela": reg.janela_usada,
            "k_medio": reg.k_medio,
            "k_max": reg.k_max,
            "estado": reg.estado,
        }
    )

    st.subheader("üõ° k* ‚Äî Sentinela dos Guardas")
    st.write(kinfo.descricao)
    st.json(
        {
            "janela": kinfo.janela_usada,
            "k_media_janela": kinfo.k_media_janela,
            "k_max_janela": kinfo.k_max_janela,
            "k_star_pct": kinfo.k_star_pct,
            "estado": kinfo.estado,
        }
    )


# ============================================================
# PAINEL 4 ‚Äî MODO TURBO++ ULTRA ADAPTATIVO
# ============================================================

elif painel == "üöÄ Modo TURBO++ ULTRA Adaptativo":
    st.header("üöÄ Modo TURBO++ ULTRA Adaptativo")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico primeiro.")
        st.stop()

    min_idx, max_idx = obter_intervalo_indices(df)

    st.subheader("üéØ √çndice alvo")
    idx_alvo = st.number_input(
        "Selecione o √≠ndice alvo:",
        min_value=min_idx + 1,
        max_value=max_idx,
        value=max_idx,
    )

    reg = calcular_regime_ultra(df)
    kinfo = calcular_k_star_ultra(df)

    st.write(reg.descricao)
    st.write(kinfo.descricao)

    st.subheader("‚öôÔ∏è Controles do Leque")
    output_mode = st.selectbox(
        "Modo de gera√ß√£o do Leque:",
        [
            "automatico",
            "fixo",
            "conf_min",
        ],
        format_func=lambda x: {
            "automatico": "Autom√°tico (por regime)",
            "fixo": "Quantidade fixa",
            "conf_min": "Confiabilidade m√≠nima",
        }[x],
    )

    n_series_fixed = st.number_input("Quantidade fixa", 5, 200, 25)
    min_conf_pct = st.slider("Confiabilidade m√≠nima (%)", 0, 100, 30)

    st.subheader("üß† Motor TURBO++ ULTRA")
    if st.button("Gerar previs√£o"):
        df_turbo = montar_previsao_turbo_ultra(
            df_hist=df,
            idx_alvo=idx_alvo,
            regime_info=reg,
            k_info=kinfo,
            n_series_base=300,
            n_series_micro=80,
            n_sim_mc=800,
            output_mode=output_mode,
            n_series_fixed=n_series_fixed,
            min_conf_pct=min_conf_pct,
        )

        if df_turbo.empty:
            st.error("Leque vazio ‚Äî algo ocorreu.")
        else:
            st.success("Previs√£o gerada!")
            st.dataframe(df_turbo, use_container_width=True)

        st.session_state["df_turbo"] = df_turbo
        st.session_state["idx_alvo_turbo"] = idx_alvo



# ============================================================
# PAINEL 5 ‚Äî Replay LIGHT
# ============================================================

elif painel == "üí° Replay LIGHT":
    st.header("üí° Replay LIGHT")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico.")
        st.stop()

    min_idx, max_idx = obter_intervalo_indices(df)
    idx_alvo = st.number_input("√çndice para Replay LIGHT", min_idx, max_idx, max_idx)

    reg = calcular_regime_ultra(df)
    kinfo = calcular_k_star_ultra(df)

    ctx = montar_contexto_replay_light(df, idx_alvo, reg, kinfo)

    st.subheader(f"‚ñ∂ {ctx['serie_id']} ‚Äî S√©rie Real")
    st.code(" ".join(str(x) for x in ctx["serie_real"]))

    st.write(reg.descricao)
    st.write(kinfo.descricao)

    st.success("Replay LIGHT finalizado.")



# ============================================================
# PAINEL 6 ‚Äî Replay ULTRA (loop tradicional)
# ============================================================

elif painel == "üìÖ Replay ULTRA (Loop Tradicional)":
    st.header("üìÖ Replay ULTRA ‚Äî Loop Tradicional")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico.")
        st.stop()

    min_idx, max_idx = obter_intervalo_indices(df)

    st.info("Este modo √© pesado ‚Äî calcula TURBO++ para todos os √≠ndices de uma janela.")

    inicio = st.number_input("In√≠cio", min_idx + 1, max_idx, max_idx - 20)
    fim = st.number_input("Fim", inicio, max_idx, max_idx)

    reg = calcular_regime_ultra(df)
    kinfo = calcular_k_star_ultra(df)

    if st.button("Executar Replay ULTRA Loop"):
        resultados = []

        for idx_alvo in range(int(inicio), int(fim) + 1):
            df_turbo = montar_previsao_turbo_ultra(
                df_hist=df,
                idx_alvo=idx_alvo,
                regime_info=reg,
                k_info=kinfo,
                n_series_base=300,
                n_series_micro=80,
                n_sim_mc=800,
            )

            col_pass = extrair_passageiros(df)
            real = df[df["idx"] == idx_alvo]
            if not real.empty:
                serie_real = [int(real.iloc[0][c]) for c in col_pass]
                hit_top1 = calcular_acerto_total(
                    serie_real,
                    normalizar_serie(df_turbo.iloc[0]["series"]) if not df_turbo.empty else [],
                )
                resultados.append({"idx": idx_alvo, "hit_top1": hit_top1})

        st.success("Loop conclu√≠do!")
        st.dataframe(pd.DataFrame(resultados), use_container_width=True)



# ============================================================
# PAINEL 7 ‚Äî Replay ULTRA UNIT√ÅRIO (Novo)
# ============================================================

elif painel == "üéØ Replay ULTRA UNIT√ÅRIO (Novo)":
    st.header("üéØ Replay ULTRA UNIT√ÅRIO ‚Äî Focado em 1 √≠ndice")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Hist√≥rico ausente.")
        st.stop()

    min_idx, max_idx = obter_intervalo_indices(df)
    idx_alvo = st.number_input(
        "Escolha o √≠ndice para Replay ULTRA Unit√°rio:",
        min_value=min_idx + 1,
        max_value=max_idx,
        value=max_idx,
    )

    st.subheader("üîß Gerar Previs√£o TURBO++ para este √≠ndice")
    if st.button("Gerar TURBO++ para este √≠ndice"):
        reg = calcular_regime_ultra(df)
        kinfo = calcular_k_star_ultra(df)

        df_turbo = montar_previsao_turbo_ultra(
            df_hist=df,
            idx_alvo=idx_alvo,
            regime_info=reg,
            k_info=kinfo,
            n_series_base=300,
            n_series_micro=80,
            n_sim_mc=800,
            output_mode="automatico",
        )

        st.session_state["df_turbo_unitario"] = df_turbo
        st.session_state["idx_unitario"] = idx_alvo
        st.success("Previs√£o TURBO++ gerada.")

    df_turbo = st.session_state.get("df_turbo_unitario", None)
    idx_unit = st.session_state.get("idx_unitario", None)

    if df_turbo is not None and idx_unit is not None:
        reg = calcular_regime_ultra(df)
        kinfo = calcular_k_star_ultra(df)

        col_pass = extrair_passageiros(df)
        recorte = df[df["idx"] == idx_unit].iloc[0]
        serie_real = [int(recorte[c]) for c in col_pass]

        # Monta contexto de Replay ULTRA Unit√°rio
        qds_dummy = None
        ctx = montar_contexto_replay_ultra_unitario(
            df_hist=df,
            idx_alvo=idx_unit,
            df_turbo=df_turbo,
            qds_info=qds_dummy,
            regime_info=reg,
            k_info=kinfo,
            top_n=25,
        )

        st.subheader(f"üéØ Resultado ‚Äî {ctx['serie_id']}")
        st.markdown("### S√©rie Real")
        st.code(" ".join(str(x) for x in serie_real))

        st.markdown("### Top-N TURBO++")
        st.dataframe(ctx["df_turbo_local"], use_container_width=True)

        if ctx["acerto_topN"]:
            st.success(f"ACERTO TOP-N! posi√ß√£o: {ctx['posicao_topN']}")
        else:
            st.error("N√£o acertou no Top-N.")

        st.markdown("### Regime")
        st.write(reg.descricao)

        st.markdown("### k*")
        st.write(kinfo.descricao)

        st.info("Replay ULTRA Unit√°rio conclu√≠do.")



# ============================================================
# PAINEL 8 ‚Äî Testes de Confiabilidade
# ============================================================

elif painel == "üß™ Testes de Confiabilidade":
    st.header("üß™ Testes de Confiabilidade ‚Äî QDS / Backtest")
    df = st.session_state.get("df", None)

    if df is None:
        st.warning("Carregue o hist√≥rico.")
        st.stop()

    st.subheader("‚ñ∂ Backtest REAL")
    janela = st.number_input("Janela", 20, 500, 150)
    top_n = st.number_input("Top-N (conceitual)", 1, 20, 10)

    if st.button("Executar Backtest"):
        bt = executar_backtest_real(
            df_hist=df,
            n_passageiros=obter_n_passageiros(df),
            janela=janela,
            top_n=top_n,
        )
        st.success("Backtest conclu√≠do!")
        st.write(bt.descricao)
        st.dataframe(bt.tabela, use_container_width=True)

        st.subheader("‚ñ∂ QDS REAL")
        qds_info = calcular_qds_real(bt.tabela, top_n=top_n)
        st.write(qds_info.descricao)



# ============================================================
# (FIM DA PARTE 3/4)
# A Pr√≥xima parte (4/4) conter√°:
# ‚Üí Finaliza√ß√£o
# ‚Üí if __name__ == "__main__"
# ============================================================
# ============================================================
# FINALIZA√á√ÉO
# ============================================================

def main():
    """
    A fun√ß√£o main() √© simb√≥lica aqui, pois o Streamlit j√° executa
    o script de cima para baixo. Mantemos para organiza√ß√£o formal
    do app completo.
    """
    pass


# ============================================================
# EXECU√á√ÉO
# ============================================================

if __name__ == "__main__":
    main()
